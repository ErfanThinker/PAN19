{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Reading general data of the problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading general data of the problems, done!\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import division\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "\n",
    "# multiprocessing.set_start_method('spawn')\n",
    "from MyUtils import clean_folder, read_files, shuffle_docs\n",
    "from Word2Dim import Word2Dim\n",
    "\n",
    "dataset_path = '.' + os.sep + 'pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23'\n",
    "outpath = '.' + os.sep + 'dev_out'\n",
    "\n",
    "clean_folder(outpath)\n",
    "\n",
    "infocollection = dataset_path + os.sep + 'collection-info.json'\n",
    "problems = []\n",
    "language = []\n",
    "with open(infocollection, 'r') as f:\n",
    "    for attrib in json.load(f):\n",
    "        problems.append(attrib['problem-name'])\n",
    "        language.append(attrib['language'])\n",
    "print('Reading general data of the problems, done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reading problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc count to process:  819\n",
      "process_doc, done!\n",
      "word_set, ready!\n",
      "fit_transform_texts is done!\n",
      "doc count to process:  468\n",
      "Reading problem 1, done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "problem = problems[0]\n",
    "index = 0\n",
    "\n",
    "# used for n_gram extraction and word indexing, a threshold which prevent words appearing lower than this value to be counted in calculations\n",
    "tf = 5\n",
    "\n",
    "\n",
    "infoproblem = dataset_path + os.sep + problem + os.sep + 'problem-info.json'\n",
    "candidates = []\n",
    "with open(infoproblem, 'r') as f:\n",
    "    fj = json.load(f)\n",
    "    unk_folder = fj['unknown-folder']\n",
    "    for attrib in fj['candidate-authors']:\n",
    "        candidates.append(attrib['author-name'])\n",
    "\n",
    "candidates.sort()\n",
    "# Building training set\n",
    "train_docs = []\n",
    "for candidate in candidates:\n",
    "    train_docs.extend(read_files(dataset_path + os.sep + problem, candidate))\n",
    "train_texts = [text for i, (text, label) in enumerate(train_docs)]\n",
    "train_labels = [label for i, (text, label) in enumerate(train_docs)]\n",
    "initial_train_size = len(train_labels)\n",
    "train_texts, train_labels = shuffle_docs(train_texts, train_labels)\n",
    "validation_size = len(train_texts) - initial_train_size\n",
    "class_size = int(initial_train_size / len(set(train_labels)))\n",
    "index_2_label_dict = {i: l for i, l in enumerate(set(train_labels))}\n",
    "label_2_index_dict = {l: i for i, l in enumerate(set(train_labels))}\n",
    "train_labels = [label_2_index_dict[v] for v in train_labels]\n",
    "w2d = Word2Dim(lang= language[index])\n",
    "train_tokenized_with_pos, train_tokenized_indexed = w2d.fit_transform_texts(train_texts, train_labels, tf= tf)\n",
    "\n",
    "maxlen = len(max(train_tokenized_indexed, key=len))  # We will cut the texts after # words\n",
    "embedding_dim = w2d.word_embedding.shape[1]\n",
    "\n",
    "# preparing test set\n",
    "ground_truth_file = dataset_path + os.sep + problem + os.sep + 'ground-truth.json'\n",
    "gt = {}\n",
    "with open(ground_truth_file, 'r') as f:\n",
    "    for attrib in json.load(f)['ground_truth']:\n",
    "        gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "test_docs = read_files(dataset_path + os.sep + problem, unk_folder, gt)\n",
    "test_texts = [text for i, (text, label) in enumerate(test_docs)]\n",
    "test_labels = [label for i, (text, label) in enumerate(test_docs)]\n",
    "\n",
    "# Filter validation to known authors\n",
    "test_texts = [text for i, (text, label) in enumerate(test_docs) if label in label_2_index_dict.keys()]\n",
    "test_labels = [label for i, (text, label) in enumerate(test_docs) if label in label_2_index_dict.keys()]\n",
    "\n",
    "test_labels = [label_2_index_dict[v] for v in test_labels]\n",
    "\n",
    "test_tokenized_with_pos, test_tokenized_indexed = w2d.transform(test_texts)\n",
    "print(\"Reading problem 1, done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Extraction for Neural Net\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from MyUtils import extract_n_grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "n = 3\n",
    "vocabulary = extract_n_grams(train_docs, n, tf)\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(n, n), lowercase=False, vocabulary=vocabulary)\n",
    "n_gram_train_data = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "n_gram_train_data = n_gram_train_data.astype(float)\n",
    "\n",
    "for i, v in enumerate(train_texts):\n",
    "    n_gram_train_data[i] = n_gram_train_data[i] / len(train_texts[i])\n",
    "n_gram_test_data = vectorizer.transform(test_texts)\n",
    "n_gram_test_data = n_gram_test_data.astype(float)\n",
    "for i, v in enumerate(test_texts):\n",
    "    n_gram_test_data[i] = n_gram_test_data[i] / len(test_texts[i])\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "scaled_train_data_ngrams = max_abs_scaler.fit_transform(n_gram_train_data)\n",
    "scaled_test_data_ngrams = max_abs_scaler.transform(n_gram_test_data)\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "scaled_train_data_words = max_abs_scaler.fit_transform(w2d.get_texts_vectorized_and_normalized(train_tokenized_indexed)[:, 1:])\n",
    "scaled_test_data_words = max_abs_scaler.transform(w2d.get_texts_vectorized_and_normalized(test_tokenized_indexed)[:, 1:])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(819, 7623)\n",
      "(468, 7623)\n",
      "7623\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_data_words.shape)\n",
    "print(scaled_test_data_words.shape)\n",
    "print(len(w2d.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 9)\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import layers, Input, callbacks\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "callbacks_list_neu = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=50,\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='my_model_neu.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        verbose=1, \n",
    "        patience=20,\n",
    "    )\n",
    "]\n",
    "\n",
    "callbacks_list_neu_ngrams = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=50,\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='my_model_neu_ngrams.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        verbose=1, \n",
    "        patience=20,\n",
    "    )\n",
    "]\n",
    "\n",
    "callbacks_list_neu_words = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=50,\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='my_model_neu_words.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        verbose=1, \n",
    "        patience=20,\n",
    "    )\n",
    "]\n",
    "\n",
    "callbacks_list_convnet = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=35,\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='my_model_convnet.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        verbose=1, \n",
    "        patience=10,\n",
    "    )\n",
    "]\n",
    "\n",
    "callbacks_list_stacked = [\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='my_model_stacked.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        verbose=1, \n",
    "        patience=20,\n",
    "    )\n",
    "]\n",
    "\n",
    "train_data = pad_sequences(train_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "test_data = pad_sequences(test_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_data, test_data, to_categorical(train_labels), to_categorical(test_labels)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels,\n",
    "#                                                   test_size=validation_size,\n",
    "#                                                   stratify=train_labels)\n",
    "# X_scaled_train_data_words, X_scaled_val_data_words, _, _ = train_test_split(scaled_train_data_words, train_labels,\n",
    "#                                                   test_size=validation_size,\n",
    "#                                                   stratify=train_labels)\n",
    "# X_scaled_train_data_ngrams, X_scaled_val_data_ngrams, _, _ = train_test_split(scaled_train_data_ngrams, train_labels,\n",
    "#                                                   test_size=validation_size,\n",
    "#                                                   stratify=train_labels)\n",
    "\n",
    "y_train, y_val = train_labels[:initial_train_size], train_labels[initial_train_size:]\n",
    "X_train, X_val = train_data[:initial_train_size], train_data[initial_train_size:]\n",
    "X_scaled_train_data_words, X_scaled_val_data_words = scaled_train_data_words[:initial_train_size], scaled_train_data_words[initial_train_size:]\n",
    "X_scaled_train_data_ngrams, X_scaled_val_data_ngrams = scaled_train_data_ngrams[:initial_train_size], scaled_train_data_ngrams[initial_train_size:]\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "# y_test = to_categorical(test_labels)\n",
    "# print(X_train.shape)\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                132896    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 139,753\n",
      "Trainable params: 139,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 63 samples, validate on 756 samples\n",
      "Epoch 1/1500\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 5.5283 - acc: 0.1587 - val_loss: 5.5049 - val_acc: 0.1124\n",
      "Epoch 2/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.4907 - acc: 0.0952 - val_loss: 5.4493 - val_acc: 0.1164\n",
      "Epoch 3/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.4378 - acc: 0.1270 - val_loss: 5.3969 - val_acc: 0.1323\n",
      "Epoch 4/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.3780 - acc: 0.2540 - val_loss: 5.3458 - val_acc: 0.1481\n",
      "Epoch 5/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.3521 - acc: 0.1111 - val_loss: 5.2977 - val_acc: 0.1786\n",
      "Epoch 6/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.2606 - acc: 0.2063 - val_loss: 5.2498 - val_acc: 0.2130\n",
      "Epoch 7/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.2364 - acc: 0.2381 - val_loss: 5.2008 - val_acc: 0.2434\n",
      "Epoch 8/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.1918 - acc: 0.1746 - val_loss: 5.1555 - val_acc: 0.2646\n",
      "Epoch 9/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.1239 - acc: 0.2063 - val_loss: 5.1087 - val_acc: 0.2897\n",
      "Epoch 10/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.0603 - acc: 0.2381 - val_loss: 5.0559 - val_acc: 0.3360\n",
      "Epoch 11/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.0411 - acc: 0.1905 - val_loss: 5.0047 - val_acc: 0.3135\n",
      "Epoch 12/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 5.0208 - acc: 0.2381 - val_loss: 4.9576 - val_acc: 0.3347\n",
      "Epoch 13/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.9967 - acc: 0.1746 - val_loss: 4.9159 - val_acc: 0.3651\n",
      "Epoch 14/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.9244 - acc: 0.2857 - val_loss: 4.8728 - val_acc: 0.4008\n",
      "Epoch 15/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.8806 - acc: 0.2857 - val_loss: 4.8253 - val_acc: 0.4590\n",
      "Epoch 16/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.8598 - acc: 0.2381 - val_loss: 4.7816 - val_acc: 0.5093\n",
      "Epoch 17/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.8161 - acc: 0.2381 - val_loss: 4.7397 - val_acc: 0.5331\n",
      "Epoch 18/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.7963 - acc: 0.2857 - val_loss: 4.6923 - val_acc: 0.5569\n",
      "Epoch 19/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.7499 - acc: 0.3016 - val_loss: 4.6443 - val_acc: 0.5767\n",
      "Epoch 20/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.7045 - acc: 0.2540 - val_loss: 4.5871 - val_acc: 0.5833\n",
      "Epoch 21/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.6342 - acc: 0.3810 - val_loss: 4.5359 - val_acc: 0.6019\n",
      "Epoch 22/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.5930 - acc: 0.2857 - val_loss: 4.4835 - val_acc: 0.6032\n",
      "Epoch 23/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.6013 - acc: 0.3492 - val_loss: 4.4389 - val_acc: 0.6204\n",
      "Epoch 24/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.5039 - acc: 0.3333 - val_loss: 4.3923 - val_acc: 0.6587\n",
      "Epoch 25/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.4145 - acc: 0.4603 - val_loss: 4.3400 - val_acc: 0.6812\n",
      "Epoch 26/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.4260 - acc: 0.3968 - val_loss: 4.2889 - val_acc: 0.6997\n",
      "Epoch 27/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.3814 - acc: 0.4444 - val_loss: 4.2390 - val_acc: 0.6944\n",
      "Epoch 28/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.3228 - acc: 0.3968 - val_loss: 4.1860 - val_acc: 0.7130\n",
      "Epoch 29/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.3080 - acc: 0.4127 - val_loss: 4.1383 - val_acc: 0.7513\n",
      "Epoch 30/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.2267 - acc: 0.4921 - val_loss: 4.0899 - val_acc: 0.7698\n",
      "Epoch 31/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.2248 - acc: 0.4762 - val_loss: 4.0408 - val_acc: 0.7817\n",
      "Epoch 32/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.1391 - acc: 0.4762 - val_loss: 3.9861 - val_acc: 0.7844\n",
      "Epoch 33/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.1378 - acc: 0.4286 - val_loss: 3.9419 - val_acc: 0.7817\n",
      "Epoch 34/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.1661 - acc: 0.3968 - val_loss: 3.9047 - val_acc: 0.7778\n",
      "Epoch 35/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.0377 - acc: 0.5238 - val_loss: 3.8616 - val_acc: 0.7923\n",
      "Epoch 36/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.0315 - acc: 0.5238 - val_loss: 3.8097 - val_acc: 0.8307\n",
      "Epoch 37/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 4.0721 - acc: 0.4444 - val_loss: 3.7587 - val_acc: 0.8413\n",
      "Epoch 38/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.8467 - acc: 0.6032 - val_loss: 3.7124 - val_acc: 0.8638\n",
      "Epoch 39/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.8991 - acc: 0.5397 - val_loss: 3.6632 - val_acc: 0.8823\n",
      "Epoch 40/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.7548 - acc: 0.6825 - val_loss: 3.6136 - val_acc: 0.8876\n",
      "Epoch 41/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.8599 - acc: 0.5873 - val_loss: 3.5708 - val_acc: 0.9272\n",
      "Epoch 42/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.7089 - acc: 0.5873 - val_loss: 3.5246 - val_acc: 0.9339\n",
      "Epoch 43/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.7608 - acc: 0.5556 - val_loss: 3.4761 - val_acc: 0.9788\n",
      "Epoch 44/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.6242 - acc: 0.6190 - val_loss: 3.4261 - val_acc: 0.9788\n",
      "Epoch 45/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 3.7442 - acc: 0.6190 - val_loss: 3.3861 - val_acc: 0.9669\n",
      "Epoch 46/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.5890 - acc: 0.6667 - val_loss: 3.3495 - val_acc: 0.9894\n",
      "Epoch 47/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.6476 - acc: 0.6667 - val_loss: 3.3088 - val_acc: 0.9974\n",
      "Epoch 48/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.6186 - acc: 0.6032 - val_loss: 3.2670 - val_acc: 0.9974\n",
      "Epoch 49/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.5607 - acc: 0.6984 - val_loss: 3.2230 - val_acc: 0.9947\n",
      "Epoch 50/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.4575 - acc: 0.6984 - val_loss: 3.1798 - val_acc: 0.9947\n",
      "Epoch 51/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.4683 - acc: 0.6667 - val_loss: 3.1428 - val_acc: 0.9987\n",
      "Epoch 52/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.5125 - acc: 0.6667 - val_loss: 3.0976 - val_acc: 0.9987\n",
      "Epoch 53/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.3165 - acc: 0.7460 - val_loss: 3.0625 - val_acc: 1.0000\n",
      "Epoch 54/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.3918 - acc: 0.6825 - val_loss: 3.0288 - val_acc: 1.0000\n",
      "Epoch 55/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.2633 - acc: 0.7778 - val_loss: 2.9872 - val_acc: 1.0000\n",
      "Epoch 56/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.2341 - acc: 0.6508 - val_loss: 2.9520 - val_acc: 1.0000\n",
      "Epoch 57/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.2692 - acc: 0.6825 - val_loss: 2.9223 - val_acc: 1.0000\n",
      "Epoch 58/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.2363 - acc: 0.7619 - val_loss: 2.8839 - val_acc: 1.0000\n",
      "Epoch 59/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.2307 - acc: 0.7778 - val_loss: 2.8467 - val_acc: 1.0000\n",
      "Epoch 60/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.1889 - acc: 0.7143 - val_loss: 2.8139 - val_acc: 1.0000\n",
      "Epoch 61/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.1809 - acc: 0.7302 - val_loss: 2.7838 - val_acc: 1.0000\n",
      "Epoch 62/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.1786 - acc: 0.6984 - val_loss: 2.7575 - val_acc: 1.0000\n",
      "Epoch 63/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9633 - acc: 0.8571 - val_loss: 2.7231 - val_acc: 1.0000\n",
      "Epoch 64/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.0802 - acc: 0.7619 - val_loss: 2.6907 - val_acc: 1.0000\n",
      "Epoch 65/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.1158 - acc: 0.7460 - val_loss: 2.6655 - val_acc: 1.0000\n",
      "Epoch 66/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9208 - acc: 0.8413 - val_loss: 2.6334 - val_acc: 1.0000\n",
      "Epoch 67/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9405 - acc: 0.7778 - val_loss: 2.5990 - val_acc: 1.0000\n",
      "Epoch 68/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 3.0043 - acc: 0.7937 - val_loss: 2.5763 - val_acc: 1.0000\n",
      "Epoch 69/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9822 - acc: 0.7937 - val_loss: 2.5525 - val_acc: 1.0000\n",
      "Epoch 70/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9081 - acc: 0.7937 - val_loss: 2.5262 - val_acc: 1.0000\n",
      "Epoch 71/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9406 - acc: 0.8095 - val_loss: 2.4973 - val_acc: 1.0000\n",
      "Epoch 72/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7966 - acc: 0.8254 - val_loss: 2.4717 - val_acc: 1.0000\n",
      "Epoch 73/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7639 - acc: 0.8095 - val_loss: 2.4458 - val_acc: 1.0000\n",
      "Epoch 74/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8667 - acc: 0.7619 - val_loss: 2.4259 - val_acc: 1.0000\n",
      "Epoch 75/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7997 - acc: 0.7937 - val_loss: 2.4088 - val_acc: 1.0000\n",
      "Epoch 76/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7916 - acc: 0.8254 - val_loss: 2.3890 - val_acc: 1.0000\n",
      "Epoch 77/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.9465 - acc: 0.6984 - val_loss: 2.3710 - val_acc: 1.0000\n",
      "Epoch 78/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8646 - acc: 0.7460 - val_loss: 2.3533 - val_acc: 1.0000\n",
      "Epoch 79/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.8667 - acc: 0.7302 - val_loss: 2.3406 - val_acc: 1.0000\n",
      "Epoch 80/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6992 - acc: 0.7778 - val_loss: 2.3279 - val_acc: 1.0000\n",
      "Epoch 81/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6905 - acc: 0.8571 - val_loss: 2.3058 - val_acc: 1.0000\n",
      "Epoch 82/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6780 - acc: 0.8413 - val_loss: 2.2866 - val_acc: 1.0000\n",
      "Epoch 83/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.7592 - acc: 0.7937 - val_loss: 2.2686 - val_acc: 1.0000\n",
      "Epoch 84/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6155 - acc: 0.8889 - val_loss: 2.2498 - val_acc: 1.0000\n",
      "Epoch 85/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6704 - acc: 0.8730 - val_loss: 2.2244 - val_acc: 1.0000\n",
      "Epoch 86/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5970 - acc: 0.8413 - val_loss: 2.2035 - val_acc: 1.0000\n",
      "Epoch 87/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5930 - acc: 0.8254 - val_loss: 2.1885 - val_acc: 1.0000\n",
      "Epoch 88/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5426 - acc: 0.8730 - val_loss: 2.1741 - val_acc: 1.0000\n",
      "Epoch 89/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.6192 - acc: 0.8254 - val_loss: 2.1648 - val_acc: 1.0000\n",
      "Epoch 90/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5284 - acc: 0.9206 - val_loss: 2.1504 - val_acc: 1.0000\n",
      "Epoch 91/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5045 - acc: 0.8889 - val_loss: 2.1328 - val_acc: 1.0000\n",
      "Epoch 92/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5502 - acc: 0.8254 - val_loss: 2.1142 - val_acc: 1.0000\n",
      "Epoch 93/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5639 - acc: 0.8095 - val_loss: 2.0996 - val_acc: 1.0000\n",
      "Epoch 94/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5967 - acc: 0.7619 - val_loss: 2.0867 - val_acc: 1.0000\n",
      "Epoch 95/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.4340 - acc: 0.8571 - val_loss: 2.0758 - val_acc: 1.0000\n",
      "Epoch 96/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5687 - acc: 0.8095 - val_loss: 2.0629 - val_acc: 1.0000\n",
      "Epoch 97/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.5307 - acc: 0.8095 - val_loss: 2.0498 - val_acc: 1.0000\n",
      "Epoch 98/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.4719 - acc: 0.8571 - val_loss: 2.0349 - val_acc: 1.0000\n",
      "Epoch 99/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3206 - acc: 0.9048 - val_loss: 2.0206 - val_acc: 1.0000\n",
      "Epoch 100/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3603 - acc: 0.9048 - val_loss: 2.0077 - val_acc: 1.0000\n",
      "Epoch 101/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3746 - acc: 0.8889 - val_loss: 1.9970 - val_acc: 1.0000\n",
      "Epoch 102/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.4672 - acc: 0.8571 - val_loss: 1.9849 - val_acc: 1.0000\n",
      "Epoch 103/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3421 - acc: 0.9048 - val_loss: 1.9741 - val_acc: 1.0000\n",
      "Epoch 104/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2834 - acc: 0.9048 - val_loss: 1.9618 - val_acc: 1.0000\n",
      "Epoch 105/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2604 - acc: 0.9206 - val_loss: 1.9487 - val_acc: 1.0000\n",
      "Epoch 106/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2726 - acc: 0.8571 - val_loss: 1.9351 - val_acc: 1.0000\n",
      "Epoch 107/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3200 - acc: 0.9048 - val_loss: 1.9250 - val_acc: 1.0000\n",
      "Epoch 108/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3136 - acc: 0.9048 - val_loss: 1.9174 - val_acc: 1.0000\n",
      "Epoch 109/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.3193 - acc: 0.9048 - val_loss: 1.9076 - val_acc: 1.0000\n",
      "Epoch 110/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2024 - acc: 0.9524 - val_loss: 1.8958 - val_acc: 1.0000\n",
      "Epoch 111/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1795 - acc: 0.9048 - val_loss: 1.8837 - val_acc: 1.0000\n",
      "Epoch 112/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2016 - acc: 0.9048 - val_loss: 1.8732 - val_acc: 1.0000\n",
      "Epoch 113/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2747 - acc: 0.8730 - val_loss: 1.8633 - val_acc: 1.0000\n",
      "Epoch 114/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1531 - acc: 0.9048 - val_loss: 1.8550 - val_acc: 1.0000\n",
      "Epoch 115/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1666 - acc: 0.9683 - val_loss: 1.8463 - val_acc: 1.0000\n",
      "Epoch 116/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1569 - acc: 0.9365 - val_loss: 1.8381 - val_acc: 1.0000\n",
      "Epoch 117/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1936 - acc: 0.9206 - val_loss: 1.8303 - val_acc: 1.0000\n",
      "Epoch 118/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2640 - acc: 0.8571 - val_loss: 1.8226 - val_acc: 1.0000\n",
      "Epoch 119/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.2913 - acc: 0.8413 - val_loss: 1.8148 - val_acc: 1.0000\n",
      "Epoch 120/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0583 - acc: 0.9365 - val_loss: 1.8064 - val_acc: 1.0000\n",
      "Epoch 121/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1622 - acc: 0.9048 - val_loss: 1.7976 - val_acc: 1.0000\n",
      "Epoch 122/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1689 - acc: 0.8730 - val_loss: 1.7884 - val_acc: 1.0000\n",
      "Epoch 123/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0357 - acc: 0.9524 - val_loss: 1.7798 - val_acc: 1.0000\n",
      "Epoch 124/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1655 - acc: 0.8254 - val_loss: 1.7735 - val_acc: 1.0000\n",
      "Epoch 125/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0831 - acc: 0.9524 - val_loss: 1.7660 - val_acc: 1.0000\n",
      "Epoch 126/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0781 - acc: 0.9206 - val_loss: 1.7550 - val_acc: 1.0000\n",
      "Epoch 127/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1360 - acc: 0.8889 - val_loss: 1.7453 - val_acc: 1.0000\n",
      "Epoch 128/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1816 - acc: 0.8571 - val_loss: 1.7405 - val_acc: 1.0000\n",
      "Epoch 129/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0217 - acc: 0.9683 - val_loss: 1.7333 - val_acc: 1.0000\n",
      "Epoch 130/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1238 - acc: 0.9048 - val_loss: 1.7237 - val_acc: 1.0000\n",
      "Epoch 131/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0426 - acc: 0.9683 - val_loss: 1.7156 - val_acc: 1.0000\n",
      "Epoch 132/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.1483 - acc: 0.8413 - val_loss: 1.7083 - val_acc: 1.0000\n",
      "Epoch 133/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0311 - acc: 0.9048 - val_loss: 1.6996 - val_acc: 1.0000\n",
      "Epoch 134/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0012 - acc: 0.8730 - val_loss: 1.6924 - val_acc: 1.0000\n",
      "Epoch 135/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9453 - acc: 0.9365 - val_loss: 1.6847 - val_acc: 1.0000\n",
      "Epoch 136/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0198 - acc: 0.8889 - val_loss: 1.6781 - val_acc: 1.0000\n",
      "Epoch 137/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0167 - acc: 0.8571 - val_loss: 1.6703 - val_acc: 1.0000\n",
      "Epoch 138/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0200 - acc: 0.8889 - val_loss: 1.6623 - val_acc: 1.0000\n",
      "Epoch 139/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0400 - acc: 0.8889 - val_loss: 1.6568 - val_acc: 1.0000\n",
      "Epoch 140/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9190 - acc: 0.9524 - val_loss: 1.6481 - val_acc: 1.0000\n",
      "Epoch 141/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0348 - acc: 0.9048 - val_loss: 1.6412 - val_acc: 1.0000\n",
      "Epoch 142/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9194 - acc: 0.9048 - val_loss: 1.6354 - val_acc: 1.0000\n",
      "Epoch 143/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9494 - acc: 0.9365 - val_loss: 1.6297 - val_acc: 1.0000\n",
      "Epoch 144/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0325 - acc: 0.8730 - val_loss: 1.6240 - val_acc: 1.0000\n",
      "Epoch 145/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0218 - acc: 0.8730 - val_loss: 1.6193 - val_acc: 1.0000\n",
      "Epoch 146/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8499 - acc: 0.9365 - val_loss: 1.6138 - val_acc: 1.0000\n",
      "Epoch 147/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.9048 - val_loss: 1.6071 - val_acc: 1.0000\n",
      "Epoch 148/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 2.0064 - acc: 0.8730 - val_loss: 1.6013 - val_acc: 1.0000\n",
      "Epoch 149/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8571 - acc: 0.9841 - val_loss: 1.5953 - val_acc: 1.0000\n",
      "Epoch 150/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8068 - acc: 0.9524 - val_loss: 1.5864 - val_acc: 1.0000\n",
      "Epoch 151/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.9540 - acc: 0.8730 - val_loss: 1.5794 - val_acc: 1.0000\n",
      "Epoch 152/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8467 - acc: 0.9524 - val_loss: 1.5747 - val_acc: 1.0000\n",
      "Epoch 153/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8488 - acc: 0.9524 - val_loss: 1.5669 - val_acc: 1.0000\n",
      "Epoch 154/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8592 - acc: 0.9206 - val_loss: 1.5600 - val_acc: 1.0000\n",
      "Epoch 155/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8069 - acc: 0.9524 - val_loss: 1.5544 - val_acc: 1.0000\n",
      "Epoch 156/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8211 - acc: 0.9048 - val_loss: 1.5493 - val_acc: 1.0000\n",
      "Epoch 157/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7633 - acc: 0.9683 - val_loss: 1.5423 - val_acc: 1.0000\n",
      "Epoch 158/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8195 - acc: 0.9048 - val_loss: 1.5335 - val_acc: 1.0000\n",
      "Epoch 159/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8678 - acc: 0.9524 - val_loss: 1.5285 - val_acc: 1.0000\n",
      "Epoch 160/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7838 - acc: 0.9524 - val_loss: 1.5237 - val_acc: 1.0000\n",
      "Epoch 161/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7943 - acc: 0.9365 - val_loss: 1.5178 - val_acc: 1.0000\n",
      "Epoch 162/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7611 - acc: 0.9683 - val_loss: 1.5138 - val_acc: 1.0000\n",
      "Epoch 163/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7356 - acc: 0.9365 - val_loss: 1.5084 - val_acc: 1.0000\n",
      "Epoch 164/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7509 - acc: 0.9048 - val_loss: 1.5014 - val_acc: 1.0000\n",
      "Epoch 165/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6901 - acc: 0.9683 - val_loss: 1.4941 - val_acc: 1.0000\n",
      "Epoch 166/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7003 - acc: 0.9524 - val_loss: 1.4866 - val_acc: 1.0000\n",
      "Epoch 167/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7495 - acc: 0.9365 - val_loss: 1.4805 - val_acc: 1.0000\n",
      "Epoch 168/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.8012 - acc: 0.9365 - val_loss: 1.4776 - val_acc: 1.0000\n",
      "Epoch 169/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7245 - acc: 0.9683 - val_loss: 1.4742 - val_acc: 1.0000\n",
      "Epoch 170/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7636 - acc: 0.8889 - val_loss: 1.4693 - val_acc: 1.0000\n",
      "Epoch 171/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6470 - acc: 0.9841 - val_loss: 1.4624 - val_acc: 1.0000\n",
      "Epoch 172/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7266 - acc: 0.9365 - val_loss: 1.4570 - val_acc: 1.0000\n",
      "Epoch 173/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7299 - acc: 0.9524 - val_loss: 1.4525 - val_acc: 1.0000\n",
      "Epoch 174/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7920 - acc: 0.9048 - val_loss: 1.4489 - val_acc: 1.0000\n",
      "Epoch 175/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6745 - acc: 0.9365 - val_loss: 1.4444 - val_acc: 1.0000\n",
      "Epoch 176/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6928 - acc: 0.9683 - val_loss: 1.4379 - val_acc: 1.0000\n",
      "Epoch 177/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6326 - acc: 0.9683 - val_loss: 1.4321 - val_acc: 1.0000\n",
      "Epoch 178/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7254 - acc: 0.9206 - val_loss: 1.4273 - val_acc: 1.0000\n",
      "Epoch 179/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6902 - acc: 0.9048 - val_loss: 1.4244 - val_acc: 1.0000\n",
      "Epoch 180/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7394 - acc: 0.9206 - val_loss: 1.4208 - val_acc: 1.0000\n",
      "Epoch 181/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6734 - acc: 0.9206 - val_loss: 1.4166 - val_acc: 1.0000\n",
      "Epoch 182/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7913 - acc: 0.7937 - val_loss: 1.4143 - val_acc: 1.0000\n",
      "Epoch 183/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6681 - acc: 0.9365 - val_loss: 1.4124 - val_acc: 1.0000\n",
      "Epoch 184/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6753 - acc: 0.9206 - val_loss: 1.4077 - val_acc: 1.0000\n",
      "Epoch 185/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6103 - acc: 0.9524 - val_loss: 1.4010 - val_acc: 1.0000\n",
      "Epoch 186/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7218 - acc: 0.9206 - val_loss: 1.3938 - val_acc: 1.0000\n",
      "Epoch 187/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6305 - acc: 0.9524 - val_loss: 1.3883 - val_acc: 1.0000\n",
      "Epoch 188/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7079 - acc: 0.9048 - val_loss: 1.3852 - val_acc: 1.0000\n",
      "Epoch 189/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6797 - acc: 0.9048 - val_loss: 1.3836 - val_acc: 1.0000\n",
      "Epoch 190/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6465 - acc: 0.9206 - val_loss: 1.3790 - val_acc: 1.0000\n",
      "Epoch 191/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.7136 - acc: 0.9365 - val_loss: 1.3762 - val_acc: 1.0000\n",
      "Epoch 192/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5987 - acc: 0.9524 - val_loss: 1.3711 - val_acc: 1.0000\n",
      "Epoch 193/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6629 - acc: 0.9048 - val_loss: 1.3649 - val_acc: 1.0000\n",
      "Epoch 194/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5704 - acc: 0.9524 - val_loss: 1.3586 - val_acc: 1.0000\n",
      "Epoch 195/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6236 - acc: 0.9524 - val_loss: 1.3535 - val_acc: 1.0000\n",
      "Epoch 196/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6504 - acc: 0.9365 - val_loss: 1.3504 - val_acc: 1.0000\n",
      "Epoch 197/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6279 - acc: 0.9365 - val_loss: 1.3489 - val_acc: 1.0000\n",
      "Epoch 198/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5833 - acc: 0.9206 - val_loss: 1.3453 - val_acc: 1.0000\n",
      "Epoch 199/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5549 - acc: 0.9365 - val_loss: 1.3415 - val_acc: 1.0000\n",
      "Epoch 200/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6002 - acc: 0.9524 - val_loss: 1.3372 - val_acc: 1.0000\n",
      "Epoch 201/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6015 - acc: 0.9206 - val_loss: 1.3341 - val_acc: 1.0000\n",
      "Epoch 202/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5558 - acc: 0.9683 - val_loss: 1.3280 - val_acc: 1.0000\n",
      "Epoch 203/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6523 - acc: 0.9048 - val_loss: 1.3253 - val_acc: 1.0000\n",
      "Epoch 204/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.6161 - acc: 0.8889 - val_loss: 1.3238 - val_acc: 1.0000\n",
      "Epoch 205/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5337 - acc: 0.9524 - val_loss: 1.3184 - val_acc: 1.0000\n",
      "Epoch 206/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5704 - acc: 0.9206 - val_loss: 1.3138 - val_acc: 1.0000\n",
      "Epoch 207/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5260 - acc: 0.9365 - val_loss: 1.3105 - val_acc: 1.0000\n",
      "Epoch 208/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5212 - acc: 0.9524 - val_loss: 1.3055 - val_acc: 1.0000\n",
      "Epoch 209/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4706 - acc: 0.9683 - val_loss: 1.2995 - val_acc: 1.0000\n",
      "Epoch 210/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5920 - acc: 0.9206 - val_loss: 1.2948 - val_acc: 1.0000\n",
      "Epoch 211/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5025 - acc: 0.9683 - val_loss: 1.2926 - val_acc: 1.0000\n",
      "Epoch 212/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4903 - acc: 0.9524 - val_loss: 1.2878 - val_acc: 1.0000\n",
      "Epoch 213/1500\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4385 - acc: 1.000 - 0s 3ms/step - loss: 1.4858 - acc: 0.9683 - val_loss: 1.2837 - val_acc: 1.0000\n",
      "Epoch 214/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5063 - acc: 0.9365 - val_loss: 1.2801 - val_acc: 1.0000\n",
      "Epoch 215/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5985 - acc: 0.9365 - val_loss: 1.2783 - val_acc: 1.0000\n",
      "Epoch 216/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4759 - acc: 0.9524 - val_loss: 1.2760 - val_acc: 1.0000\n",
      "Epoch 217/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4786 - acc: 0.9524 - val_loss: 1.2712 - val_acc: 1.0000\n",
      "Epoch 218/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5915 - acc: 0.8889 - val_loss: 1.2683 - val_acc: 1.0000\n",
      "Epoch 219/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4979 - acc: 0.9683 - val_loss: 1.2660 - val_acc: 1.0000\n",
      "Epoch 220/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5099 - acc: 0.9206 - val_loss: 1.2616 - val_acc: 1.0000\n",
      "Epoch 221/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4738 - acc: 0.9524 - val_loss: 1.2581 - val_acc: 1.0000\n",
      "Epoch 222/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4333 - acc: 0.9683 - val_loss: 1.2535 - val_acc: 1.0000\n",
      "Epoch 223/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5035 - acc: 0.9206 - val_loss: 1.2480 - val_acc: 1.0000\n",
      "Epoch 224/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4925 - acc: 0.9524 - val_loss: 1.2471 - val_acc: 1.0000\n",
      "Epoch 225/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4714 - acc: 0.9841 - val_loss: 1.2461 - val_acc: 1.0000\n",
      "Epoch 226/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4634 - acc: 0.9048 - val_loss: 1.2415 - val_acc: 1.0000\n",
      "Epoch 227/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5316 - acc: 0.8730 - val_loss: 1.2395 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4338 - acc: 0.9841 - val_loss: 1.2373 - val_acc: 1.0000\n",
      "Epoch 229/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4947 - acc: 0.9365 - val_loss: 1.2332 - val_acc: 1.0000\n",
      "Epoch 230/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4864 - acc: 0.9206 - val_loss: 1.2309 - val_acc: 1.0000\n",
      "Epoch 231/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4725 - acc: 0.9524 - val_loss: 1.2277 - val_acc: 1.0000\n",
      "Epoch 232/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4211 - acc: 0.9683 - val_loss: 1.2231 - val_acc: 1.0000\n",
      "Epoch 233/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4427 - acc: 0.9206 - val_loss: 1.2210 - val_acc: 1.0000\n",
      "Epoch 234/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3924 - acc: 0.9683 - val_loss: 1.2177 - val_acc: 1.0000\n",
      "Epoch 235/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4635 - acc: 0.9048 - val_loss: 1.2145 - val_acc: 1.0000\n",
      "Epoch 236/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4245 - acc: 0.9683 - val_loss: 1.2101 - val_acc: 1.0000\n",
      "Epoch 237/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4232 - acc: 0.9841 - val_loss: 1.2058 - val_acc: 1.0000\n",
      "Epoch 238/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4240 - acc: 0.9365 - val_loss: 1.2031 - val_acc: 1.0000\n",
      "Epoch 239/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4655 - acc: 0.9365 - val_loss: 1.2014 - val_acc: 1.0000\n",
      "Epoch 240/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3910 - acc: 0.9841 - val_loss: 1.2010 - val_acc: 1.0000\n",
      "Epoch 241/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4902 - acc: 0.9048 - val_loss: 1.1986 - val_acc: 1.0000\n",
      "Epoch 242/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4793 - acc: 0.9365 - val_loss: 1.1974 - val_acc: 1.0000\n",
      "Epoch 243/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4444 - acc: 0.9841 - val_loss: 1.1953 - val_acc: 1.0000\n",
      "Epoch 244/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4226 - acc: 0.9524 - val_loss: 1.1913 - val_acc: 1.0000\n",
      "Epoch 245/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4709 - acc: 0.9365 - val_loss: 1.1876 - val_acc: 1.0000\n",
      "Epoch 246/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3982 - acc: 0.9524 - val_loss: 1.1869 - val_acc: 1.0000\n",
      "Epoch 247/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4007 - acc: 0.9683 - val_loss: 1.1833 - val_acc: 1.0000\n",
      "Epoch 248/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3768 - acc: 0.9524 - val_loss: 1.1831 - val_acc: 1.0000\n",
      "Epoch 249/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3593 - acc: 0.9841 - val_loss: 1.1797 - val_acc: 1.0000\n",
      "Epoch 250/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3846 - acc: 0.9524 - val_loss: 1.1758 - val_acc: 1.0000\n",
      "Epoch 251/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3873 - acc: 0.9524 - val_loss: 1.1738 - val_acc: 1.0000\n",
      "Epoch 252/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4185 - acc: 0.9206 - val_loss: 1.1724 - val_acc: 1.0000\n",
      "Epoch 253/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3272 - acc: 0.9841 - val_loss: 1.1679 - val_acc: 1.0000\n",
      "Epoch 254/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3501 - acc: 0.9841 - val_loss: 1.1632 - val_acc: 1.0000\n",
      "Epoch 255/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3656 - acc: 0.9841 - val_loss: 1.1599 - val_acc: 1.0000\n",
      "Epoch 256/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4472 - acc: 0.9048 - val_loss: 1.1588 - val_acc: 1.0000\n",
      "Epoch 257/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3888 - acc: 0.9524 - val_loss: 1.1602 - val_acc: 1.0000\n",
      "Epoch 258/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3265 - acc: 0.9524 - val_loss: 1.1573 - val_acc: 1.0000\n",
      "Epoch 259/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4408 - acc: 0.9365 - val_loss: 1.1559 - val_acc: 1.0000\n",
      "Epoch 260/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3975 - acc: 0.9206 - val_loss: 1.1535 - val_acc: 1.0000\n",
      "Epoch 261/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3603 - acc: 0.9365 - val_loss: 1.1500 - val_acc: 1.0000\n",
      "Epoch 262/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3347 - acc: 0.9524 - val_loss: 1.1478 - val_acc: 1.0000\n",
      "Epoch 263/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3788 - acc: 0.9524 - val_loss: 1.1462 - val_acc: 1.0000\n",
      "Epoch 264/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4162 - acc: 0.9524 - val_loss: 1.1453 - val_acc: 1.0000\n",
      "Epoch 265/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3866 - acc: 0.9206 - val_loss: 1.1440 - val_acc: 1.0000\n",
      "Epoch 266/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3094 - acc: 0.9683 - val_loss: 1.1409 - val_acc: 1.0000\n",
      "Epoch 267/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3626 - acc: 0.9365 - val_loss: 1.1374 - val_acc: 1.0000\n",
      "Epoch 268/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2922 - acc: 0.9683 - val_loss: 1.1332 - val_acc: 1.0000\n",
      "Epoch 269/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3285 - acc: 0.9841 - val_loss: 1.1288 - val_acc: 1.0000\n",
      "Epoch 270/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3962 - acc: 0.9206 - val_loss: 1.1286 - val_acc: 1.0000\n",
      "Epoch 271/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2743 - acc: 0.9683 - val_loss: 1.1263 - val_acc: 1.0000\n",
      "Epoch 272/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3078 - acc: 0.9841 - val_loss: 1.1231 - val_acc: 1.0000\n",
      "Epoch 273/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2588 - acc: 1.0000 - val_loss: 1.1203 - val_acc: 1.0000\n",
      "Epoch 274/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2591 - acc: 0.9683 - val_loss: 1.1171 - val_acc: 1.0000\n",
      "Epoch 275/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3369 - acc: 0.9365 - val_loss: 1.1155 - val_acc: 1.0000\n",
      "Epoch 276/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2612 - acc: 0.9841 - val_loss: 1.1129 - val_acc: 1.0000\n",
      "Epoch 277/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2747 - acc: 0.9524 - val_loss: 1.1092 - val_acc: 1.0000\n",
      "Epoch 278/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2093 - acc: 1.0000 - val_loss: 1.1067 - val_acc: 1.0000\n",
      "Epoch 279/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3451 - acc: 0.9683 - val_loss: 1.1054 - val_acc: 1.0000\n",
      "Epoch 280/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2912 - acc: 0.9683 - val_loss: 1.1039 - val_acc: 1.0000\n",
      "Epoch 281/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2920 - acc: 0.9524 - val_loss: 1.1014 - val_acc: 1.0000\n",
      "Epoch 282/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3095 - acc: 0.9206 - val_loss: 1.1020 - val_acc: 1.0000\n",
      "Epoch 283/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3015 - acc: 1.0000 - val_loss: 1.1028 - val_acc: 1.0000\n",
      "Epoch 284/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2608 - acc: 0.9841 - val_loss: 1.0998 - val_acc: 1.0000\n",
      "Epoch 285/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2705 - acc: 0.9841 - val_loss: 1.0961 - val_acc: 1.0000\n",
      "Epoch 286/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2061 - acc: 0.9841 - val_loss: 1.0923 - val_acc: 1.0000\n",
      "Epoch 287/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3337 - acc: 0.9524 - val_loss: 1.0910 - val_acc: 1.0000\n",
      "Epoch 288/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2794 - acc: 0.9683 - val_loss: 1.0907 - val_acc: 1.0000\n",
      "Epoch 289/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2191 - acc: 0.9683 - val_loss: 1.0880 - val_acc: 1.0000\n",
      "Epoch 290/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2396 - acc: 0.9683 - val_loss: 1.0850 - val_acc: 1.0000\n",
      "Epoch 291/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2858 - acc: 0.9206 - val_loss: 1.0836 - val_acc: 1.0000\n",
      "Epoch 292/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3046 - acc: 0.9683 - val_loss: 1.0824 - val_acc: 1.0000\n",
      "Epoch 293/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3450 - acc: 0.9206 - val_loss: 1.0817 - val_acc: 1.0000\n",
      "Epoch 294/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4149 - acc: 0.9206 - val_loss: 1.0844 - val_acc: 1.0000\n",
      "Epoch 295/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2203 - acc: 1.0000 - val_loss: 1.0824 - val_acc: 1.0000\n",
      "Epoch 296/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2249 - acc: 1.0000 - val_loss: 1.0779 - val_acc: 1.0000\n",
      "Epoch 297/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3230 - acc: 0.9524 - val_loss: 1.0750 - val_acc: 1.0000\n",
      "Epoch 298/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2547 - acc: 0.9841 - val_loss: 1.0730 - val_acc: 1.0000\n",
      "Epoch 299/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1959 - acc: 0.9841 - val_loss: 1.0693 - val_acc: 1.0000\n",
      "Epoch 300/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2691 - acc: 0.9365 - val_loss: 1.0671 - val_acc: 1.0000\n",
      "Epoch 301/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2598 - acc: 0.9683 - val_loss: 1.0652 - val_acc: 1.0000\n",
      "Epoch 302/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2872 - acc: 0.9683 - val_loss: 1.0644 - val_acc: 1.0000\n",
      "Epoch 303/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2461 - acc: 0.9683 - val_loss: 1.0623 - val_acc: 1.0000\n",
      "Epoch 304/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1874 - acc: 0.9683 - val_loss: 1.0595 - val_acc: 1.0000\n",
      "Epoch 305/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1577 - acc: 1.0000 - val_loss: 1.0567 - val_acc: 1.0000\n",
      "Epoch 306/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2579 - acc: 0.9683 - val_loss: 1.0559 - val_acc: 1.0000\n",
      "Epoch 307/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2870 - acc: 0.8889 - val_loss: 1.0543 - val_acc: 1.0000\n",
      "Epoch 308/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2379 - acc: 0.9365 - val_loss: 1.0541 - val_acc: 1.0000\n",
      "Epoch 309/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2217 - acc: 0.9683 - val_loss: 1.0507 - val_acc: 1.0000\n",
      "Epoch 310/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1822 - acc: 0.9683 - val_loss: 1.0486 - val_acc: 1.0000\n",
      "Epoch 311/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2467 - acc: 0.9683 - val_loss: 1.0461 - val_acc: 1.0000\n",
      "Epoch 312/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2036 - acc: 0.9683 - val_loss: 1.0450 - val_acc: 1.0000\n",
      "Epoch 313/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2479 - acc: 0.9524 - val_loss: 1.0463 - val_acc: 1.0000\n",
      "Epoch 314/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.3783 - acc: 0.9206 - val_loss: 1.0464 - val_acc: 1.0000\n",
      "Epoch 315/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2078 - acc: 0.9683 - val_loss: 1.0451 - val_acc: 1.0000\n",
      "Epoch 316/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2322 - acc: 0.9683 - val_loss: 1.0417 - val_acc: 1.0000\n",
      "Epoch 317/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1962 - acc: 0.9841 - val_loss: 1.0398 - val_acc: 1.0000\n",
      "Epoch 318/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2150 - acc: 0.9524 - val_loss: 1.0368 - val_acc: 1.0000\n",
      "Epoch 319/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1767 - acc: 0.9683 - val_loss: 1.0339 - val_acc: 1.0000\n",
      "Epoch 320/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1653 - acc: 0.9841 - val_loss: 1.0319 - val_acc: 1.0000\n",
      "Epoch 321/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2047 - acc: 0.9683 - val_loss: 1.0302 - val_acc: 1.0000\n",
      "Epoch 322/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2270 - acc: 0.9683 - val_loss: 1.0310 - val_acc: 1.0000\n",
      "Epoch 323/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1960 - acc: 0.9841 - val_loss: 1.0307 - val_acc: 1.0000\n",
      "Epoch 324/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2541 - acc: 0.9683 - val_loss: 1.0314 - val_acc: 1.0000\n",
      "Epoch 325/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2828 - acc: 0.9206 - val_loss: 1.0338 - val_acc: 1.0000\n",
      "Epoch 326/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2082 - acc: 0.9841 - val_loss: 1.0332 - val_acc: 1.0000\n",
      "Epoch 327/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2306 - acc: 0.9841 - val_loss: 1.0296 - val_acc: 1.0000\n",
      "Epoch 328/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1998 - acc: 0.9683 - val_loss: 1.0264 - val_acc: 1.0000\n",
      "Epoch 329/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2316 - acc: 0.9206 - val_loss: 1.0256 - val_acc: 1.0000\n",
      "Epoch 330/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1645 - acc: 0.9683 - val_loss: 1.0236 - val_acc: 1.0000\n",
      "Epoch 331/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1970 - acc: 0.9683 - val_loss: 1.0222 - val_acc: 1.0000\n",
      "Epoch 332/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1903 - acc: 0.9683 - val_loss: 1.0207 - val_acc: 1.0000\n",
      "Epoch 333/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2090 - acc: 0.9524 - val_loss: 1.0193 - val_acc: 1.0000\n",
      "Epoch 334/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2024 - acc: 0.9841 - val_loss: 1.0190 - val_acc: 1.0000\n",
      "Epoch 335/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1707 - acc: 0.9841 - val_loss: 1.0176 - val_acc: 1.0000\n",
      "Epoch 336/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2586 - acc: 0.9524 - val_loss: 1.0152 - val_acc: 1.0000\n",
      "Epoch 337/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2494 - acc: 0.9206 - val_loss: 1.0150 - val_acc: 1.0000\n",
      "Epoch 338/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2620 - acc: 0.9524 - val_loss: 1.0157 - val_acc: 1.0000\n",
      "Epoch 339/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2551 - acc: 0.9524 - val_loss: 1.0159 - val_acc: 1.0000\n",
      "Epoch 340/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1658 - acc: 0.9683 - val_loss: 1.0146 - val_acc: 1.0000\n",
      "Epoch 341/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2149 - acc: 0.9365 - val_loss: 1.0127 - val_acc: 1.0000\n",
      "Epoch 342/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1755 - acc: 0.9524 - val_loss: 1.0111 - val_acc: 1.0000\n",
      "Epoch 343/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1420 - acc: 0.9841 - val_loss: 1.0068 - val_acc: 1.0000\n",
      "Epoch 344/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1584 - acc: 0.9841 - val_loss: 1.0033 - val_acc: 1.0000\n",
      "Epoch 345/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1851 - acc: 0.9524 - val_loss: 1.0018 - val_acc: 1.0000\n",
      "Epoch 346/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2008 - acc: 0.9841 - val_loss: 1.0016 - val_acc: 1.0000\n",
      "Epoch 347/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2397 - acc: 0.9206 - val_loss: 1.0027 - val_acc: 1.0000\n",
      "Epoch 348/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2093 - acc: 0.9683 - val_loss: 1.0046 - val_acc: 1.0000\n",
      "Epoch 349/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1572 - acc: 0.9841 - val_loss: 1.0033 - val_acc: 1.0000\n",
      "Epoch 350/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1813 - acc: 0.9524 - val_loss: 0.9993 - val_acc: 1.0000\n",
      "Epoch 351/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1293 - acc: 0.9841 - val_loss: 0.9958 - val_acc: 1.0000\n",
      "Epoch 352/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1473 - acc: 0.9683 - val_loss: 0.9930 - val_acc: 1.0000\n",
      "Epoch 353/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2050 - acc: 0.9365 - val_loss: 0.9939 - val_acc: 1.0000\n",
      "Epoch 354/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2008 - acc: 0.9365 - val_loss: 0.9929 - val_acc: 1.0000\n",
      "Epoch 355/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1382 - acc: 0.9841 - val_loss: 0.9907 - val_acc: 1.0000\n",
      "Epoch 356/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1911 - acc: 0.9683 - val_loss: 0.9875 - val_acc: 1.0000\n",
      "Epoch 357/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1974 - acc: 0.9206 - val_loss: 0.9881 - val_acc: 1.0000\n",
      "Epoch 358/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1009 - acc: 0.9524 - val_loss: 0.9905 - val_acc: 1.0000\n",
      "Epoch 359/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1074 - acc: 0.9841 - val_loss: 0.9876 - val_acc: 1.0000\n",
      "Epoch 360/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1362 - acc: 0.9841 - val_loss: 0.9843 - val_acc: 1.0000\n",
      "Epoch 361/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2130 - acc: 0.9683 - val_loss: 0.9859 - val_acc: 1.0000\n",
      "Epoch 362/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1573 - acc: 0.9683 - val_loss: 0.9834 - val_acc: 1.0000\n",
      "Epoch 363/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1988 - acc: 0.9683 - val_loss: 0.9821 - val_acc: 1.0000\n",
      "Epoch 364/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1131 - acc: 0.9524 - val_loss: 0.9843 - val_acc: 1.0000\n",
      "Epoch 365/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1633 - acc: 0.9683 - val_loss: 0.9817 - val_acc: 1.0000\n",
      "Epoch 366/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1633 - acc: 0.9524 - val_loss: 0.9814 - val_acc: 1.0000\n",
      "Epoch 367/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2086 - acc: 0.9524 - val_loss: 0.9815 - val_acc: 1.0000\n",
      "Epoch 368/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1371 - acc: 0.9841 - val_loss: 0.9784 - val_acc: 1.0000\n",
      "Epoch 369/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1201 - acc: 0.9841 - val_loss: 0.9749 - val_acc: 1.0000\n",
      "Epoch 370/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1274 - acc: 0.9841 - val_loss: 0.9724 - val_acc: 1.0000\n",
      "Epoch 371/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1354 - acc: 0.9683 - val_loss: 0.9717 - val_acc: 1.0000\n",
      "Epoch 372/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1620 - acc: 0.9683 - val_loss: 0.9714 - val_acc: 1.0000\n",
      "Epoch 373/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1376 - acc: 0.9683 - val_loss: 0.9715 - val_acc: 1.0000\n",
      "Epoch 374/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1215 - acc: 0.9683 - val_loss: 0.9699 - val_acc: 1.0000\n",
      "Epoch 375/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1503 - acc: 0.9683 - val_loss: 0.9699 - val_acc: 1.0000\n",
      "Epoch 376/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0949 - acc: 0.9841 - val_loss: 0.9690 - val_acc: 1.0000\n",
      "Epoch 377/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2168 - acc: 0.9365 - val_loss: 0.9687 - val_acc: 1.0000\n",
      "Epoch 378/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1425 - acc: 0.9683 - val_loss: 0.9688 - val_acc: 1.0000\n",
      "Epoch 379/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0541 - acc: 1.0000 - val_loss: 0.9663 - val_acc: 1.0000\n",
      "Epoch 380/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1830 - acc: 0.9524 - val_loss: 0.9636 - val_acc: 1.0000\n",
      "Epoch 381/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2292 - acc: 0.9365 - val_loss: 0.9662 - val_acc: 1.0000\n",
      "Epoch 382/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0601 - acc: 1.0000 - val_loss: 0.9661 - val_acc: 1.0000\n",
      "Epoch 383/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1781 - acc: 1.0000 - val_loss: 0.9634 - val_acc: 1.0000\n",
      "Epoch 384/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1202 - acc: 0.9683 - val_loss: 0.9619 - val_acc: 1.0000\n",
      "Epoch 385/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0868 - acc: 0.9841 - val_loss: 0.9602 - val_acc: 1.0000\n",
      "Epoch 386/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1031 - acc: 0.9683 - val_loss: 0.9577 - val_acc: 1.0000\n",
      "Epoch 387/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1361 - acc: 0.9683 - val_loss: 0.9567 - val_acc: 1.0000\n",
      "Epoch 388/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0988 - acc: 0.9841 - val_loss: 0.9548 - val_acc: 1.0000\n",
      "Epoch 389/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1381 - acc: 0.9683 - val_loss: 0.9532 - val_acc: 1.0000\n",
      "Epoch 390/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0705 - acc: 0.9841 - val_loss: 0.9514 - val_acc: 1.0000\n",
      "Epoch 391/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1415 - acc: 0.9206 - val_loss: 0.9511 - val_acc: 1.0000\n",
      "Epoch 392/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0822 - acc: 0.9683 - val_loss: 0.9510 - val_acc: 1.0000\n",
      "Epoch 393/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1764 - acc: 0.9365 - val_loss: 0.9508 - val_acc: 1.0000\n",
      "Epoch 394/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1113 - acc: 0.9841 - val_loss: 0.9522 - val_acc: 1.0000\n",
      "Epoch 395/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2311 - acc: 0.9365 - val_loss: 0.9517 - val_acc: 1.0000\n",
      "Epoch 396/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1234 - acc: 0.9524 - val_loss: 0.9516 - val_acc: 1.0000\n",
      "Epoch 397/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1399 - acc: 0.9524 - val_loss: 0.9494 - val_acc: 1.0000\n",
      "Epoch 398/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0924 - acc: 0.9524 - val_loss: 0.9454 - val_acc: 1.0000\n",
      "Epoch 399/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1675 - acc: 0.9524 - val_loss: 0.9435 - val_acc: 1.0000\n",
      "Epoch 400/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0638 - acc: 0.9841 - val_loss: 0.9437 - val_acc: 1.0000\n",
      "Epoch 401/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0465 - acc: 0.9841 - val_loss: 0.9410 - val_acc: 1.0000\n",
      "Epoch 402/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0520 - acc: 0.9683 - val_loss: 0.9396 - val_acc: 1.0000\n",
      "Epoch 403/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0582 - acc: 1.0000 - val_loss: 0.9374 - val_acc: 1.0000\n",
      "Epoch 404/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1301 - acc: 0.9683 - val_loss: 0.9351 - val_acc: 1.0000\n",
      "Epoch 405/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1257 - acc: 0.9524 - val_loss: 0.9365 - val_acc: 1.0000\n",
      "Epoch 406/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0815 - acc: 0.9683 - val_loss: 0.9362 - val_acc: 1.0000\n",
      "Epoch 407/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1061 - acc: 0.9524 - val_loss: 0.9364 - val_acc: 1.0000\n",
      "Epoch 408/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1104 - acc: 0.9841 - val_loss: 0.9373 - val_acc: 1.0000\n",
      "Epoch 409/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1382 - acc: 0.9683 - val_loss: 0.9367 - val_acc: 1.0000\n",
      "Epoch 410/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0830 - acc: 1.0000 - val_loss: 0.9344 - val_acc: 1.0000\n",
      "Epoch 411/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0579 - acc: 1.0000 - val_loss: 0.9310 - val_acc: 1.0000\n",
      "Epoch 412/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1070 - acc: 0.9841 - val_loss: 0.9306 - val_acc: 1.0000\n",
      "Epoch 413/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0553 - acc: 0.9841 - val_loss: 0.9300 - val_acc: 1.0000\n",
      "Epoch 414/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0825 - acc: 0.9365 - val_loss: 0.9287 - val_acc: 1.0000\n",
      "Epoch 415/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0440 - acc: 0.9841 - val_loss: 0.9278 - val_acc: 1.0000\n",
      "Epoch 416/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0825 - acc: 0.9524 - val_loss: 0.9259 - val_acc: 1.0000\n",
      "Epoch 417/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0864 - acc: 0.9524 - val_loss: 0.9236 - val_acc: 1.0000\n",
      "Epoch 418/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0364 - acc: 0.9683 - val_loss: 0.9236 - val_acc: 1.0000\n",
      "Epoch 419/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0401 - acc: 1.0000 - val_loss: 0.9211 - val_acc: 1.0000\n",
      "Epoch 420/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0979 - acc: 0.9683 - val_loss: 0.9215 - val_acc: 1.0000\n",
      "Epoch 421/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.2116 - acc: 0.8889 - val_loss: 0.9267 - val_acc: 1.0000\n",
      "Epoch 422/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0788 - acc: 0.9524 - val_loss: 0.9268 - val_acc: 1.0000\n",
      "Epoch 423/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0025 - acc: 1.0000 - val_loss: 0.9244 - val_acc: 1.0000\n",
      "Epoch 424/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0500 - acc: 0.9841 - val_loss: 0.9202 - val_acc: 1.0000\n",
      "Epoch 425/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0473 - acc: 0.9841 - val_loss: 0.9171 - val_acc: 1.0000\n",
      "Epoch 426/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0841 - acc: 0.9524 - val_loss: 0.9161 - val_acc: 1.0000\n",
      "Epoch 427/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0350 - acc: 0.9683 - val_loss: 0.9142 - val_acc: 1.0000\n",
      "Epoch 428/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0598 - acc: 0.9683 - val_loss: 0.9132 - val_acc: 1.0000\n",
      "Epoch 429/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0846 - acc: 0.9365 - val_loss: 0.9143 - val_acc: 1.0000\n",
      "Epoch 430/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0139 - acc: 0.9841 - val_loss: 0.9156 - val_acc: 1.0000\n",
      "Epoch 431/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0998 - acc: 0.9206 - val_loss: 0.9133 - val_acc: 1.0000\n",
      "Epoch 432/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1105 - acc: 0.9365 - val_loss: 0.9167 - val_acc: 1.0000\n",
      "Epoch 433/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0588 - acc: 0.9683 - val_loss: 0.9149 - val_acc: 1.0000\n",
      "Epoch 434/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1175 - acc: 0.9683 - val_loss: 0.9139 - val_acc: 1.0000\n",
      "Epoch 435/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1262 - acc: 0.9206 - val_loss: 0.9127 - val_acc: 1.0000\n",
      "Epoch 436/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0405 - acc: 0.9683 - val_loss: 0.9119 - val_acc: 1.0000\n",
      "Epoch 437/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1460 - acc: 0.9365 - val_loss: 0.9124 - val_acc: 1.0000\n",
      "Epoch 438/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0091 - acc: 0.9841 - val_loss: 0.9117 - val_acc: 1.0000\n",
      "Epoch 439/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0434 - acc: 0.9683 - val_loss: 0.9092 - val_acc: 1.0000\n",
      "Epoch 440/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0713 - acc: 0.9841 - val_loss: 0.9073 - val_acc: 1.0000\n",
      "Epoch 441/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0706 - acc: 0.9683 - val_loss: 0.9054 - val_acc: 1.0000\n",
      "Epoch 442/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9839 - acc: 1.0000 - val_loss: 0.9043 - val_acc: 1.0000\n",
      "Epoch 443/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0947 - acc: 0.9683 - val_loss: 0.9016 - val_acc: 1.0000\n",
      "Epoch 444/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1346 - acc: 0.9524 - val_loss: 0.9038 - val_acc: 1.0000\n",
      "Epoch 445/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0443 - acc: 1.0000 - val_loss: 0.9036 - val_acc: 1.0000\n",
      "Epoch 446/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0543 - acc: 0.9683 - val_loss: 0.9001 - val_acc: 1.0000\n",
      "Epoch 447/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9913 - acc: 0.9841 - val_loss: 0.8983 - val_acc: 1.0000\n",
      "Epoch 448/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0647 - acc: 0.9524 - val_loss: 0.8977 - val_acc: 1.0000\n",
      "Epoch 449/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0192 - acc: 0.9683 - val_loss: 0.9006 - val_acc: 1.0000\n",
      "Epoch 450/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0487 - acc: 0.9841 - val_loss: 0.9004 - val_acc: 1.0000\n",
      "Epoch 451/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0865 - acc: 0.9206 - val_loss: 0.8996 - val_acc: 1.0000\n",
      "Epoch 452/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1206 - acc: 0.9365 - val_loss: 0.8997 - val_acc: 1.0000\n",
      "Epoch 453/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0693 - acc: 0.9524 - val_loss: 0.9003 - val_acc: 1.0000\n",
      "Epoch 454/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0397 - acc: 0.9841 - val_loss: 0.8997 - val_acc: 1.0000\n",
      "Epoch 455/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0188 - acc: 1.0000 - val_loss: 0.8971 - val_acc: 1.0000\n",
      "Epoch 456/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1303 - acc: 0.9365 - val_loss: 0.8950 - val_acc: 1.0000\n",
      "Epoch 457/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0777 - acc: 0.9683 - val_loss: 0.9013 - val_acc: 1.0000\n",
      "Epoch 458/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0506 - acc: 0.9524 - val_loss: 0.9017 - val_acc: 1.0000\n",
      "Epoch 459/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0354 - acc: 0.9841 - val_loss: 0.8993 - val_acc: 1.0000\n",
      "Epoch 460/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1446 - acc: 0.9365 - val_loss: 0.8956 - val_acc: 1.0000\n",
      "Epoch 461/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0533 - acc: 0.9683 - val_loss: 0.8948 - val_acc: 1.0000\n",
      "Epoch 462/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0530 - acc: 0.9683 - val_loss: 0.8934 - val_acc: 1.0000\n",
      "Epoch 463/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0268 - acc: 0.9841 - val_loss: 0.8926 - val_acc: 1.0000\n",
      "Epoch 464/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0768 - acc: 0.9683 - val_loss: 0.8928 - val_acc: 1.0000\n",
      "Epoch 465/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9589 - acc: 0.9841 - val_loss: 0.8905 - val_acc: 1.0000\n",
      "Epoch 466/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0655 - acc: 0.9524 - val_loss: 0.8875 - val_acc: 1.0000\n",
      "Epoch 467/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1005 - acc: 0.9365 - val_loss: 0.8883 - val_acc: 1.0000\n",
      "Epoch 468/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9977 - acc: 0.9841 - val_loss: 0.8898 - val_acc: 1.0000\n",
      "Epoch 469/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0789 - acc: 0.9683 - val_loss: 0.8894 - val_acc: 1.0000\n",
      "Epoch 470/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0607 - acc: 0.9841 - val_loss: 0.8902 - val_acc: 1.0000\n",
      "Epoch 471/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0347 - acc: 0.9683 - val_loss: 0.8904 - val_acc: 1.0000\n",
      "Epoch 472/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9848 - acc: 0.9683 - val_loss: 0.8879 - val_acc: 1.0000\n",
      "Epoch 473/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9573 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 1.0000\n",
      "Epoch 474/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0025 - acc: 0.9683 - val_loss: 0.8787 - val_acc: 1.0000\n",
      "Epoch 475/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0105 - acc: 0.9841 - val_loss: 0.8769 - val_acc: 1.0000\n",
      "Epoch 476/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0126 - acc: 0.9841 - val_loss: 0.8773 - val_acc: 1.0000\n",
      "Epoch 477/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9853 - acc: 1.0000 - val_loss: 0.8757 - val_acc: 1.0000\n",
      "Epoch 478/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0215 - acc: 0.9841 - val_loss: 0.8733 - val_acc: 1.0000\n",
      "Epoch 479/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1092 - acc: 0.9206 - val_loss: 0.8757 - val_acc: 1.0000\n",
      "Epoch 480/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0567 - acc: 0.9683 - val_loss: 0.8824 - val_acc: 1.0000\n",
      "Epoch 481/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0266 - acc: 0.9683 - val_loss: 0.8819 - val_acc: 1.0000\n",
      "Epoch 482/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9725 - acc: 1.0000 - val_loss: 0.8787 - val_acc: 1.0000\n",
      "Epoch 483/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0723 - acc: 0.9524 - val_loss: 0.8771 - val_acc: 1.0000\n",
      "Epoch 484/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0137 - acc: 1.0000 - val_loss: 0.8764 - val_acc: 1.0000\n",
      "Epoch 485/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9956 - acc: 0.9841 - val_loss: 0.8756 - val_acc: 1.0000\n",
      "Epoch 486/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9808 - acc: 1.0000 - val_loss: 0.8742 - val_acc: 1.0000\n",
      "Epoch 487/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0168 - acc: 0.9841 - val_loss: 0.8723 - val_acc: 1.0000\n",
      "Epoch 488/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1038 - acc: 0.9683 - val_loss: 0.8711 - val_acc: 1.0000\n",
      "Epoch 489/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9979 - acc: 1.0000 - val_loss: 0.8718 - val_acc: 1.0000\n",
      "Epoch 490/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9855 - acc: 0.9841 - val_loss: 0.8700 - val_acc: 1.0000\n",
      "Epoch 491/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9552 - acc: 0.9841 - val_loss: 0.8678 - val_acc: 1.0000\n",
      "Epoch 492/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9366 - acc: 0.9841 - val_loss: 0.8647 - val_acc: 1.0000\n",
      "Epoch 493/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9570 - acc: 1.0000 - val_loss: 0.8613 - val_acc: 1.0000\n",
      "Epoch 494/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9629 - acc: 1.0000 - val_loss: 0.8598 - val_acc: 1.0000\n",
      "Epoch 495/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0523 - acc: 0.9524 - val_loss: 0.8619 - val_acc: 1.0000\n",
      "Epoch 496/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9991 - acc: 0.9841 - val_loss: 0.8612 - val_acc: 1.0000\n",
      "Epoch 497/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9619 - acc: 0.9841 - val_loss: 0.8602 - val_acc: 1.0000\n",
      "Epoch 498/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0068 - acc: 0.9841 - val_loss: 0.8604 - val_acc: 1.0000\n",
      "Epoch 499/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0451 - acc: 0.9524 - val_loss: 0.8629 - val_acc: 1.0000\n",
      "Epoch 500/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0139 - acc: 0.9524 - val_loss: 0.8643 - val_acc: 1.0000\n",
      "Epoch 501/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0299 - acc: 0.9524 - val_loss: 0.8645 - val_acc: 1.0000\n",
      "Epoch 502/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0976 - acc: 0.9206 - val_loss: 0.8661 - val_acc: 1.0000\n",
      "Epoch 503/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9466 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 1.0000\n",
      "Epoch 504/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9936 - acc: 0.9683 - val_loss: 0.8608 - val_acc: 1.0000\n",
      "Epoch 505/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9730 - acc: 0.9841 - val_loss: 0.8574 - val_acc: 1.0000\n",
      "Epoch 506/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0620 - acc: 0.9524 - val_loss: 0.8595 - val_acc: 1.0000\n",
      "Epoch 507/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0639 - acc: 0.9365 - val_loss: 0.8627 - val_acc: 1.0000\n",
      "Epoch 508/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0063 - acc: 0.9841 - val_loss: 0.8630 - val_acc: 1.0000\n",
      "Epoch 509/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9493 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 1.0000\n",
      "Epoch 510/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9516 - acc: 1.0000 - val_loss: 0.8567 - val_acc: 1.0000\n",
      "Epoch 511/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0117 - acc: 0.9365 - val_loss: 0.8574 - val_acc: 1.0000\n",
      "Epoch 512/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0665 - acc: 0.9365 - val_loss: 0.8622 - val_acc: 1.0000\n",
      "Epoch 513/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9798 - acc: 0.9683 - val_loss: 0.8630 - val_acc: 1.0000\n",
      "Epoch 514/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9926 - acc: 0.9841 - val_loss: 0.8626 - val_acc: 1.0000\n",
      "Epoch 515/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9838 - acc: 1.0000 - val_loss: 0.8596 - val_acc: 1.0000\n",
      "Epoch 516/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1111 - acc: 0.9365 - val_loss: 0.8584 - val_acc: 1.0000\n",
      "Epoch 517/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9954 - acc: 1.0000 - val_loss: 0.8601 - val_acc: 1.0000\n",
      "Epoch 518/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9954 - acc: 0.9683 - val_loss: 0.8584 - val_acc: 1.0000\n",
      "Epoch 519/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9653 - acc: 1.0000 - val_loss: 0.8554 - val_acc: 1.0000\n",
      "Epoch 520/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0187 - acc: 0.9683 - val_loss: 0.8545 - val_acc: 1.0000\n",
      "Epoch 521/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0131 - acc: 0.9683 - val_loss: 0.8545 - val_acc: 1.0000\n",
      "Epoch 522/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9413 - acc: 1.0000 - val_loss: 0.8532 - val_acc: 1.0000\n",
      "Epoch 523/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0300 - acc: 0.9524 - val_loss: 0.8543 - val_acc: 1.0000\n",
      "Epoch 524/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9737 - acc: 0.9683 - val_loss: 0.8544 - val_acc: 1.0000\n",
      "Epoch 525/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9646 - acc: 1.0000 - val_loss: 0.8520 - val_acc: 1.0000\n",
      "Epoch 526/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0007 - acc: 0.9524 - val_loss: 0.8489 - val_acc: 1.0000\n",
      "Epoch 527/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9864 - acc: 0.9841 - val_loss: 0.8469 - val_acc: 1.0000\n",
      "Epoch 528/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0036 - acc: 0.9524 - val_loss: 0.8464 - val_acc: 1.0000\n",
      "Epoch 529/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0001 - acc: 0.9683 - val_loss: 0.8460 - val_acc: 1.0000\n",
      "Epoch 530/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0162 - acc: 0.9524 - val_loss: 0.8482 - val_acc: 1.0000\n",
      "Epoch 531/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9930 - acc: 1.0000 - val_loss: 0.8483 - val_acc: 1.0000\n",
      "Epoch 532/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9822 - acc: 0.9841 - val_loss: 0.8465 - val_acc: 1.0000\n",
      "Epoch 533/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9876 - acc: 0.9683 - val_loss: 0.8477 - val_acc: 1.0000\n",
      "Epoch 534/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9882 - acc: 0.9841 - val_loss: 0.8477 - val_acc: 1.0000\n",
      "Epoch 535/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9517 - acc: 1.0000 - val_loss: 0.8441 - val_acc: 1.0000\n",
      "Epoch 536/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0227 - acc: 0.9683 - val_loss: 0.8422 - val_acc: 1.0000\n",
      "Epoch 537/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9234 - acc: 1.0000 - val_loss: 0.8415 - val_acc: 1.0000\n",
      "Epoch 538/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9520 - acc: 1.0000 - val_loss: 0.8390 - val_acc: 1.0000\n",
      "Epoch 539/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9871 - acc: 0.9841 - val_loss: 0.8379 - val_acc: 1.0000\n",
      "Epoch 540/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0332 - acc: 0.9365 - val_loss: 0.8392 - val_acc: 1.0000\n",
      "Epoch 541/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0282 - acc: 0.9206 - val_loss: 0.8416 - val_acc: 1.0000\n",
      "Epoch 542/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0404 - acc: 0.9524 - val_loss: 0.8430 - val_acc: 1.0000\n",
      "Epoch 543/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0724 - acc: 0.9524 - val_loss: 0.8447 - val_acc: 1.0000\n",
      "Epoch 544/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9964 - acc: 0.9524 - val_loss: 0.8444 - val_acc: 1.0000\n",
      "Epoch 545/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9495 - acc: 0.9841 - val_loss: 0.8424 - val_acc: 1.0000\n",
      "Epoch 546/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0093 - acc: 0.9683 - val_loss: 0.8397 - val_acc: 1.0000\n",
      "Epoch 547/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9442 - acc: 0.9841 - val_loss: 0.8391 - val_acc: 1.0000\n",
      "Epoch 548/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.1283 - acc: 0.9365 - val_loss: 0.8401 - val_acc: 1.0000\n",
      "Epoch 549/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9698 - acc: 0.9683 - val_loss: 0.8411 - val_acc: 1.0000\n",
      "Epoch 550/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9650 - acc: 0.9683 - val_loss: 0.8392 - val_acc: 1.0000\n",
      "Epoch 551/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9585 - acc: 0.9524 - val_loss: 0.8363 - val_acc: 1.0000\n",
      "Epoch 552/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9660 - acc: 1.0000 - val_loss: 0.8358 - val_acc: 1.0000\n",
      "Epoch 553/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8952 - acc: 1.0000 - val_loss: 0.8324 - val_acc: 1.0000\n",
      "Epoch 554/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9725 - acc: 0.9683 - val_loss: 0.8295 - val_acc: 1.0000\n",
      "Epoch 555/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0173 - acc: 0.9365 - val_loss: 0.8305 - val_acc: 1.0000\n",
      "Epoch 556/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9220 - acc: 0.9841 - val_loss: 0.8322 - val_acc: 1.0000\n",
      "Epoch 557/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9392 - acc: 1.0000 - val_loss: 0.8301 - val_acc: 1.0000\n",
      "Epoch 558/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9431 - acc: 1.0000 - val_loss: 0.8268 - val_acc: 1.0000\n",
      "Epoch 559/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9125 - acc: 0.9841 - val_loss: 0.8236 - val_acc: 1.0000\n",
      "Epoch 560/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0250 - acc: 0.9048 - val_loss: 0.8241 - val_acc: 1.0000\n",
      "Epoch 561/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9210 - acc: 1.0000 - val_loss: 0.8246 - val_acc: 1.0000\n",
      "Epoch 562/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9351 - acc: 0.9841 - val_loss: 0.8232 - val_acc: 1.0000\n",
      "Epoch 563/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9037 - acc: 1.0000 - val_loss: 0.8202 - val_acc: 1.0000\n",
      "Epoch 564/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9799 - acc: 0.9524 - val_loss: 0.8193 - val_acc: 1.0000\n",
      "Epoch 565/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9647 - acc: 0.9841 - val_loss: 0.8210 - val_acc: 1.0000\n",
      "Epoch 566/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9785 - acc: 0.9683 - val_loss: 0.8234 - val_acc: 1.0000\n",
      "Epoch 567/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9583 - acc: 0.9683 - val_loss: 0.8252 - val_acc: 1.0000\n",
      "Epoch 568/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9836 - acc: 0.9841 - val_loss: 0.8262 - val_acc: 1.0000\n",
      "Epoch 569/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9776 - acc: 0.9683 - val_loss: 0.8249 - val_acc: 1.0000\n",
      "Epoch 570/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9644 - acc: 0.9683 - val_loss: 0.8229 - val_acc: 1.0000\n",
      "Epoch 571/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0377 - acc: 0.9206 - val_loss: 0.8235 - val_acc: 1.0000\n",
      "Epoch 572/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9960 - acc: 0.9365 - val_loss: 0.8261 - val_acc: 1.0000\n",
      "Epoch 573/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0038 - acc: 0.9841 - val_loss: 0.8260 - val_acc: 1.0000\n",
      "Epoch 574/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0696 - acc: 0.9365 - val_loss: 0.8277 - val_acc: 1.0000\n",
      "Epoch 575/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9384 - acc: 0.9841 - val_loss: 0.8287 - val_acc: 1.0000\n",
      "Epoch 576/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9524 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 1.0000\n",
      "Epoch 577/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9518 - acc: 0.9683 - val_loss: 0.8254 - val_acc: 1.0000\n",
      "Epoch 578/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9181 - acc: 0.9683 - val_loss: 0.8254 - val_acc: 1.0000\n",
      "Epoch 579/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9992 - acc: 0.9524 - val_loss: 0.8242 - val_acc: 1.0000\n",
      "Epoch 580/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9505 - acc: 0.9841 - val_loss: 0.8248 - val_acc: 1.0000\n",
      "Epoch 581/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9896 - acc: 0.9683 - val_loss: 0.8237 - val_acc: 1.0000\n",
      "Epoch 582/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8953 - acc: 1.0000 - val_loss: 0.8225 - val_acc: 1.0000\n",
      "Epoch 583/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8796 - acc: 1.0000 - val_loss: 0.8190 - val_acc: 1.0000\n",
      "Epoch 584/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9603 - acc: 0.9841 - val_loss: 0.8150 - val_acc: 1.0000\n",
      "Epoch 585/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9296 - acc: 1.0000 - val_loss: 0.8148 - val_acc: 1.0000\n",
      "Epoch 586/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9831 - acc: 0.9683 - val_loss: 0.8159 - val_acc: 1.0000\n",
      "Epoch 587/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9488 - acc: 0.9841 - val_loss: 0.8183 - val_acc: 1.0000\n",
      "Epoch 588/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9604 - acc: 0.9683 - val_loss: 0.8175 - val_acc: 1.0000\n",
      "Epoch 589/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9128 - acc: 1.0000 - val_loss: 0.8148 - val_acc: 1.0000\n",
      "Epoch 590/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9294 - acc: 0.9683 - val_loss: 0.8119 - val_acc: 1.0000\n",
      "Epoch 591/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9374 - acc: 1.0000 - val_loss: 0.8105 - val_acc: 1.0000\n",
      "Epoch 592/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0310 - acc: 0.9524 - val_loss: 0.8131 - val_acc: 1.0000\n",
      "Epoch 593/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9063 - acc: 0.9841 - val_loss: 0.8134 - val_acc: 1.0000\n",
      "Epoch 594/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9178 - acc: 0.9683 - val_loss: 0.8115 - val_acc: 1.0000\n",
      "Epoch 595/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9234 - acc: 0.9683 - val_loss: 0.8101 - val_acc: 1.0000\n",
      "Epoch 596/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9442 - acc: 0.9365 - val_loss: 0.8075 - val_acc: 1.0000\n",
      "Epoch 597/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9159 - acc: 0.9841 - val_loss: 0.8057 - val_acc: 1.0000\n",
      "Epoch 598/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9487 - acc: 0.9841 - val_loss: 0.8076 - val_acc: 1.0000\n",
      "Epoch 599/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9771 - acc: 0.9683 - val_loss: 0.8077 - val_acc: 1.0000\n",
      "Epoch 600/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9339 - acc: 0.9683 - val_loss: 0.8059 - val_acc: 1.0000\n",
      "Epoch 601/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9863 - acc: 0.9524 - val_loss: 0.8075 - val_acc: 1.0000\n",
      "Epoch 602/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8828 - acc: 0.9841 - val_loss: 0.8064 - val_acc: 1.0000\n",
      "Epoch 603/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9101 - acc: 0.9683 - val_loss: 0.8026 - val_acc: 1.0000\n",
      "Epoch 604/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9115 - acc: 0.9841 - val_loss: 0.8004 - val_acc: 1.0000\n",
      "Epoch 605/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9553 - acc: 0.9524 - val_loss: 0.8041 - val_acc: 1.0000\n",
      "Epoch 606/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8710 - acc: 0.9841 - val_loss: 0.8041 - val_acc: 1.0000\n",
      "Epoch 607/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8939 - acc: 1.0000 - val_loss: 0.8005 - val_acc: 1.0000\n",
      "Epoch 608/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9306 - acc: 0.9524 - val_loss: 0.7973 - val_acc: 1.0000\n",
      "Epoch 609/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9152 - acc: 0.9841 - val_loss: 0.7979 - val_acc: 1.0000\n",
      "Epoch 610/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9457 - acc: 0.9683 - val_loss: 0.7985 - val_acc: 1.0000\n",
      "Epoch 611/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9217 - acc: 0.9841 - val_loss: 0.8003 - val_acc: 1.0000\n",
      "Epoch 612/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9689 - acc: 0.9683 - val_loss: 0.7999 - val_acc: 1.0000\n",
      "Epoch 613/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9001 - acc: 0.9841 - val_loss: 0.7992 - val_acc: 1.0000\n",
      "Epoch 614/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9247 - acc: 0.9524 - val_loss: 0.7974 - val_acc: 1.0000\n",
      "Epoch 615/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9263 - acc: 1.0000 - val_loss: 0.7975 - val_acc: 1.0000\n",
      "Epoch 616/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9105 - acc: 0.9841 - val_loss: 0.7982 - val_acc: 1.0000\n",
      "Epoch 617/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9710 - acc: 0.9683 - val_loss: 0.7976 - val_acc: 1.0000\n",
      "Epoch 618/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9648 - acc: 0.9683 - val_loss: 0.7990 - val_acc: 1.0000\n",
      "Epoch 619/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9507 - acc: 0.9841 - val_loss: 0.7991 - val_acc: 1.0000\n",
      "Epoch 620/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8783 - acc: 0.9841 - val_loss: 0.7971 - val_acc: 1.0000\n",
      "Epoch 621/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8989 - acc: 1.0000 - val_loss: 0.7947 - val_acc: 1.0000\n",
      "Epoch 622/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9421 - acc: 0.9683 - val_loss: 0.7948 - val_acc: 1.0000\n",
      "Epoch 623/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8970 - acc: 0.9841 - val_loss: 0.7943 - val_acc: 1.0000\n",
      "Epoch 624/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9070 - acc: 0.9841 - val_loss: 0.7917 - val_acc: 1.0000\n",
      "Epoch 625/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8877 - acc: 0.9683 - val_loss: 0.7894 - val_acc: 1.0000\n",
      "Epoch 626/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8955 - acc: 0.9524 - val_loss: 0.7884 - val_acc: 1.0000\n",
      "Epoch 627/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9102 - acc: 0.9841 - val_loss: 0.7866 - val_acc: 1.0000\n",
      "Epoch 628/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9483 - acc: 0.9524 - val_loss: 0.7874 - val_acc: 1.0000\n",
      "Epoch 629/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9140 - acc: 0.9841 - val_loss: 0.7864 - val_acc: 1.0000\n",
      "Epoch 630/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9042 - acc: 0.9683 - val_loss: 0.7867 - val_acc: 1.0000\n",
      "Epoch 631/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9086 - acc: 0.9683 - val_loss: 0.7850 - val_acc: 1.0000\n",
      "Epoch 632/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9666 - acc: 0.9524 - val_loss: 0.7849 - val_acc: 1.0000\n",
      "Epoch 633/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9095 - acc: 0.9841 - val_loss: 0.7866 - val_acc: 1.0000\n",
      "Epoch 634/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8594 - acc: 0.9841 - val_loss: 0.7858 - val_acc: 1.0000\n",
      "Epoch 635/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8930 - acc: 0.9841 - val_loss: 0.7864 - val_acc: 1.0000\n",
      "Epoch 636/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9126 - acc: 0.9841 - val_loss: 0.7875 - val_acc: 1.0000\n",
      "Epoch 637/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9594 - acc: 0.9841 - val_loss: 0.7899 - val_acc: 1.0000\n",
      "Epoch 638/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9514 - acc: 0.9365 - val_loss: 0.7887 - val_acc: 1.0000\n",
      "Epoch 639/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9225 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 1.0000\n",
      "Epoch 640/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9482 - acc: 0.9683 - val_loss: 0.7872 - val_acc: 1.0000\n",
      "Epoch 641/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9154 - acc: 0.9841 - val_loss: 0.7860 - val_acc: 1.0000\n",
      "Epoch 642/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8787 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 1.0000\n",
      "Epoch 643/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9092 - acc: 1.0000 - val_loss: 0.7836 - val_acc: 1.0000\n",
      "Epoch 644/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9364 - acc: 0.9683 - val_loss: 0.7856 - val_acc: 1.0000\n",
      "Epoch 645/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9332 - acc: 0.9683 - val_loss: 0.7885 - val_acc: 1.0000\n",
      "Epoch 646/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8905 - acc: 1.0000 - val_loss: 0.7867 - val_acc: 1.0000\n",
      "Epoch 647/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8811 - acc: 1.0000 - val_loss: 0.7836 - val_acc: 1.0000\n",
      "Epoch 648/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9457 - acc: 0.9524 - val_loss: 0.7824 - val_acc: 1.0000\n",
      "Epoch 649/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9468 - acc: 0.9524 - val_loss: 0.7829 - val_acc: 1.0000\n",
      "Epoch 650/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9386 - acc: 0.9841 - val_loss: 0.7863 - val_acc: 1.0000\n",
      "Epoch 651/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8940 - acc: 1.0000 - val_loss: 0.7849 - val_acc: 1.0000\n",
      "Epoch 652/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8507 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 1.0000\n",
      "Epoch 653/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8973 - acc: 0.9841 - val_loss: 0.7793 - val_acc: 1.0000\n",
      "Epoch 654/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8850 - acc: 0.9841 - val_loss: 0.7767 - val_acc: 1.0000\n",
      "Epoch 655/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8934 - acc: 1.0000 - val_loss: 0.7748 - val_acc: 1.0000\n",
      "Epoch 656/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8922 - acc: 0.9683 - val_loss: 0.7744 - val_acc: 1.0000\n",
      "Epoch 657/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9036 - acc: 1.0000 - val_loss: 0.7752 - val_acc: 1.0000\n",
      "Epoch 658/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8361 - acc: 1.0000 - val_loss: 0.7733 - val_acc: 1.0000\n",
      "Epoch 659/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8622 - acc: 1.0000 - val_loss: 0.7700 - val_acc: 1.0000\n",
      "Epoch 660/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9326 - acc: 0.9365 - val_loss: 0.7697 - val_acc: 1.0000\n",
      "Epoch 661/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8990 - acc: 0.9524 - val_loss: 0.7750 - val_acc: 1.0000\n",
      "Epoch 662/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9220 - acc: 0.9206 - val_loss: 0.7773 - val_acc: 1.0000\n",
      "Epoch 663/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8886 - acc: 1.0000 - val_loss: 0.7781 - val_acc: 1.0000\n",
      "Epoch 664/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8317 - acc: 1.0000 - val_loss: 0.7755 - val_acc: 1.0000\n",
      "Epoch 665/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8695 - acc: 0.9841 - val_loss: 0.7708 - val_acc: 1.0000\n",
      "Epoch 666/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8729 - acc: 0.9841 - val_loss: 0.7688 - val_acc: 1.0000\n",
      "Epoch 667/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8843 - acc: 0.9841 - val_loss: 0.7683 - val_acc: 1.0000\n",
      "Epoch 668/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8833 - acc: 0.9841 - val_loss: 0.7686 - val_acc: 1.0000\n",
      "Epoch 669/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8744 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 1.0000\n",
      "Epoch 670/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9239 - acc: 0.9683 - val_loss: 0.7674 - val_acc: 1.0000\n",
      "Epoch 671/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9013 - acc: 0.9841 - val_loss: 0.7693 - val_acc: 1.0000\n",
      "Epoch 672/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9213 - acc: 0.9365 - val_loss: 0.7705 - val_acc: 1.0000\n",
      "Epoch 673/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8449 - acc: 0.9841 - val_loss: 0.7694 - val_acc: 1.0000\n",
      "Epoch 674/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8700 - acc: 1.0000 - val_loss: 0.7664 - val_acc: 1.0000\n",
      "Epoch 675/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8710 - acc: 0.9683 - val_loss: 0.7638 - val_acc: 1.0000\n",
      "Epoch 676/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9266 - acc: 0.9683 - val_loss: 0.7665 - val_acc: 1.0000\n",
      "Epoch 677/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8283 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 1.0000\n",
      "Epoch 678/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8799 - acc: 0.9841 - val_loss: 0.7635 - val_acc: 1.0000\n",
      "Epoch 679/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8886 - acc: 0.9841 - val_loss: 0.7626 - val_acc: 1.0000\n",
      "Epoch 680/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8684 - acc: 1.0000 - val_loss: 0.7622 - val_acc: 1.0000\n",
      "Epoch 681/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8977 - acc: 0.9841 - val_loss: 0.7639 - val_acc: 1.0000\n",
      "Epoch 682/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0048 - acc: 0.9365 - val_loss: 0.7676 - val_acc: 1.0000\n",
      "Epoch 683/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9060 - acc: 0.9841 - val_loss: 0.7701 - val_acc: 1.0000\n",
      "Epoch 684/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9029 - acc: 0.9841 - val_loss: 0.7702 - val_acc: 1.0000\n",
      "Epoch 685/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8995 - acc: 0.9524 - val_loss: 0.7697 - val_acc: 1.0000\n",
      "Epoch 686/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8507 - acc: 0.9841 - val_loss: 0.7667 - val_acc: 1.0000\n",
      "Epoch 687/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8408 - acc: 0.9841 - val_loss: 0.7631 - val_acc: 1.0000\n",
      "Epoch 688/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9124 - acc: 0.9683 - val_loss: 0.7609 - val_acc: 1.0000\n",
      "Epoch 689/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8223 - acc: 1.0000 - val_loss: 0.7595 - val_acc: 1.0000\n",
      "Epoch 690/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8630 - acc: 0.9841 - val_loss: 0.7574 - val_acc: 1.0000\n",
      "Epoch 691/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8764 - acc: 0.9841 - val_loss: 0.7579 - val_acc: 1.0000\n",
      "Epoch 692/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8815 - acc: 1.0000 - val_loss: 0.7592 - val_acc: 1.0000\n",
      "Epoch 693/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8427 - acc: 0.9841 - val_loss: 0.7592 - val_acc: 1.0000\n",
      "Epoch 694/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8445 - acc: 0.9841 - val_loss: 0.7594 - val_acc: 1.0000\n",
      "Epoch 695/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8956 - acc: 0.9841 - val_loss: 0.7575 - val_acc: 1.0000\n",
      "Epoch 696/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8523 - acc: 0.9841 - val_loss: 0.7567 - val_acc: 1.0000\n",
      "Epoch 697/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9204 - acc: 0.9524 - val_loss: 0.7587 - val_acc: 1.0000\n",
      "Epoch 698/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8637 - acc: 0.9683 - val_loss: 0.7604 - val_acc: 1.0000\n",
      "Epoch 699/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8866 - acc: 0.9841 - val_loss: 0.7588 - val_acc: 1.0000\n",
      "Epoch 700/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8306 - acc: 0.9841 - val_loss: 0.7554 - val_acc: 1.0000\n",
      "Epoch 701/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8775 - acc: 0.9683 - val_loss: 0.7529 - val_acc: 1.0000\n",
      "Epoch 702/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9272 - acc: 0.9524 - val_loss: 0.7553 - val_acc: 1.0000\n",
      "Epoch 703/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8758 - acc: 0.9683 - val_loss: 0.7557 - val_acc: 1.0000\n",
      "Epoch 704/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8198 - acc: 1.0000 - val_loss: 0.7540 - val_acc: 1.0000\n",
      "Epoch 705/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8762 - acc: 0.9841 - val_loss: 0.7520 - val_acc: 1.0000\n",
      "Epoch 706/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9253 - acc: 0.9841 - val_loss: 0.7558 - val_acc: 1.0000\n",
      "Epoch 707/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8424 - acc: 0.9841 - val_loss: 0.7560 - val_acc: 1.0000\n",
      "Epoch 708/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8643 - acc: 0.9841 - val_loss: 0.7559 - val_acc: 1.0000\n",
      "Epoch 709/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8896 - acc: 0.9683 - val_loss: 0.7549 - val_acc: 1.0000\n",
      "Epoch 710/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8506 - acc: 0.9841 - val_loss: 0.7542 - val_acc: 1.0000\n",
      "Epoch 711/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8364 - acc: 0.9841 - val_loss: 0.7532 - val_acc: 1.0000\n",
      "Epoch 712/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8986 - acc: 0.9841 - val_loss: 0.7529 - val_acc: 1.0000\n",
      "Epoch 713/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8823 - acc: 0.9683 - val_loss: 0.7530 - val_acc: 1.0000\n",
      "Epoch 714/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8852 - acc: 0.9841 - val_loss: 0.7521 - val_acc: 1.0000\n",
      "Epoch 715/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8969 - acc: 0.9683 - val_loss: 0.7533 - val_acc: 1.0000\n",
      "Epoch 716/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8669 - acc: 0.9841 - val_loss: 0.7536 - val_acc: 1.0000\n",
      "Epoch 717/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8290 - acc: 1.0000 - val_loss: 0.7517 - val_acc: 1.0000\n",
      "Epoch 718/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8392 - acc: 0.9841 - val_loss: 0.7491 - val_acc: 1.0000\n",
      "Epoch 719/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9086 - acc: 0.9524 - val_loss: 0.7494 - val_acc: 1.0000\n",
      "Epoch 720/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8620 - acc: 0.9841 - val_loss: 0.7515 - val_acc: 1.0000\n",
      "Epoch 721/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9116 - acc: 0.9524 - val_loss: 0.7513 - val_acc: 1.0000\n",
      "Epoch 722/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8636 - acc: 0.9683 - val_loss: 0.7546 - val_acc: 1.0000\n",
      "Epoch 723/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8123 - acc: 1.0000 - val_loss: 0.7530 - val_acc: 1.0000\n",
      "Epoch 724/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8451 - acc: 1.0000 - val_loss: 0.7495 - val_acc: 1.0000\n",
      "Epoch 725/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8678 - acc: 0.9841 - val_loss: 0.7494 - val_acc: 1.0000\n",
      "Epoch 726/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8800 - acc: 0.9683 - val_loss: 0.7494 - val_acc: 1.0000\n",
      "Epoch 727/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8647 - acc: 0.9683 - val_loss: 0.7499 - val_acc: 1.0000\n",
      "Epoch 728/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8158 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 1.0000\n",
      "Epoch 729/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8446 - acc: 0.9841 - val_loss: 0.7481 - val_acc: 1.0000\n",
      "Epoch 730/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8341 - acc: 0.9841 - val_loss: 0.7463 - val_acc: 1.0000\n",
      "Epoch 731/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8362 - acc: 0.9841 - val_loss: 0.7434 - val_acc: 1.0000\n",
      "Epoch 732/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8282 - acc: 0.9683 - val_loss: 0.7408 - val_acc: 1.0000\n",
      "Epoch 733/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8176 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 1.0000\n",
      "Epoch 734/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8261 - acc: 0.9841 - val_loss: 0.7368 - val_acc: 1.0000\n",
      "Epoch 735/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8314 - acc: 0.9841 - val_loss: 0.7348 - val_acc: 1.0000\n",
      "Epoch 736/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8373 - acc: 0.9841 - val_loss: 0.7347 - val_acc: 1.0000\n",
      "Epoch 737/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8693 - acc: 0.9683 - val_loss: 0.7367 - val_acc: 1.0000\n",
      "Epoch 738/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8491 - acc: 0.9841 - val_loss: 0.7444 - val_acc: 1.0000\n",
      "Epoch 739/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8962 - acc: 0.9683 - val_loss: 0.7455 - val_acc: 1.0000\n",
      "Epoch 740/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8654 - acc: 0.9841 - val_loss: 0.7452 - val_acc: 1.0000\n",
      "Epoch 741/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8781 - acc: 0.9683 - val_loss: 0.7440 - val_acc: 1.0000\n",
      "Epoch 742/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8482 - acc: 0.9841 - val_loss: 0.7432 - val_acc: 1.0000\n",
      "Epoch 743/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8312 - acc: 0.9841 - val_loss: 0.7412 - val_acc: 1.0000\n",
      "Epoch 744/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8441 - acc: 0.9683 - val_loss: 0.7393 - val_acc: 1.0000\n",
      "Epoch 745/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8361 - acc: 0.9841 - val_loss: 0.7389 - val_acc: 1.0000\n",
      "Epoch 746/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8513 - acc: 0.9841 - val_loss: 0.7378 - val_acc: 1.0000\n",
      "Epoch 747/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8877 - acc: 0.9524 - val_loss: 0.7380 - val_acc: 1.0000\n",
      "Epoch 748/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8364 - acc: 0.9524 - val_loss: 0.7375 - val_acc: 1.0000\n",
      "Epoch 749/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8600 - acc: 0.9841 - val_loss: 0.7380 - val_acc: 1.0000\n",
      "Epoch 750/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8675 - acc: 0.9683 - val_loss: 0.7374 - val_acc: 1.0000\n",
      "Epoch 751/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7974 - acc: 1.0000 - val_loss: 0.7356 - val_acc: 1.0000\n",
      "Epoch 752/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8350 - acc: 0.9841 - val_loss: 0.7322 - val_acc: 1.0000\n",
      "Epoch 753/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8967 - acc: 0.9683 - val_loss: 0.7344 - val_acc: 1.0000\n",
      "Epoch 754/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8150 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 1.0000\n",
      "Epoch 755/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.0070 - acc: 0.9365 - val_loss: 0.7399 - val_acc: 1.0000\n",
      "Epoch 756/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8572 - acc: 0.9841 - val_loss: 0.7436 - val_acc: 1.0000\n",
      "Epoch 757/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8274 - acc: 1.0000 - val_loss: 0.7421 - val_acc: 1.0000\n",
      "Epoch 758/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8719 - acc: 0.9683 - val_loss: 0.7389 - val_acc: 1.0000\n",
      "Epoch 759/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8310 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 1.0000\n",
      "Epoch 760/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9035 - acc: 0.9524 - val_loss: 0.7346 - val_acc: 1.0000\n",
      "Epoch 761/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7787 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 1.0000\n",
      "Epoch 762/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8357 - acc: 0.9841 - val_loss: 0.7336 - val_acc: 1.0000\n",
      "Epoch 763/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7978 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 764/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8974 - acc: 0.9683 - val_loss: 0.7297 - val_acc: 1.0000\n",
      "Epoch 765/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8124 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 766/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8014 - acc: 0.9841 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 767/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8967 - acc: 0.9524 - val_loss: 0.7302 - val_acc: 1.0000\n",
      "Epoch 768/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8192 - acc: 0.9841 - val_loss: 0.7339 - val_acc: 1.0000\n",
      "Epoch 769/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8322 - acc: 1.0000 - val_loss: 0.7338 - val_acc: 1.0000\n",
      "Epoch 770/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8169 - acc: 0.9841 - val_loss: 0.7315 - val_acc: 1.0000\n",
      "Epoch 771/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8038 - acc: 1.0000 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 772/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8118 - acc: 0.9841 - val_loss: 0.7229 - val_acc: 1.0000\n",
      "Epoch 773/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8231 - acc: 0.9841 - val_loss: 0.7213 - val_acc: 1.0000\n",
      "Epoch 774/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8806 - acc: 0.9365 - val_loss: 0.7209 - val_acc: 1.0000\n",
      "Epoch 775/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7927 - acc: 0.9841 - val_loss: 0.7203 - val_acc: 1.0000\n",
      "Epoch 776/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7938 - acc: 1.0000 - val_loss: 0.7185 - val_acc: 1.0000\n",
      "Epoch 777/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8579 - acc: 0.9841 - val_loss: 0.7199 - val_acc: 1.0000\n",
      "Epoch 778/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9124 - acc: 0.9524 - val_loss: 0.7232 - val_acc: 1.0000\n",
      "Epoch 779/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8096 - acc: 0.9841 - val_loss: 0.7239 - val_acc: 1.0000\n",
      "Epoch 780/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8198 - acc: 0.9683 - val_loss: 0.7222 - val_acc: 1.0000\n",
      "Epoch 781/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8136 - acc: 1.0000 - val_loss: 0.7206 - val_acc: 1.0000\n",
      "Epoch 782/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8548 - acc: 0.9524 - val_loss: 0.7193 - val_acc: 1.0000\n",
      "Epoch 783/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7974 - acc: 1.0000 - val_loss: 0.7185 - val_acc: 1.0000\n",
      "Epoch 784/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8473 - acc: 0.9683 - val_loss: 0.7199 - val_acc: 1.0000\n",
      "Epoch 785/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7939 - acc: 1.0000 - val_loss: 0.7220 - val_acc: 1.0000\n",
      "Epoch 786/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8190 - acc: 0.9841 - val_loss: 0.7203 - val_acc: 1.0000\n",
      "Epoch 787/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8180 - acc: 0.9841 - val_loss: 0.7192 - val_acc: 1.0000\n",
      "Epoch 788/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7959 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 1.0000\n",
      "Epoch 789/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8750 - acc: 0.9683 - val_loss: 0.7170 - val_acc: 1.0000\n",
      "Epoch 790/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7835 - acc: 0.9841 - val_loss: 0.7162 - val_acc: 1.0000\n",
      "Epoch 791/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8434 - acc: 0.9841 - val_loss: 0.7155 - val_acc: 1.0000\n",
      "Epoch 792/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8325 - acc: 0.9841 - val_loss: 0.7151 - val_acc: 1.0000\n",
      "Epoch 793/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8449 - acc: 0.9841 - val_loss: 0.7160 - val_acc: 1.0000\n",
      "Epoch 794/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8199 - acc: 0.9841 - val_loss: 0.7160 - val_acc: 1.0000\n",
      "Epoch 795/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8698 - acc: 0.9841 - val_loss: 0.7164 - val_acc: 1.0000\n",
      "Epoch 796/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7906 - acc: 1.0000 - val_loss: 0.7153 - val_acc: 1.0000\n",
      "Epoch 797/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7905 - acc: 1.0000 - val_loss: 0.7115 - val_acc: 1.0000\n",
      "Epoch 798/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8022 - acc: 0.9841 - val_loss: 0.7101 - val_acc: 1.0000\n",
      "Epoch 799/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8038 - acc: 1.0000 - val_loss: 0.7109 - val_acc: 1.0000\n",
      "Epoch 800/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8264 - acc: 0.9841 - val_loss: 0.7103 - val_acc: 1.0000\n",
      "Epoch 801/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8399 - acc: 0.9683 - val_loss: 0.7113 - val_acc: 1.0000\n",
      "Epoch 802/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7603 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 1.0000\n",
      "Epoch 803/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7809 - acc: 0.9841 - val_loss: 0.7081 - val_acc: 1.0000\n",
      "Epoch 804/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8445 - acc: 0.9524 - val_loss: 0.7085 - val_acc: 1.0000\n",
      "Epoch 805/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8031 - acc: 0.9841 - val_loss: 0.7112 - val_acc: 1.0000\n",
      "Epoch 806/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8381 - acc: 0.9841 - val_loss: 0.7128 - val_acc: 1.0000\n",
      "Epoch 807/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9000 - acc: 0.9524 - val_loss: 0.7130 - val_acc: 1.0000\n",
      "Epoch 808/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8259 - acc: 0.9841 - val_loss: 0.7151 - val_acc: 1.0000\n",
      "Epoch 809/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8664 - acc: 0.9683 - val_loss: 0.7155 - val_acc: 1.0000\n",
      "Epoch 810/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8340 - acc: 0.9841 - val_loss: 0.7161 - val_acc: 1.0000\n",
      "Epoch 811/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8393 - acc: 0.9841 - val_loss: 0.7181 - val_acc: 1.0000\n",
      "Epoch 812/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8237 - acc: 0.9841 - val_loss: 0.7172 - val_acc: 1.0000\n",
      "Epoch 813/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7915 - acc: 1.0000 - val_loss: 0.7149 - val_acc: 1.0000\n",
      "Epoch 814/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8123 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 1.0000\n",
      "Epoch 815/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8809 - acc: 0.9524 - val_loss: 0.7107 - val_acc: 1.0000\n",
      "Epoch 816/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8177 - acc: 1.0000 - val_loss: 0.7128 - val_acc: 1.0000\n",
      "Epoch 817/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8221 - acc: 0.9683 - val_loss: 0.7127 - val_acc: 1.0000\n",
      "Epoch 818/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8472 - acc: 0.9841 - val_loss: 0.7121 - val_acc: 1.0000\n",
      "Epoch 819/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8131 - acc: 0.9841 - val_loss: 0.7105 - val_acc: 1.0000\n",
      "Epoch 820/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8342 - acc: 0.9841 - val_loss: 0.7093 - val_acc: 1.0000\n",
      "Epoch 821/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8024 - acc: 0.9841 - val_loss: 0.7090 - val_acc: 1.0000\n",
      "Epoch 822/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7990 - acc: 0.9683 - val_loss: 0.7080 - val_acc: 1.0000\n",
      "Epoch 823/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8121 - acc: 0.9683 - val_loss: 0.7087 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00823: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 824/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7836 - acc: 1.0000 - val_loss: 0.7079 - val_acc: 1.0000\n",
      "Epoch 825/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8535 - acc: 0.9683 - val_loss: 0.7061 - val_acc: 1.0000\n",
      "Epoch 826/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8466 - acc: 0.9524 - val_loss: 0.7055 - val_acc: 1.0000\n",
      "Epoch 827/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7577 - acc: 1.0000 - val_loss: 0.7035 - val_acc: 1.0000\n",
      "Epoch 828/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8608 - acc: 0.9524 - val_loss: 0.7019 - val_acc: 1.0000\n",
      "Epoch 829/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8817 - acc: 0.9365 - val_loss: 0.7037 - val_acc: 1.0000\n",
      "Epoch 830/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8448 - acc: 0.9683 - val_loss: 0.7040 - val_acc: 1.0000\n",
      "Epoch 831/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8537 - acc: 0.9683 - val_loss: 0.7043 - val_acc: 1.0000\n",
      "Epoch 832/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7899 - acc: 1.0000 - val_loss: 0.7037 - val_acc: 1.0000\n",
      "Epoch 833/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8226 - acc: 0.9683 - val_loss: 0.7020 - val_acc: 1.0000\n",
      "Epoch 834/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8178 - acc: 0.9683 - val_loss: 0.7009 - val_acc: 1.0000\n",
      "Epoch 835/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8724 - acc: 0.9524 - val_loss: 0.7010 - val_acc: 1.0000\n",
      "Epoch 836/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8518 - acc: 0.9365 - val_loss: 0.7000 - val_acc: 1.0000\n",
      "Epoch 837/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7944 - acc: 1.0000 - val_loss: 0.6982 - val_acc: 1.0000\n",
      "Epoch 838/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8139 - acc: 0.9683 - val_loss: 0.6964 - val_acc: 1.0000\n",
      "Epoch 839/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8116 - acc: 1.0000 - val_loss: 0.6959 - val_acc: 1.0000\n",
      "Epoch 840/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8431 - acc: 0.9524 - val_loss: 0.6949 - val_acc: 1.0000\n",
      "Epoch 841/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8072 - acc: 0.9841 - val_loss: 0.6948 - val_acc: 1.0000\n",
      "Epoch 842/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8370 - acc: 0.9841 - val_loss: 0.6937 - val_acc: 1.0000\n",
      "Epoch 843/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8129 - acc: 0.9841 - val_loss: 0.6931 - val_acc: 1.0000\n",
      "Epoch 844/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8508 - acc: 0.9683 - val_loss: 0.6936 - val_acc: 1.0000\n",
      "Epoch 845/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7846 - acc: 1.0000 - val_loss: 0.6931 - val_acc: 1.0000\n",
      "Epoch 846/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8339 - acc: 0.9683 - val_loss: 0.6920 - val_acc: 1.0000\n",
      "Epoch 847/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8074 - acc: 0.9841 - val_loss: 0.6924 - val_acc: 1.0000\n",
      "Epoch 848/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7627 - acc: 1.0000 - val_loss: 0.6912 - val_acc: 1.0000\n",
      "Epoch 849/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7811 - acc: 1.0000 - val_loss: 0.6892 - val_acc: 1.0000\n",
      "Epoch 850/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8122 - acc: 0.9841 - val_loss: 0.6877 - val_acc: 1.0000\n",
      "Epoch 851/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7720 - acc: 1.0000 - val_loss: 0.6869 - val_acc: 1.0000\n",
      "Epoch 852/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8364 - acc: 0.9683 - val_loss: 0.6872 - val_acc: 1.0000\n",
      "Epoch 853/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7660 - acc: 1.0000 - val_loss: 0.6873 - val_acc: 1.0000\n",
      "Epoch 854/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7735 - acc: 1.0000 - val_loss: 0.6868 - val_acc: 1.0000\n",
      "Epoch 855/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7769 - acc: 0.9841 - val_loss: 0.6861 - val_acc: 1.0000\n",
      "Epoch 856/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7886 - acc: 1.0000 - val_loss: 0.6851 - val_acc: 1.0000\n",
      "Epoch 857/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7926 - acc: 0.9841 - val_loss: 0.6845 - val_acc: 1.0000\n",
      "Epoch 858/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7684 - acc: 0.9841 - val_loss: 0.6839 - val_acc: 1.0000\n",
      "Epoch 859/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8128 - acc: 0.9841 - val_loss: 0.6842 - val_acc: 1.0000\n",
      "Epoch 860/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8195 - acc: 0.9683 - val_loss: 0.6850 - val_acc: 1.0000\n",
      "Epoch 861/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8149 - acc: 0.9524 - val_loss: 0.6860 - val_acc: 1.0000\n",
      "Epoch 862/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7574 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 1.0000\n",
      "Epoch 863/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7847 - acc: 0.9841 - val_loss: 0.6852 - val_acc: 1.0000\n",
      "Epoch 864/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7998 - acc: 0.9524 - val_loss: 0.6847 - val_acc: 1.0000\n",
      "Epoch 865/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 1.0000 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Epoch 866/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7709 - acc: 1.0000 - val_loss: 0.6828 - val_acc: 1.0000\n",
      "Epoch 867/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7801 - acc: 0.9841 - val_loss: 0.6835 - val_acc: 1.0000\n",
      "Epoch 868/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7593 - acc: 1.0000 - val_loss: 0.6836 - val_acc: 1.0000\n",
      "Epoch 869/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7942 - acc: 0.9683 - val_loss: 0.6841 - val_acc: 1.0000\n",
      "Epoch 870/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7666 - acc: 1.0000 - val_loss: 0.6839 - val_acc: 1.0000\n",
      "Epoch 871/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7672 - acc: 0.9841 - val_loss: 0.6825 - val_acc: 1.0000\n",
      "Epoch 872/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7564 - acc: 0.9841 - val_loss: 0.6806 - val_acc: 1.0000\n",
      "Epoch 873/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7804 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 1.0000\n",
      "Epoch 874/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8764 - acc: 0.9524 - val_loss: 0.6820 - val_acc: 1.0000\n",
      "Epoch 875/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7626 - acc: 1.0000 - val_loss: 0.6826 - val_acc: 1.0000\n",
      "Epoch 876/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8136 - acc: 0.9841 - val_loss: 0.6812 - val_acc: 1.0000\n",
      "Epoch 877/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8265 - acc: 0.9524 - val_loss: 0.6803 - val_acc: 1.0000\n",
      "Epoch 878/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7251 - acc: 1.0000 - val_loss: 0.6798 - val_acc: 1.0000\n",
      "Epoch 879/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7423 - acc: 1.0000 - val_loss: 0.6780 - val_acc: 1.0000\n",
      "Epoch 880/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7797 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 1.0000\n",
      "Epoch 881/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7350 - acc: 1.0000 - val_loss: 0.6766 - val_acc: 1.0000\n",
      "Epoch 882/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7921 - acc: 0.9841 - val_loss: 0.6767 - val_acc: 1.0000\n",
      "Epoch 883/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7918 - acc: 0.9683 - val_loss: 0.6783 - val_acc: 1.0000\n",
      "Epoch 884/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8045 - acc: 0.9683 - val_loss: 0.6802 - val_acc: 1.0000\n",
      "Epoch 885/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.9163 - acc: 0.9365 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Epoch 886/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8100 - acc: 0.9841 - val_loss: 0.6845 - val_acc: 1.0000\n",
      "Epoch 887/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8839 - acc: 0.9683 - val_loss: 0.6835 - val_acc: 1.0000\n",
      "Epoch 888/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8101 - acc: 0.9683 - val_loss: 0.6836 - val_acc: 1.0000\n",
      "Epoch 889/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7750 - acc: 0.9841 - val_loss: 0.6827 - val_acc: 1.0000\n",
      "Epoch 890/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7818 - acc: 1.0000 - val_loss: 0.6812 - val_acc: 1.0000\n",
      "Epoch 891/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8448 - acc: 0.9683 - val_loss: 0.6809 - val_acc: 1.0000\n",
      "Epoch 892/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8088 - acc: 0.9524 - val_loss: 0.6805 - val_acc: 1.0000\n",
      "Epoch 893/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7511 - acc: 0.9841 - val_loss: 0.6795 - val_acc: 1.0000\n",
      "Epoch 894/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7925 - acc: 0.9841 - val_loss: 0.6792 - val_acc: 1.0000\n",
      "Epoch 895/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7511 - acc: 1.0000 - val_loss: 0.6781 - val_acc: 1.0000\n",
      "Epoch 896/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7696 - acc: 1.0000 - val_loss: 0.6771 - val_acc: 1.0000\n",
      "Epoch 897/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7835 - acc: 1.0000 - val_loss: 0.6767 - val_acc: 1.0000\n",
      "Epoch 898/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8050 - acc: 0.9841 - val_loss: 0.6773 - val_acc: 1.0000\n",
      "Epoch 899/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8208 - acc: 0.9683 - val_loss: 0.6773 - val_acc: 1.0000\n",
      "Epoch 900/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8080 - acc: 0.9841 - val_loss: 0.6788 - val_acc: 1.0000\n",
      "Epoch 901/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7519 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00901: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 902/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7523 - acc: 1.0000 - val_loss: 0.6776 - val_acc: 1.0000\n",
      "Epoch 903/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7916 - acc: 0.9683 - val_loss: 0.6764 - val_acc: 1.0000\n",
      "Epoch 904/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7651 - acc: 0.9841 - val_loss: 0.6753 - val_acc: 1.0000\n",
      "Epoch 905/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7818 - acc: 0.9683 - val_loss: 0.6744 - val_acc: 1.0000\n",
      "Epoch 906/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7822 - acc: 0.9841 - val_loss: 0.6735 - val_acc: 1.0000\n",
      "Epoch 907/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7902 - acc: 1.0000 - val_loss: 0.6729 - val_acc: 1.0000\n",
      "Epoch 908/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7036 - acc: 1.0000 - val_loss: 0.6721 - val_acc: 1.0000\n",
      "Epoch 909/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7647 - acc: 0.9841 - val_loss: 0.6711 - val_acc: 1.0000\n",
      "Epoch 910/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8260 - acc: 0.9524 - val_loss: 0.6710 - val_acc: 1.0000\n",
      "Epoch 911/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7351 - acc: 1.0000 - val_loss: 0.6709 - val_acc: 1.0000\n",
      "Epoch 912/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8309 - acc: 0.9524 - val_loss: 0.6706 - val_acc: 1.0000\n",
      "Epoch 913/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7454 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 1.0000\n",
      "Epoch 914/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7601 - acc: 0.9841 - val_loss: 0.6699 - val_acc: 1.0000\n",
      "Epoch 915/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8015 - acc: 0.9524 - val_loss: 0.6698 - val_acc: 1.0000\n",
      "Epoch 916/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7594 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 1.0000\n",
      "Epoch 917/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7444 - acc: 0.9683 - val_loss: 0.6693 - val_acc: 1.0000\n",
      "Epoch 918/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7439 - acc: 1.0000 - val_loss: 0.6690 - val_acc: 1.0000\n",
      "Epoch 919/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8137 - acc: 0.9683 - val_loss: 0.6688 - val_acc: 1.0000\n",
      "Epoch 920/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7459 - acc: 1.0000 - val_loss: 0.6686 - val_acc: 1.0000\n",
      "Epoch 921/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7781 - acc: 0.9683 - val_loss: 0.6685 - val_acc: 1.0000\n",
      "Epoch 922/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8019 - acc: 0.9683 - val_loss: 0.6683 - val_acc: 1.0000\n",
      "Epoch 923/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7428 - acc: 1.0000 - val_loss: 0.6678 - val_acc: 1.0000\n",
      "Epoch 924/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7515 - acc: 0.9841 - val_loss: 0.6671 - val_acc: 1.0000\n",
      "Epoch 925/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7265 - acc: 1.0000 - val_loss: 0.6664 - val_acc: 1.0000\n",
      "Epoch 926/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8681 - acc: 0.9206 - val_loss: 0.6668 - val_acc: 1.0000\n",
      "Epoch 927/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7273 - acc: 0.9841 - val_loss: 0.6680 - val_acc: 1.0000\n",
      "Epoch 928/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7189 - acc: 1.0000 - val_loss: 0.6676 - val_acc: 1.0000\n",
      "Epoch 929/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7595 - acc: 0.9841 - val_loss: 0.6666 - val_acc: 1.0000\n",
      "Epoch 930/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7421 - acc: 1.0000 - val_loss: 0.6665 - val_acc: 1.0000\n",
      "Epoch 931/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7818 - acc: 0.9683 - val_loss: 0.6660 - val_acc: 1.0000\n",
      "Epoch 932/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7518 - acc: 1.0000 - val_loss: 0.6660 - val_acc: 1.0000\n",
      "Epoch 933/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7578 - acc: 0.9841 - val_loss: 0.6655 - val_acc: 1.0000\n",
      "Epoch 934/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7451 - acc: 0.9841 - val_loss: 0.6653 - val_acc: 1.0000\n",
      "Epoch 935/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8196 - acc: 0.9683 - val_loss: 0.6651 - val_acc: 1.0000\n",
      "Epoch 936/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7370 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 1.0000\n",
      "Epoch 937/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7108 - acc: 1.0000 - val_loss: 0.6643 - val_acc: 1.0000\n",
      "Epoch 938/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7457 - acc: 0.9841 - val_loss: 0.6636 - val_acc: 1.0000\n",
      "Epoch 939/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8119 - acc: 0.9683 - val_loss: 0.6636 - val_acc: 1.0000\n",
      "Epoch 940/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7262 - acc: 0.9841 - val_loss: 0.6634 - val_acc: 1.0000\n",
      "Epoch 941/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7528 - acc: 0.9841 - val_loss: 0.6631 - val_acc: 1.0000\n",
      "Epoch 942/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7532 - acc: 1.0000 - val_loss: 0.6633 - val_acc: 1.0000\n",
      "Epoch 943/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7999 - acc: 0.9524 - val_loss: 0.6634 - val_acc: 1.0000\n",
      "Epoch 944/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8745 - acc: 0.9524 - val_loss: 0.6636 - val_acc: 1.0000\n",
      "Epoch 945/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7767 - acc: 0.9683 - val_loss: 0.6642 - val_acc: 1.0000\n",
      "Epoch 946/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8017 - acc: 0.9841 - val_loss: 0.6645 - val_acc: 1.0000\n",
      "Epoch 947/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7675 - acc: 0.9841 - val_loss: 0.6646 - val_acc: 1.0000\n",
      "Epoch 948/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7258 - acc: 1.0000 - val_loss: 0.6638 - val_acc: 1.0000\n",
      "Epoch 949/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7587 - acc: 1.0000 - val_loss: 0.6630 - val_acc: 1.0000\n",
      "Epoch 950/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7572 - acc: 1.0000 - val_loss: 0.6627 - val_acc: 1.0000\n",
      "Epoch 951/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7665 - acc: 0.9841 - val_loss: 0.6627 - val_acc: 1.0000\n",
      "Epoch 952/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7558 - acc: 0.9841 - val_loss: 0.6627 - val_acc: 1.0000\n",
      "Epoch 953/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7810 - acc: 0.9683 - val_loss: 0.6627 - val_acc: 1.0000\n",
      "Epoch 954/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7402 - acc: 1.0000 - val_loss: 0.6624 - val_acc: 1.0000\n",
      "Epoch 955/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7193 - acc: 1.0000 - val_loss: 0.6618 - val_acc: 1.0000\n",
      "Epoch 956/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7161 - acc: 0.9841 - val_loss: 0.6612 - val_acc: 1.0000\n",
      "Epoch 957/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7719 - acc: 0.9841 - val_loss: 0.6607 - val_acc: 1.0000\n",
      "Epoch 958/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7664 - acc: 0.9841 - val_loss: 0.6603 - val_acc: 1.0000\n",
      "Epoch 959/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7723 - acc: 0.9841 - val_loss: 0.6606 - val_acc: 1.0000\n",
      "Epoch 960/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8009 - acc: 0.9524 - val_loss: 0.6611 - val_acc: 1.0000\n",
      "Epoch 961/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7419 - acc: 0.9841 - val_loss: 0.6620 - val_acc: 1.0000\n",
      "Epoch 962/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7719 - acc: 0.9524 - val_loss: 0.6619 - val_acc: 1.0000\n",
      "Epoch 963/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8430 - acc: 0.9365 - val_loss: 0.6624 - val_acc: 1.0000\n",
      "Epoch 964/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7228 - acc: 0.9841 - val_loss: 0.6630 - val_acc: 1.0000\n",
      "Epoch 965/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7319 - acc: 1.0000 - val_loss: 0.6623 - val_acc: 1.0000\n",
      "Epoch 966/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8013 - acc: 0.9683 - val_loss: 0.6618 - val_acc: 1.0000\n",
      "Epoch 967/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8133 - acc: 0.9841 - val_loss: 0.6617 - val_acc: 1.0000\n",
      "Epoch 968/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7515 - acc: 0.9841 - val_loss: 0.6619 - val_acc: 1.0000\n",
      "Epoch 969/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8188 - acc: 0.9524 - val_loss: 0.6618 - val_acc: 1.0000\n",
      "Epoch 970/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7439 - acc: 0.9841 - val_loss: 0.6619 - val_acc: 1.0000\n",
      "Epoch 971/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8087 - acc: 0.9524 - val_loss: 0.6616 - val_acc: 1.0000\n",
      "Epoch 972/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7982 - acc: 0.9683 - val_loss: 0.6618 - val_acc: 1.0000\n",
      "Epoch 973/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7729 - acc: 0.9683 - val_loss: 0.6621 - val_acc: 1.0000\n",
      "Epoch 974/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7193 - acc: 1.0000 - val_loss: 0.6619 - val_acc: 1.0000\n",
      "Epoch 975/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8416 - acc: 0.9683 - val_loss: 0.6624 - val_acc: 1.0000\n",
      "Epoch 976/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7639 - acc: 0.9841 - val_loss: 0.6617 - val_acc: 1.0000\n",
      "Epoch 977/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7412 - acc: 1.0000 - val_loss: 0.6610 - val_acc: 1.0000\n",
      "Epoch 978/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7348 - acc: 1.0000 - val_loss: 0.6602 - val_acc: 1.0000\n",
      "Epoch 979/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8043 - acc: 0.9683 - val_loss: 0.6596 - val_acc: 1.0000\n",
      "Epoch 980/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7413 - acc: 0.9841 - val_loss: 0.6593 - val_acc: 1.0000\n",
      "Epoch 981/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7514 - acc: 0.9841 - val_loss: 0.6594 - val_acc: 1.0000\n",
      "Epoch 982/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7622 - acc: 1.0000 - val_loss: 0.6592 - val_acc: 1.0000\n",
      "Epoch 983/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7497 - acc: 1.0000 - val_loss: 0.6593 - val_acc: 1.0000\n",
      "Epoch 984/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7181 - acc: 1.0000 - val_loss: 0.6588 - val_acc: 1.0000\n",
      "Epoch 985/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7664 - acc: 0.9683 - val_loss: 0.6583 - val_acc: 1.0000\n",
      "Epoch 986/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8141 - acc: 0.9524 - val_loss: 0.6585 - val_acc: 1.0000\n",
      "Epoch 987/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8675 - acc: 0.9524 - val_loss: 0.6595 - val_acc: 1.0000\n",
      "Epoch 988/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7564 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 1.0000\n",
      "Epoch 989/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7509 - acc: 0.9841 - val_loss: 0.6599 - val_acc: 1.0000\n",
      "Epoch 990/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7432 - acc: 0.9841 - val_loss: 0.6591 - val_acc: 1.0000\n",
      "Epoch 991/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7573 - acc: 0.9841 - val_loss: 0.6587 - val_acc: 1.0000\n",
      "Epoch 992/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7851 - acc: 0.9841 - val_loss: 0.6583 - val_acc: 1.0000\n",
      "Epoch 993/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7745 - acc: 0.9841 - val_loss: 0.6583 - val_acc: 1.0000\n",
      "Epoch 994/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7559 - acc: 0.9683 - val_loss: 0.6581 - val_acc: 1.0000\n",
      "Epoch 995/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 1.0000 - val_loss: 0.6582 - val_acc: 1.0000\n",
      "Epoch 996/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7976 - acc: 0.9683 - val_loss: 0.6580 - val_acc: 1.0000\n",
      "Epoch 997/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8269 - acc: 0.9841 - val_loss: 0.6585 - val_acc: 1.0000\n",
      "Epoch 998/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7796 - acc: 0.9683 - val_loss: 0.6588 - val_acc: 1.0000\n",
      "Epoch 999/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7502 - acc: 1.0000 - val_loss: 0.6589 - val_acc: 1.0000\n",
      "Epoch 1000/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8019 - acc: 0.9683 - val_loss: 0.6592 - val_acc: 1.0000\n",
      "Epoch 1001/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8240 - acc: 0.9206 - val_loss: 0.6595 - val_acc: 1.0000\n",
      "Epoch 1002/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7748 - acc: 0.9524 - val_loss: 0.6595 - val_acc: 1.0000\n",
      "Epoch 1003/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7894 - acc: 0.9683 - val_loss: 0.6592 - val_acc: 1.0000\n",
      "Epoch 1004/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8164 - acc: 0.9524 - val_loss: 0.6595 - val_acc: 1.0000\n",
      "Epoch 1005/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7227 - acc: 1.0000 - val_loss: 0.6592 - val_acc: 1.0000\n",
      "Epoch 1006/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7453 - acc: 0.9841 - val_loss: 0.6585 - val_acc: 1.0000\n",
      "Epoch 1007/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7181 - acc: 0.9841 - val_loss: 0.6575 - val_acc: 1.0000\n",
      "Epoch 1008/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7287 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 1.0000\n",
      "Epoch 1009/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7894 - acc: 0.9683 - val_loss: 0.6564 - val_acc: 1.0000\n",
      "Epoch 1010/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7554 - acc: 0.9841 - val_loss: 0.6562 - val_acc: 1.0000\n",
      "Epoch 1011/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7777 - acc: 0.9841 - val_loss: 0.6561 - val_acc: 1.0000\n",
      "Epoch 1012/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7534 - acc: 0.9841 - val_loss: 0.6559 - val_acc: 1.0000\n",
      "Epoch 1013/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7674 - acc: 0.9841 - val_loss: 0.6562 - val_acc: 1.0000\n",
      "Epoch 1014/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7817 - acc: 0.9683 - val_loss: 0.6562 - val_acc: 1.0000\n",
      "Epoch 1015/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7279 - acc: 0.9841 - val_loss: 0.6561 - val_acc: 1.0000\n",
      "Epoch 1016/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8126 - acc: 0.9365 - val_loss: 0.6561 - val_acc: 1.0000\n",
      "Epoch 1017/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7558 - acc: 0.9841 - val_loss: 0.6561 - val_acc: 1.0000\n",
      "Epoch 1018/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7400 - acc: 0.9841 - val_loss: 0.6557 - val_acc: 1.0000\n",
      "Epoch 1019/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7337 - acc: 1.0000 - val_loss: 0.6552 - val_acc: 1.0000\n",
      "Epoch 1020/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7457 - acc: 0.9841 - val_loss: 0.6548 - val_acc: 1.0000\n",
      "Epoch 1021/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7504 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 1.0000\n",
      "Epoch 1022/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7710 - acc: 0.9683 - val_loss: 0.6545 - val_acc: 1.0000\n",
      "Epoch 1023/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7518 - acc: 0.9841 - val_loss: 0.6552 - val_acc: 1.0000\n",
      "Epoch 1024/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8565 - acc: 0.9524 - val_loss: 0.6558 - val_acc: 1.0000\n",
      "Epoch 1025/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7512 - acc: 1.0000 - val_loss: 0.6564 - val_acc: 1.0000\n",
      "Epoch 1026/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7220 - acc: 0.9841 - val_loss: 0.6564 - val_acc: 1.0000\n",
      "Epoch 1027/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7586 - acc: 0.9841 - val_loss: 0.6557 - val_acc: 1.0000\n",
      "Epoch 1028/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7968 - acc: 0.9683 - val_loss: 0.6558 - val_acc: 1.0000\n",
      "Epoch 1029/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7312 - acc: 1.0000 - val_loss: 0.6556 - val_acc: 1.0000\n",
      "Epoch 1030/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7396 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 1.0000\n",
      "Epoch 1031/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7666 - acc: 0.9841 - val_loss: 0.6549 - val_acc: 1.0000\n",
      "Epoch 1032/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7117 - acc: 1.0000 - val_loss: 0.6544 - val_acc: 1.0000\n",
      "Epoch 1033/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7164 - acc: 1.0000 - val_loss: 0.6534 - val_acc: 1.0000\n",
      "Epoch 1034/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7342 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 1.0000\n",
      "Epoch 1035/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7649 - acc: 0.9683 - val_loss: 0.6529 - val_acc: 1.0000\n",
      "Epoch 1036/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7396 - acc: 1.0000 - val_loss: 0.6534 - val_acc: 1.0000\n",
      "Epoch 1037/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7465 - acc: 0.9683 - val_loss: 0.6532 - val_acc: 1.0000\n",
      "Epoch 1038/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7849 - acc: 0.9841 - val_loss: 0.6531 - val_acc: 1.0000\n",
      "Epoch 1039/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7264 - acc: 1.0000 - val_loss: 0.6530 - val_acc: 1.0000\n",
      "Epoch 1040/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7408 - acc: 1.0000 - val_loss: 0.6526 - val_acc: 1.0000\n",
      "Epoch 1041/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7883 - acc: 0.9683 - val_loss: 0.6525 - val_acc: 1.0000\n",
      "Epoch 1042/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7335 - acc: 1.0000 - val_loss: 0.6530 - val_acc: 1.0000\n",
      "Epoch 1043/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8731 - acc: 0.9206 - val_loss: 0.6537 - val_acc: 1.0000\n",
      "Epoch 1044/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7695 - acc: 0.9683 - val_loss: 0.6545 - val_acc: 1.0000\n",
      "Epoch 1045/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7316 - acc: 0.9841 - val_loss: 0.6542 - val_acc: 1.0000\n",
      "Epoch 1046/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7260 - acc: 0.9841 - val_loss: 0.6534 - val_acc: 1.0000\n",
      "Epoch 1047/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7644 - acc: 0.9841 - val_loss: 0.6528 - val_acc: 1.0000\n",
      "Epoch 1048/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7373 - acc: 0.9841 - val_loss: 0.6525 - val_acc: 1.0000\n",
      "Epoch 1049/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7533 - acc: 0.9524 - val_loss: 0.6527 - val_acc: 1.0000\n",
      "Epoch 1050/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7677 - acc: 0.9683 - val_loss: 0.6532 - val_acc: 1.0000\n",
      "Epoch 1051/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7503 - acc: 0.9841 - val_loss: 0.6533 - val_acc: 1.0000\n",
      "Epoch 1052/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7465 - acc: 0.9841 - val_loss: 0.6529 - val_acc: 1.0000\n",
      "Epoch 1053/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7383 - acc: 1.0000 - val_loss: 0.6531 - val_acc: 1.0000\n",
      "Epoch 1054/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7500 - acc: 0.9841 - val_loss: 0.6526 - val_acc: 1.0000\n",
      "Epoch 1055/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7655 - acc: 0.9841 - val_loss: 0.6519 - val_acc: 1.0000\n",
      "Epoch 1056/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7927 - acc: 0.9683 - val_loss: 0.6521 - val_acc: 1.0000\n",
      "Epoch 1057/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7867 - acc: 0.9524 - val_loss: 0.6530 - val_acc: 1.0000\n",
      "Epoch 1058/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7205 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 1.0000\n",
      "Epoch 1059/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7208 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 1.0000\n",
      "Epoch 1060/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7758 - acc: 0.9524 - val_loss: 0.6513 - val_acc: 1.0000\n",
      "Epoch 1061/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7816 - acc: 0.9841 - val_loss: 0.6519 - val_acc: 1.0000\n",
      "Epoch 1062/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7174 - acc: 0.9841 - val_loss: 0.6519 - val_acc: 1.0000\n",
      "Epoch 1063/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7460 - acc: 1.0000 - val_loss: 0.6517 - val_acc: 1.0000\n",
      "Epoch 1064/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7591 - acc: 0.9683 - val_loss: 0.6511 - val_acc: 1.0000\n",
      "Epoch 1065/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7770 - acc: 0.9683 - val_loss: 0.6508 - val_acc: 1.0000\n",
      "Epoch 1066/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7987 - acc: 0.9683 - val_loss: 0.6514 - val_acc: 1.0000\n",
      "Epoch 1067/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7893 - acc: 0.9841 - val_loss: 0.6516 - val_acc: 1.0000\n",
      "Epoch 1068/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7324 - acc: 0.9841 - val_loss: 0.6515 - val_acc: 1.0000\n",
      "Epoch 1069/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7631 - acc: 0.9841 - val_loss: 0.6512 - val_acc: 1.0000\n",
      "Epoch 1070/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7094 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 1.0000\n",
      "Epoch 1071/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7897 - acc: 0.9524 - val_loss: 0.6507 - val_acc: 1.0000\n",
      "Epoch 1072/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8366 - acc: 0.9683 - val_loss: 0.6509 - val_acc: 1.0000\n",
      "Epoch 1073/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7437 - acc: 1.0000 - val_loss: 0.6516 - val_acc: 1.0000\n",
      "Epoch 1074/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7133 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 1.0000\n",
      "Epoch 1075/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6877 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 1.0000\n",
      "Epoch 1076/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7755 - acc: 0.9683 - val_loss: 0.6498 - val_acc: 1.0000\n",
      "Epoch 1077/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7629 - acc: 0.9524 - val_loss: 0.6497 - val_acc: 1.0000\n",
      "Epoch 1078/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7468 - acc: 0.9841 - val_loss: 0.6500 - val_acc: 1.0000\n",
      "Epoch 1079/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.9841 - val_loss: 0.6501 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1080/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7437 - acc: 0.9841 - val_loss: 0.6501 - val_acc: 1.0000\n",
      "Epoch 1081/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8049 - acc: 0.9841 - val_loss: 0.6500 - val_acc: 1.0000\n",
      "Epoch 1082/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 1.0000 - val_loss: 0.6494 - val_acc: 1.0000\n",
      "Epoch 1083/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8060 - acc: 0.9524 - val_loss: 0.6488 - val_acc: 1.0000\n",
      "Epoch 1084/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7743 - acc: 1.0000 - val_loss: 0.6490 - val_acc: 1.0000\n",
      "Epoch 1085/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7293 - acc: 0.9841 - val_loss: 0.6494 - val_acc: 1.0000\n",
      "Epoch 1086/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7400 - acc: 0.9841 - val_loss: 0.6494 - val_acc: 1.0000\n",
      "Epoch 1087/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7425 - acc: 1.0000 - val_loss: 0.6494 - val_acc: 1.0000\n",
      "Epoch 1088/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7090 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 1.0000\n",
      "Epoch 1089/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7613 - acc: 0.9683 - val_loss: 0.6489 - val_acc: 1.0000\n",
      "Epoch 1090/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7682 - acc: 0.9841 - val_loss: 0.6487 - val_acc: 1.0000\n",
      "Epoch 1091/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7561 - acc: 0.9841 - val_loss: 0.6488 - val_acc: 1.0000\n",
      "Epoch 1092/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7786 - acc: 0.9841 - val_loss: 0.6486 - val_acc: 1.0000\n",
      "Epoch 1093/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7948 - acc: 0.9683 - val_loss: 0.6492 - val_acc: 1.0000\n",
      "Epoch 1094/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7438 - acc: 0.9841 - val_loss: 0.6494 - val_acc: 1.0000\n",
      "Epoch 1095/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7424 - acc: 0.9683 - val_loss: 0.6492 - val_acc: 1.0000\n",
      "Epoch 1096/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7234 - acc: 1.0000 - val_loss: 0.6489 - val_acc: 1.0000\n",
      "Epoch 1097/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7377 - acc: 0.9841 - val_loss: 0.6482 - val_acc: 1.0000\n",
      "Epoch 1098/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7692 - acc: 0.9683 - val_loss: 0.6481 - val_acc: 1.0000\n",
      "Epoch 1099/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7260 - acc: 0.9841 - val_loss: 0.6482 - val_acc: 1.0000\n",
      "Epoch 1100/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7309 - acc: 0.9683 - val_loss: 0.6478 - val_acc: 1.0000\n",
      "Epoch 1101/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7379 - acc: 0.9841 - val_loss: 0.6474 - val_acc: 1.0000\n",
      "Epoch 1102/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7320 - acc: 0.9683 - val_loss: 0.6469 - val_acc: 1.0000\n",
      "Epoch 1103/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7150 - acc: 0.9841 - val_loss: 0.6465 - val_acc: 1.0000\n",
      "Epoch 1104/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7155 - acc: 1.0000 - val_loss: 0.6461 - val_acc: 1.0000\n",
      "Epoch 1105/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7479 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 1.0000\n",
      "Epoch 1106/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7369 - acc: 1.0000 - val_loss: 0.6457 - val_acc: 1.0000\n",
      "Epoch 1107/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7864 - acc: 0.9841 - val_loss: 0.6460 - val_acc: 1.0000\n",
      "Epoch 1108/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7841 - acc: 0.9683 - val_loss: 0.6467 - val_acc: 1.0000\n",
      "Epoch 1109/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7626 - acc: 0.9841 - val_loss: 0.6479 - val_acc: 1.0000\n",
      "Epoch 1110/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7219 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 1.0000\n",
      "Epoch 1111/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7644 - acc: 0.9841 - val_loss: 0.6478 - val_acc: 1.0000\n",
      "Epoch 1112/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7964 - acc: 0.9365 - val_loss: 0.6475 - val_acc: 1.0000\n",
      "Epoch 1113/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8131 - acc: 0.9683 - val_loss: 0.6478 - val_acc: 1.0000\n",
      "Epoch 1114/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7237 - acc: 1.0000 - val_loss: 0.6481 - val_acc: 1.0000\n",
      "Epoch 1115/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7765 - acc: 0.9683 - val_loss: 0.6479 - val_acc: 1.0000\n",
      "Epoch 1116/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7345 - acc: 0.9841 - val_loss: 0.6478 - val_acc: 1.0000\n",
      "Epoch 1117/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7965 - acc: 0.9524 - val_loss: 0.6476 - val_acc: 1.0000\n",
      "Epoch 1118/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7615 - acc: 0.9841 - val_loss: 0.6474 - val_acc: 1.0000\n",
      "Epoch 1119/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7474 - acc: 0.9841 - val_loss: 0.6471 - val_acc: 1.0000\n",
      "Epoch 1120/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7417 - acc: 0.9841 - val_loss: 0.6467 - val_acc: 1.0000\n",
      "Epoch 1121/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7511 - acc: 0.9841 - val_loss: 0.6462 - val_acc: 1.0000\n",
      "Epoch 1122/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7705 - acc: 0.9524 - val_loss: 0.6464 - val_acc: 1.0000\n",
      "Epoch 1123/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7582 - acc: 0.9841 - val_loss: 0.6467 - val_acc: 1.0000\n",
      "Epoch 1124/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7504 - acc: 0.9841 - val_loss: 0.6467 - val_acc: 1.0000\n",
      "Epoch 1125/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7204 - acc: 1.0000 - val_loss: 0.6463 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01125: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 1126/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7458 - acc: 1.0000 - val_loss: 0.6458 - val_acc: 1.0000\n",
      "Epoch 1127/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7353 - acc: 1.0000 - val_loss: 0.6455 - val_acc: 1.0000\n",
      "Epoch 1128/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7710 - acc: 0.9683 - val_loss: 0.6452 - val_acc: 1.0000\n",
      "Epoch 1129/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8215 - acc: 0.9524 - val_loss: 0.6449 - val_acc: 1.0000\n",
      "Epoch 1130/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7695 - acc: 0.9683 - val_loss: 0.6450 - val_acc: 1.0000\n",
      "Epoch 1131/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6903 - acc: 1.0000 - val_loss: 0.6446 - val_acc: 1.0000\n",
      "Epoch 1132/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7508 - acc: 0.9841 - val_loss: 0.6442 - val_acc: 1.0000\n",
      "Epoch 1133/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7657 - acc: 0.9683 - val_loss: 0.6441 - val_acc: 1.0000\n",
      "Epoch 1134/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7795 - acc: 0.9683 - val_loss: 0.6441 - val_acc: 1.0000\n",
      "Epoch 1135/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7290 - acc: 0.9841 - val_loss: 0.6439 - val_acc: 1.0000\n",
      "Epoch 1136/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7555 - acc: 0.9524 - val_loss: 0.6437 - val_acc: 1.0000\n",
      "Epoch 1137/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6961 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 1.0000\n",
      "Epoch 1138/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6998 - acc: 1.0000 - val_loss: 0.6428 - val_acc: 1.0000\n",
      "Epoch 1139/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7830 - acc: 0.9683 - val_loss: 0.6426 - val_acc: 1.0000\n",
      "Epoch 1140/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7418 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 1.0000\n",
      "Epoch 1141/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7419 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 1.0000\n",
      "Epoch 1142/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7401 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 1.0000\n",
      "Epoch 1143/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7225 - acc: 1.0000 - val_loss: 0.6422 - val_acc: 1.0000\n",
      "Epoch 1144/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7319 - acc: 1.0000 - val_loss: 0.6419 - val_acc: 1.0000\n",
      "Epoch 1145/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7108 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 1.0000\n",
      "Epoch 1146/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7353 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 1.0000\n",
      "Epoch 1147/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7267 - acc: 1.0000 - val_loss: 0.6411 - val_acc: 1.0000\n",
      "Epoch 1148/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7567 - acc: 0.9683 - val_loss: 0.6410 - val_acc: 1.0000\n",
      "Epoch 1149/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7806 - acc: 0.9841 - val_loss: 0.6412 - val_acc: 1.0000\n",
      "Epoch 1150/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7301 - acc: 0.9841 - val_loss: 0.6414 - val_acc: 1.0000\n",
      "Epoch 1151/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7317 - acc: 0.9841 - val_loss: 0.6413 - val_acc: 1.0000\n",
      "Epoch 1152/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6928 - acc: 1.0000 - val_loss: 0.6412 - val_acc: 1.0000\n",
      "Epoch 1153/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7410 - acc: 0.9841 - val_loss: 0.6410 - val_acc: 1.0000\n",
      "Epoch 1154/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7325 - acc: 0.9683 - val_loss: 0.6409 - val_acc: 1.0000\n",
      "Epoch 1155/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7723 - acc: 0.9683 - val_loss: 0.6410 - val_acc: 1.0000\n",
      "Epoch 1156/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7802 - acc: 0.9841 - val_loss: 0.6413 - val_acc: 1.0000\n",
      "Epoch 1157/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7623 - acc: 0.9841 - val_loss: 0.6412 - val_acc: 1.0000\n",
      "Epoch 1158/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8026 - acc: 0.9683 - val_loss: 0.6415 - val_acc: 1.0000\n",
      "Epoch 1159/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7168 - acc: 1.0000 - val_loss: 0.6414 - val_acc: 1.0000\n",
      "Epoch 1160/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7679 - acc: 0.9841 - val_loss: 0.6412 - val_acc: 1.0000\n",
      "Epoch 1161/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7145 - acc: 1.0000 - val_loss: 0.6410 - val_acc: 1.0000\n",
      "Epoch 1162/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7257 - acc: 1.0000 - val_loss: 0.6407 - val_acc: 1.0000\n",
      "Epoch 1163/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7670 - acc: 0.9841 - val_loss: 0.6407 - val_acc: 1.0000\n",
      "Epoch 1164/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6860 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 1.0000\n",
      "Epoch 1165/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6943 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 1.0000\n",
      "Epoch 1166/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7234 - acc: 1.0000 - val_loss: 0.6398 - val_acc: 1.0000\n",
      "Epoch 1167/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7131 - acc: 1.0000 - val_loss: 0.6395 - val_acc: 1.0000\n",
      "Epoch 1168/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7430 - acc: 0.9683 - val_loss: 0.6393 - val_acc: 1.0000\n",
      "Epoch 1169/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7233 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 1.0000\n",
      "Epoch 1170/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7397 - acc: 0.9683 - val_loss: 0.6396 - val_acc: 1.0000\n",
      "Epoch 1171/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7910 - acc: 0.9683 - val_loss: 0.6396 - val_acc: 1.0000\n",
      "Epoch 1172/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7939 - acc: 0.9206 - val_loss: 0.6397 - val_acc: 1.0000\n",
      "Epoch 1173/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7560 - acc: 1.0000 - val_loss: 0.6402 - val_acc: 1.0000\n",
      "Epoch 1174/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7319 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 1.0000\n",
      "Epoch 1175/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7736 - acc: 0.9683 - val_loss: 0.6403 - val_acc: 1.0000\n",
      "Epoch 1176/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7520 - acc: 0.9841 - val_loss: 0.6405 - val_acc: 1.0000\n",
      "Epoch 1177/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6975 - acc: 1.0000 - val_loss: 0.6401 - val_acc: 1.0000\n",
      "Epoch 1178/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8035 - acc: 0.9365 - val_loss: 0.6400 - val_acc: 1.0000\n",
      "Epoch 1179/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7279 - acc: 1.0000 - val_loss: 0.6400 - val_acc: 1.0000\n",
      "Epoch 1180/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7427 - acc: 0.9841 - val_loss: 0.6399 - val_acc: 1.0000\n",
      "Epoch 1181/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7332 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 1.0000\n",
      "Epoch 1182/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7345 - acc: 0.9841 - val_loss: 0.6392 - val_acc: 1.0000\n",
      "Epoch 1183/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7372 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 1.0000\n",
      "Epoch 1184/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8251 - acc: 0.9683 - val_loss: 0.6392 - val_acc: 1.0000\n",
      "Epoch 1185/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7278 - acc: 0.9841 - val_loss: 0.6394 - val_acc: 1.0000\n",
      "Epoch 1186/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6987 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 1.0000\n",
      "Epoch 1187/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7796 - acc: 0.9683 - val_loss: 0.6390 - val_acc: 1.0000\n",
      "Epoch 1188/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7431 - acc: 0.9683 - val_loss: 0.6393 - val_acc: 1.0000\n",
      "Epoch 1189/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7036 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 1.0000\n",
      "Epoch 1190/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7217 - acc: 0.9683 - val_loss: 0.6388 - val_acc: 1.0000\n",
      "Epoch 1191/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7805 - acc: 0.9683 - val_loss: 0.6386 - val_acc: 1.0000\n",
      "Epoch 1192/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7095 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 1.0000\n",
      "Epoch 1193/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7562 - acc: 0.9524 - val_loss: 0.6385 - val_acc: 1.0000\n",
      "Epoch 1194/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7148 - acc: 1.0000 - val_loss: 0.6386 - val_acc: 1.0000\n",
      "Epoch 1195/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7779 - acc: 0.9683 - val_loss: 0.6386 - val_acc: 1.0000\n",
      "Epoch 1196/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7991 - acc: 0.9683 - val_loss: 0.6390 - val_acc: 1.0000\n",
      "Epoch 1197/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7760 - acc: 0.9841 - val_loss: 0.6393 - val_acc: 1.0000\n",
      "Epoch 1198/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7559 - acc: 0.9841 - val_loss: 0.6394 - val_acc: 1.0000\n",
      "Epoch 1199/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.9841 - val_loss: 0.6391 - val_acc: 1.0000\n",
      "Epoch 1200/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7429 - acc: 1.0000 - val_loss: 0.6388 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1201/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6939 - acc: 1.0000 - val_loss: 0.6385 - val_acc: 1.0000\n",
      "Epoch 1202/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7257 - acc: 1.0000 - val_loss: 0.6382 - val_acc: 1.0000\n",
      "Epoch 1203/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7359 - acc: 0.9841 - val_loss: 0.6379 - val_acc: 1.0000\n",
      "Epoch 1204/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7420 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 1.0000\n",
      "Epoch 1205/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7462 - acc: 0.9841 - val_loss: 0.6377 - val_acc: 1.0000\n",
      "Epoch 1206/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7939 - acc: 0.9524 - val_loss: 0.6381 - val_acc: 1.0000\n",
      "Epoch 1207/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7755 - acc: 0.9683 - val_loss: 0.6381 - val_acc: 1.0000\n",
      "Epoch 1208/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7213 - acc: 1.0000 - val_loss: 0.6381 - val_acc: 1.0000\n",
      "Epoch 1209/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7142 - acc: 1.0000 - val_loss: 0.6378 - val_acc: 1.0000\n",
      "Epoch 1210/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6807 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 1.0000\n",
      "Epoch 1211/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7133 - acc: 0.9841 - val_loss: 0.6369 - val_acc: 1.0000\n",
      "Epoch 1212/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7621 - acc: 1.0000 - val_loss: 0.6369 - val_acc: 1.0000\n",
      "Epoch 1213/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7449 - acc: 0.9841 - val_loss: 0.6369 - val_acc: 1.0000\n",
      "Epoch 1214/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7378 - acc: 0.9841 - val_loss: 0.6370 - val_acc: 1.0000\n",
      "Epoch 1215/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7641 - acc: 0.9841 - val_loss: 0.6372 - val_acc: 1.0000\n",
      "Epoch 1216/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7215 - acc: 0.9841 - val_loss: 0.6370 - val_acc: 1.0000\n",
      "Epoch 1217/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6693 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 1.0000\n",
      "Epoch 1218/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7466 - acc: 0.9841 - val_loss: 0.6361 - val_acc: 1.0000\n",
      "Epoch 1219/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7984 - acc: 0.9841 - val_loss: 0.6363 - val_acc: 1.0000\n",
      "Epoch 1220/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7833 - acc: 0.9683 - val_loss: 0.6370 - val_acc: 1.0000\n",
      "Epoch 1221/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7501 - acc: 0.9683 - val_loss: 0.6371 - val_acc: 1.0000\n",
      "Epoch 1222/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7475 - acc: 0.9841 - val_loss: 0.6372 - val_acc: 1.0000\n",
      "Epoch 1223/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7683 - acc: 0.9683 - val_loss: 0.6374 - val_acc: 1.0000\n",
      "Epoch 1224/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6882 - acc: 1.0000 - val_loss: 0.6372 - val_acc: 1.0000\n",
      "Epoch 1225/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7137 - acc: 0.9841 - val_loss: 0.6369 - val_acc: 1.0000\n",
      "Epoch 1226/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7521 - acc: 0.9683 - val_loss: 0.6366 - val_acc: 1.0000\n",
      "Epoch 1227/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7047 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 1.0000\n",
      "Epoch 1228/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7253 - acc: 1.0000 - val_loss: 0.6362 - val_acc: 1.0000\n",
      "Epoch 1229/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7371 - acc: 0.9841 - val_loss: 0.6364 - val_acc: 1.0000\n",
      "Epoch 1230/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6976 - acc: 0.9841 - val_loss: 0.6362 - val_acc: 1.0000\n",
      "Epoch 1231/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7257 - acc: 1.0000 - val_loss: 0.6359 - val_acc: 1.0000\n",
      "Epoch 1232/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7635 - acc: 0.9683 - val_loss: 0.6359 - val_acc: 1.0000\n",
      "Epoch 1233/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7188 - acc: 0.9841 - val_loss: 0.6357 - val_acc: 1.0000\n",
      "Epoch 1234/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7965 - acc: 0.9524 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1235/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7285 - acc: 0.9841 - val_loss: 0.6359 - val_acc: 1.0000\n",
      "Epoch 1236/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7323 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1237/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7187 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 1.0000\n",
      "Epoch 1238/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8086 - acc: 0.9841 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1239/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6978 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1240/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6872 - acc: 1.0000 - val_loss: 0.6354 - val_acc: 1.0000\n",
      "Epoch 1241/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7369 - acc: 0.9524 - val_loss: 0.6351 - val_acc: 1.0000\n",
      "Epoch 1242/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7958 - acc: 0.9524 - val_loss: 0.6353 - val_acc: 1.0000\n",
      "Epoch 1243/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6980 - acc: 0.9841 - val_loss: 0.6354 - val_acc: 1.0000\n",
      "Epoch 1244/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7419 - acc: 0.9841 - val_loss: 0.6353 - val_acc: 1.0000\n",
      "Epoch 1245/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8005 - acc: 0.9365 - val_loss: 0.6359 - val_acc: 1.0000\n",
      "Epoch 1246/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7232 - acc: 0.9841 - val_loss: 0.6361 - val_acc: 1.0000\n",
      "Epoch 1247/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7511 - acc: 0.9841 - val_loss: 0.6360 - val_acc: 1.0000\n",
      "Epoch 1248/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7006 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1249/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7326 - acc: 0.9683 - val_loss: 0.6356 - val_acc: 1.0000\n",
      "Epoch 1250/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7818 - acc: 0.9524 - val_loss: 0.6356 - val_acc: 1.0000\n",
      "Epoch 1251/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7515 - acc: 0.9841 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1252/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7485 - acc: 0.9841 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 1253/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7064 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 1.0000\n",
      "Epoch 1254/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7486 - acc: 1.0000 - val_loss: 0.6354 - val_acc: 1.0000\n",
      "Epoch 1255/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7119 - acc: 0.9841 - val_loss: 0.6352 - val_acc: 1.0000\n",
      "Epoch 1256/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7162 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 1.0000\n",
      "Epoch 1257/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7472 - acc: 0.9841 - val_loss: 0.6349 - val_acc: 1.0000\n",
      "Epoch 1258/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7647 - acc: 0.9683 - val_loss: 0.6349 - val_acc: 1.0000\n",
      "Epoch 1259/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7314 - acc: 1.0000 - val_loss: 0.6350 - val_acc: 1.0000\n",
      "Epoch 1260/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6816 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 1.0000\n",
      "Epoch 1261/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7107 - acc: 1.0000 - val_loss: 0.6345 - val_acc: 1.0000\n",
      "Epoch 1262/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6914 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 1.0000\n",
      "Epoch 1263/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7789 - acc: 0.9683 - val_loss: 0.6342 - val_acc: 1.0000\n",
      "Epoch 1264/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7454 - acc: 0.9683 - val_loss: 0.6341 - val_acc: 1.0000\n",
      "Epoch 1265/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7447 - acc: 1.0000 - val_loss: 0.6345 - val_acc: 1.0000\n",
      "Epoch 1266/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7126 - acc: 0.9841 - val_loss: 0.6345 - val_acc: 1.0000\n",
      "Epoch 1267/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7037 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 1.0000\n",
      "Epoch 1268/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7631 - acc: 0.9841 - val_loss: 0.6346 - val_acc: 1.0000\n",
      "Epoch 1269/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6915 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 1.0000\n",
      "Epoch 1270/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8227 - acc: 0.9524 - val_loss: 0.6351 - val_acc: 1.0000\n",
      "Epoch 1271/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7474 - acc: 0.9841 - val_loss: 0.6353 - val_acc: 1.0000\n",
      "Epoch 1272/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7296 - acc: 0.9841 - val_loss: 0.6352 - val_acc: 1.0000\n",
      "Epoch 1273/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7062 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 1.0000\n",
      "Epoch 1274/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7413 - acc: 0.9841 - val_loss: 0.6347 - val_acc: 1.0000\n",
      "Epoch 1275/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6911 - acc: 0.9683 - val_loss: 0.6345 - val_acc: 1.0000\n",
      "Epoch 1276/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7970 - acc: 0.9206 - val_loss: 0.6345 - val_acc: 1.0000\n",
      "Epoch 1277/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6929 - acc: 1.0000 - val_loss: 0.6344 - val_acc: 1.0000\n",
      "Epoch 1278/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7405 - acc: 0.9841 - val_loss: 0.6340 - val_acc: 1.0000\n",
      "Epoch 1279/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6993 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 1.0000\n",
      "Epoch 1280/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7506 - acc: 0.9841 - val_loss: 0.6337 - val_acc: 1.0000\n",
      "Epoch 1281/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7129 - acc: 1.0000 - val_loss: 0.6339 - val_acc: 1.0000\n",
      "Epoch 1282/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7002 - acc: 1.0000 - val_loss: 0.6336 - val_acc: 1.0000\n",
      "Epoch 1283/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7492 - acc: 0.9841 - val_loss: 0.6337 - val_acc: 1.0000\n",
      "Epoch 1284/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7275 - acc: 0.9841 - val_loss: 0.6337 - val_acc: 1.0000\n",
      "Epoch 1285/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7469 - acc: 0.9841 - val_loss: 0.6334 - val_acc: 1.0000\n",
      "Epoch 1286/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7211 - acc: 0.9841 - val_loss: 0.6332 - val_acc: 1.0000\n",
      "Epoch 1287/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7813 - acc: 0.9841 - val_loss: 0.6334 - val_acc: 1.0000\n",
      "Epoch 1288/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7699 - acc: 0.9683 - val_loss: 0.6335 - val_acc: 1.0000\n",
      "Epoch 1289/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7178 - acc: 1.0000 - val_loss: 0.6336 - val_acc: 1.0000\n",
      "Epoch 1290/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7616 - acc: 0.9683 - val_loss: 0.6336 - val_acc: 1.0000\n",
      "Epoch 1291/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6721 - acc: 1.0000 - val_loss: 0.6334 - val_acc: 1.0000\n",
      "Epoch 1292/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7291 - acc: 0.9841 - val_loss: 0.6330 - val_acc: 1.0000\n",
      "Epoch 1293/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7096 - acc: 1.0000 - val_loss: 0.6330 - val_acc: 1.0000\n",
      "Epoch 1294/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6853 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 1.0000\n",
      "Epoch 1295/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7147 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 1.0000\n",
      "Epoch 1296/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7038 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1297/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8091 - acc: 0.9524 - val_loss: 0.6322 - val_acc: 1.0000\n",
      "Epoch 1298/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7520 - acc: 0.9683 - val_loss: 0.6325 - val_acc: 1.0000\n",
      "Epoch 1299/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6930 - acc: 1.0000 - val_loss: 0.6325 - val_acc: 1.0000\n",
      "Epoch 1300/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7817 - acc: 0.9683 - val_loss: 0.6326 - val_acc: 1.0000\n",
      "Epoch 1301/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7730 - acc: 0.9524 - val_loss: 0.6328 - val_acc: 1.0000\n",
      "Epoch 1302/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7371 - acc: 0.9683 - val_loss: 0.6329 - val_acc: 1.0000\n",
      "Epoch 1303/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7565 - acc: 0.9841 - val_loss: 0.6329 - val_acc: 1.0000\n",
      "Epoch 1304/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7684 - acc: 0.9841 - val_loss: 0.6328 - val_acc: 1.0000\n",
      "Epoch 1305/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7107 - acc: 1.0000 - val_loss: 0.6327 - val_acc: 1.0000\n",
      "Epoch 1306/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7183 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 1.0000\n",
      "Epoch 1307/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7306 - acc: 1.0000 - val_loss: 0.6319 - val_acc: 1.0000\n",
      "Epoch 1308/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7322 - acc: 0.9841 - val_loss: 0.6318 - val_acc: 1.0000\n",
      "Epoch 1309/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8074 - acc: 0.9683 - val_loss: 0.6319 - val_acc: 1.0000\n",
      "Epoch 1310/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7292 - acc: 0.9841 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1311/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7021 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1312/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7476 - acc: 0.9683 - val_loss: 0.6321 - val_acc: 1.0000\n",
      "Epoch 1313/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7440 - acc: 1.0000 - val_loss: 0.6323 - val_acc: 1.0000\n",
      "Epoch 1314/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7304 - acc: 0.9683 - val_loss: 0.6323 - val_acc: 1.0000\n",
      "Epoch 1315/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7419 - acc: 0.9841 - val_loss: 0.6325 - val_acc: 1.0000\n",
      "Epoch 1316/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7743 - acc: 0.9841 - val_loss: 0.6327 - val_acc: 1.0000\n",
      "Epoch 1317/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6931 - acc: 1.0000 - val_loss: 0.6327 - val_acc: 1.0000\n",
      "Epoch 1318/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7096 - acc: 1.0000 - val_loss: 0.6323 - val_acc: 1.0000\n",
      "Epoch 1319/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7061 - acc: 1.0000 - val_loss: 0.6321 - val_acc: 1.0000\n",
      "Epoch 1320/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7598 - acc: 0.9683 - val_loss: 0.6324 - val_acc: 1.0000\n",
      "Epoch 1321/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7130 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1322/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7051 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 1.0000\n",
      "Epoch 1323/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7343 - acc: 0.9841 - val_loss: 0.6322 - val_acc: 1.0000\n",
      "Epoch 1324/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6899 - acc: 1.0000 - val_loss: 0.6318 - val_acc: 1.0000\n",
      "Epoch 1325/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7141 - acc: 0.9841 - val_loss: 0.6315 - val_acc: 1.0000\n",
      "Epoch 1326/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6832 - acc: 1.0000 - val_loss: 0.6312 - val_acc: 1.0000\n",
      "Epoch 1327/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8214 - acc: 0.9683 - val_loss: 0.6313 - val_acc: 1.0000\n",
      "Epoch 1328/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7201 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1329/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7171 - acc: 1.0000 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1330/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.9683 - val_loss: 0.6319 - val_acc: 1.0000\n",
      "Epoch 1331/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7190 - acc: 1.0000 - val_loss: 0.6317 - val_acc: 1.0000\n",
      "Epoch 1332/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7399 - acc: 0.9841 - val_loss: 0.6315 - val_acc: 1.0000\n",
      "Epoch 1333/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8229 - acc: 0.9365 - val_loss: 0.6318 - val_acc: 1.0000\n",
      "Epoch 1334/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7413 - acc: 0.9683 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1335/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7151 - acc: 0.9841 - val_loss: 0.6320 - val_acc: 1.0000\n",
      "Epoch 1336/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7340 - acc: 0.9841 - val_loss: 0.6319 - val_acc: 1.0000\n",
      "Epoch 1337/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7549 - acc: 0.9683 - val_loss: 0.6317 - val_acc: 1.0000\n",
      "Epoch 1338/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7162 - acc: 1.0000 - val_loss: 0.6316 - val_acc: 1.0000\n",
      "Epoch 1339/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7483 - acc: 0.9683 - val_loss: 0.6314 - val_acc: 1.0000\n",
      "Epoch 1340/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7673 - acc: 0.9683 - val_loss: 0.6314 - val_acc: 1.0000\n",
      "Epoch 1341/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 1.0000 - val_loss: 0.6314 - val_acc: 1.0000\n",
      "Epoch 1342/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6977 - acc: 1.0000 - val_loss: 0.6313 - val_acc: 1.0000\n",
      "Epoch 1343/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6914 - acc: 0.9841 - val_loss: 0.6311 - val_acc: 1.0000\n",
      "Epoch 1344/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7510 - acc: 0.9841 - val_loss: 0.6307 - val_acc: 1.0000\n",
      "Epoch 1345/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7422 - acc: 0.9841 - val_loss: 0.6306 - val_acc: 1.0000\n",
      "Epoch 1346/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7676 - acc: 0.9841 - val_loss: 0.6311 - val_acc: 1.0000\n",
      "Epoch 1347/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7551 - acc: 0.9841 - val_loss: 0.6312 - val_acc: 1.0000\n",
      "Epoch 1348/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 1.0000 - val_loss: 0.6311 - val_acc: 1.0000\n",
      "Epoch 1349/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7885 - acc: 0.9683 - val_loss: 0.6311 - val_acc: 1.0000\n",
      "Epoch 1350/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7242 - acc: 0.9841 - val_loss: 0.6315 - val_acc: 1.0000\n",
      "Epoch 1351/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7232 - acc: 1.0000 - val_loss: 0.6312 - val_acc: 1.0000\n",
      "Epoch 1352/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7153 - acc: 0.9841 - val_loss: 0.6309 - val_acc: 1.0000\n",
      "Epoch 1353/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7053 - acc: 0.9683 - val_loss: 0.6307 - val_acc: 1.0000\n",
      "Epoch 1354/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7578 - acc: 0.9683 - val_loss: 0.6304 - val_acc: 1.0000\n",
      "Epoch 1355/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7272 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 1.0000\n",
      "Epoch 1356/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7378 - acc: 0.9841 - val_loss: 0.6303 - val_acc: 1.0000\n",
      "Epoch 1357/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8422 - acc: 0.9524 - val_loss: 0.6306 - val_acc: 1.0000\n",
      "Epoch 1358/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7596 - acc: 0.9524 - val_loss: 0.6313 - val_acc: 1.0000\n",
      "Epoch 1359/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7262 - acc: 0.9841 - val_loss: 0.6313 - val_acc: 1.0000\n",
      "Epoch 1360/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6991 - acc: 1.0000 - val_loss: 0.6310 - val_acc: 1.0000\n",
      "Epoch 1361/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8393 - acc: 0.9524 - val_loss: 0.6312 - val_acc: 1.0000\n",
      "Epoch 1362/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 1.0000 - val_loss: 0.6312 - val_acc: 1.0000\n",
      "Epoch 1363/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7123 - acc: 0.9683 - val_loss: 0.6307 - val_acc: 1.0000\n",
      "Epoch 1364/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7395 - acc: 0.9683 - val_loss: 0.6305 - val_acc: 1.0000\n",
      "Epoch 1365/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 1.0000 - val_loss: 0.6301 - val_acc: 1.0000\n",
      "Epoch 1366/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7040 - acc: 0.9841 - val_loss: 0.6296 - val_acc: 1.0000\n",
      "Epoch 1367/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7569 - acc: 0.9841 - val_loss: 0.6296 - val_acc: 1.0000\n",
      "Epoch 1368/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7435 - acc: 0.9841 - val_loss: 0.6297 - val_acc: 1.0000\n",
      "Epoch 1369/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7198 - acc: 0.9841 - val_loss: 0.6297 - val_acc: 1.0000\n",
      "Epoch 1370/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6795 - acc: 1.0000 - val_loss: 0.6295 - val_acc: 1.0000\n",
      "Epoch 1371/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7499 - acc: 0.9524 - val_loss: 0.6294 - val_acc: 1.0000\n",
      "Epoch 1372/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7183 - acc: 0.9841 - val_loss: 0.6295 - val_acc: 1.0000\n",
      "Epoch 1373/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6704 - acc: 1.0000 - val_loss: 0.6292 - val_acc: 1.0000\n",
      "Epoch 1374/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7063 - acc: 1.0000 - val_loss: 0.6289 - val_acc: 1.0000\n",
      "Epoch 1375/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7081 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 1.0000\n",
      "Epoch 1376/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6995 - acc: 0.9841 - val_loss: 0.6284 - val_acc: 1.0000\n",
      "Epoch 1377/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7135 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 1.0000\n",
      "Epoch 1378/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7219 - acc: 0.9841 - val_loss: 0.6286 - val_acc: 1.0000\n",
      "Epoch 1379/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7869 - acc: 0.9524 - val_loss: 0.6293 - val_acc: 1.0000\n",
      "Epoch 1380/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7013 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 1.0000\n",
      "Epoch 1381/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6834 - acc: 1.0000 - val_loss: 0.6290 - val_acc: 1.0000\n",
      "Epoch 1382/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7179 - acc: 0.9841 - val_loss: 0.6287 - val_acc: 1.0000\n",
      "Epoch 1383/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7319 - acc: 0.9841 - val_loss: 0.6286 - val_acc: 1.0000\n",
      "Epoch 1384/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7288 - acc: 0.9841 - val_loss: 0.6286 - val_acc: 1.0000\n",
      "Epoch 1385/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7706 - acc: 0.9841 - val_loss: 0.6287 - val_acc: 1.0000\n",
      "Epoch 1386/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7151 - acc: 1.0000 - val_loss: 0.6293 - val_acc: 1.0000\n",
      "Epoch 1387/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8126 - acc: 0.9206 - val_loss: 0.6297 - val_acc: 1.0000\n",
      "Epoch 1388/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7383 - acc: 1.0000 - val_loss: 0.6299 - val_acc: 1.0000\n",
      "Epoch 1389/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7655 - acc: 0.9524 - val_loss: 0.6298 - val_acc: 1.0000\n",
      "Epoch 1390/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7177 - acc: 0.9841 - val_loss: 0.6296 - val_acc: 1.0000\n",
      "Epoch 1391/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7091 - acc: 0.9841 - val_loss: 0.6292 - val_acc: 1.0000\n",
      "Epoch 1392/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7066 - acc: 1.0000 - val_loss: 0.6290 - val_acc: 1.0000\n",
      "Epoch 1393/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6973 - acc: 1.0000 - val_loss: 0.6286 - val_acc: 1.0000\n",
      "Epoch 1394/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7264 - acc: 0.9841 - val_loss: 0.6285 - val_acc: 1.0000\n",
      "Epoch 1395/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7158 - acc: 0.9841 - val_loss: 0.6285 - val_acc: 1.0000\n",
      "Epoch 1396/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7377 - acc: 0.9683 - val_loss: 0.6286 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01396: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 1397/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7172 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 1.0000\n",
      "Epoch 1398/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7215 - acc: 1.0000 - val_loss: 0.6283 - val_acc: 1.0000\n",
      "Epoch 1399/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 1.0000 - val_loss: 0.6281 - val_acc: 1.0000\n",
      "Epoch 1400/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7408 - acc: 0.9683 - val_loss: 0.6279 - val_acc: 1.0000\n",
      "Epoch 1401/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7210 - acc: 0.9841 - val_loss: 0.6278 - val_acc: 1.0000\n",
      "Epoch 1402/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7594 - acc: 0.9841 - val_loss: 0.6278 - val_acc: 1.0000\n",
      "Epoch 1403/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7221 - acc: 0.9841 - val_loss: 0.6277 - val_acc: 1.0000\n",
      "Epoch 1404/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6940 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 1.0000\n",
      "Epoch 1405/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7564 - acc: 0.9683 - val_loss: 0.6273 - val_acc: 1.0000\n",
      "Epoch 1406/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7570 - acc: 0.9841 - val_loss: 0.6274 - val_acc: 1.0000\n",
      "Epoch 1407/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7245 - acc: 0.9841 - val_loss: 0.6274 - val_acc: 1.0000\n",
      "Epoch 1408/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7625 - acc: 0.9841 - val_loss: 0.6274 - val_acc: 1.0000\n",
      "Epoch 1409/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7235 - acc: 1.0000 - val_loss: 0.6273 - val_acc: 1.0000\n",
      "Epoch 1410/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7289 - acc: 0.9683 - val_loss: 0.6272 - val_acc: 1.0000\n",
      "Epoch 1411/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7356 - acc: 0.9683 - val_loss: 0.6271 - val_acc: 1.0000\n",
      "Epoch 1412/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6861 - acc: 0.9841 - val_loss: 0.6270 - val_acc: 1.0000\n",
      "Epoch 1413/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7088 - acc: 1.0000 - val_loss: 0.6268 - val_acc: 1.0000\n",
      "Epoch 1414/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7491 - acc: 0.9841 - val_loss: 0.6268 - val_acc: 1.0000\n",
      "Epoch 1415/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7165 - acc: 1.0000 - val_loss: 0.6267 - val_acc: 1.0000\n",
      "Epoch 1416/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7440 - acc: 0.9841 - val_loss: 0.6266 - val_acc: 1.0000\n",
      "Epoch 1417/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7997 - acc: 0.9524 - val_loss: 0.6267 - val_acc: 1.0000\n",
      "Epoch 1418/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7637 - acc: 0.9841 - val_loss: 0.6269 - val_acc: 1.0000\n",
      "Epoch 1419/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.9841 - val_loss: 0.6270 - val_acc: 1.0000\n",
      "Epoch 1420/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7266 - acc: 0.9841 - val_loss: 0.6269 - val_acc: 1.0000\n",
      "Epoch 1421/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7260 - acc: 0.9841 - val_loss: 0.6268 - val_acc: 1.0000\n",
      "Epoch 1422/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7301 - acc: 0.9683 - val_loss: 0.6267 - val_acc: 1.0000\n",
      "Epoch 1423/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7716 - acc: 0.9841 - val_loss: 0.6266 - val_acc: 1.0000\n",
      "Epoch 1424/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7363 - acc: 0.9841 - val_loss: 0.6267 - val_acc: 1.0000\n",
      "Epoch 1425/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7413 - acc: 1.0000 - val_loss: 0.6267 - val_acc: 1.0000\n",
      "Epoch 1426/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.9524 - val_loss: 0.6267 - val_acc: 1.0000\n",
      "Epoch 1427/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7560 - acc: 0.9524 - val_loss: 0.6266 - val_acc: 1.0000\n",
      "Epoch 1428/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7120 - acc: 0.9841 - val_loss: 0.6266 - val_acc: 1.0000\n",
      "Epoch 1429/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6988 - acc: 0.9841 - val_loss: 0.6266 - val_acc: 1.0000\n",
      "Epoch 1430/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7654 - acc: 0.9841 - val_loss: 0.6265 - val_acc: 1.0000\n",
      "Epoch 1431/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7728 - acc: 1.0000 - val_loss: 0.6265 - val_acc: 1.0000\n",
      "Epoch 1432/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7330 - acc: 0.9683 - val_loss: 0.6265 - val_acc: 1.0000\n",
      "Epoch 1433/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7400 - acc: 0.9841 - val_loss: 0.6265 - val_acc: 1.0000\n",
      "Epoch 1434/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7411 - acc: 0.9683 - val_loss: 0.6264 - val_acc: 1.0000\n",
      "Epoch 1435/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6831 - acc: 1.0000 - val_loss: 0.6264 - val_acc: 1.0000\n",
      "Epoch 1436/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7031 - acc: 0.9841 - val_loss: 0.6262 - val_acc: 1.0000\n",
      "Epoch 1437/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7053 - acc: 0.9841 - val_loss: 0.6260 - val_acc: 1.0000\n",
      "Epoch 1438/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7308 - acc: 0.9683 - val_loss: 0.6258 - val_acc: 1.0000\n",
      "Epoch 1439/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7422 - acc: 0.9841 - val_loss: 0.6258 - val_acc: 1.0000\n",
      "Epoch 1440/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7222 - acc: 0.9841 - val_loss: 0.6259 - val_acc: 1.0000\n",
      "Epoch 1441/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7001 - acc: 0.9841 - val_loss: 0.6258 - val_acc: 1.0000\n",
      "Epoch 1442/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6842 - acc: 0.9841 - val_loss: 0.6257 - val_acc: 1.0000\n",
      "Epoch 1443/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7281 - acc: 0.9841 - val_loss: 0.6256 - val_acc: 1.0000\n",
      "Epoch 1444/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7324 - acc: 1.0000 - val_loss: 0.6257 - val_acc: 1.0000\n",
      "Epoch 1445/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.9841 - val_loss: 0.6257 - val_acc: 1.0000\n",
      "Epoch 1446/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7351 - acc: 0.9524 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1447/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6917 - acc: 1.0000 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1448/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7095 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1449/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7243 - acc: 0.9841 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1450/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7835 - acc: 0.9683 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1451/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7153 - acc: 0.9841 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1452/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7150 - acc: 0.9841 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1453/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6963 - acc: 0.9841 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1454/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7340 - acc: 1.0000 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1455/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7295 - acc: 0.9841 - val_loss: 0.6257 - val_acc: 1.0000\n",
      "Epoch 1456/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7613 - acc: 1.0000 - val_loss: 0.6258 - val_acc: 1.0000\n",
      "Epoch 1457/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7400 - acc: 0.9841 - val_loss: 0.6259 - val_acc: 1.0000\n",
      "Epoch 1458/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7536 - acc: 0.9683 - val_loss: 0.6258 - val_acc: 1.0000\n",
      "Epoch 1459/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6955 - acc: 1.0000 - val_loss: 0.6256 - val_acc: 1.0000\n",
      "Epoch 1460/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7254 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1461/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6976 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 1.0000\n",
      "Epoch 1462/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7873 - acc: 0.9683 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1463/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7271 - acc: 0.9841 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1464/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7080 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 1.0000\n",
      "Epoch 1465/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7541 - acc: 0.9683 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1466/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7236 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1467/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7433 - acc: 0.9841 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1468/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6925 - acc: 1.0000 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1469/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7339 - acc: 0.9683 - val_loss: 0.6253 - val_acc: 1.0000\n",
      "Epoch 1470/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7604 - acc: 0.9683 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1471/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6705 - acc: 0.9841 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1472/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6896 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 1.0000\n",
      "Epoch 1473/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7206 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 1.0000\n",
      "Epoch 1474/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7154 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 1.0000\n",
      "Epoch 1475/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6818 - acc: 1.0000 - val_loss: 0.6249 - val_acc: 1.0000\n",
      "Epoch 1476/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7186 - acc: 0.9841 - val_loss: 0.6248 - val_acc: 1.0000\n",
      "Epoch 1477/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7141 - acc: 1.0000 - val_loss: 0.6249 - val_acc: 1.0000\n",
      "Epoch 1478/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7150 - acc: 1.0000 - val_loss: 0.6248 - val_acc: 1.0000\n",
      "Epoch 1479/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7783 - acc: 0.9524 - val_loss: 0.6248 - val_acc: 1.0000\n",
      "Epoch 1480/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6791 - acc: 1.0000 - val_loss: 0.6249 - val_acc: 1.0000\n",
      "Epoch 1481/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7578 - acc: 0.9841 - val_loss: 0.6249 - val_acc: 1.0000\n",
      "Epoch 1482/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7454 - acc: 0.9683 - val_loss: 0.6250 - val_acc: 1.0000\n",
      "Epoch 1483/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7196 - acc: 1.0000 - val_loss: 0.6250 - val_acc: 1.0000\n",
      "Epoch 1484/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.8039 - acc: 0.9365 - val_loss: 0.6253 - val_acc: 1.0000\n",
      "Epoch 1485/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6945 - acc: 1.0000 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1486/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7717 - acc: 0.9524 - val_loss: 0.6256 - val_acc: 1.0000\n",
      "Epoch 1487/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6804 - acc: 1.0000 - val_loss: 0.6255 - val_acc: 1.0000\n",
      "Epoch 1488/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7722 - acc: 0.9841 - val_loss: 0.6253 - val_acc: 1.0000\n",
      "Epoch 1489/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7756 - acc: 0.9683 - val_loss: 0.6254 - val_acc: 1.0000\n",
      "Epoch 1490/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7143 - acc: 1.0000 - val_loss: 0.6252 - val_acc: 1.0000\n",
      "Epoch 1491/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7061 - acc: 1.0000 - val_loss: 0.6251 - val_acc: 1.0000\n",
      "Epoch 1492/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7011 - acc: 0.9683 - val_loss: 0.6250 - val_acc: 1.0000\n",
      "Epoch 1493/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7191 - acc: 0.9841 - val_loss: 0.6248 - val_acc: 1.0000\n",
      "Epoch 1494/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7402 - acc: 0.9683 - val_loss: 0.6248 - val_acc: 1.0000\n",
      "Epoch 1495/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7051 - acc: 0.9683 - val_loss: 0.6246 - val_acc: 1.0000\n",
      "Epoch 1496/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6753 - acc: 1.0000 - val_loss: 0.6244 - val_acc: 1.0000\n",
      "Epoch 1497/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6830 - acc: 0.9841 - val_loss: 0.6242 - val_acc: 1.0000\n",
      "Epoch 1498/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7176 - acc: 0.9841 - val_loss: 0.6240 - val_acc: 1.0000\n",
      "Epoch 1499/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.6996 - acc: 1.0000 - val_loss: 0.6240 - val_acc: 1.0000\n",
      "Epoch 1500/1500\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.7235 - acc: 0.9841 - val_loss: 0.6239 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dba505e7a09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0ml_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model_neu_ngrams.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_test_data_ngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "neu_ng = Sequential()\n",
    "neu_ng.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "                               input_shape=(scaled_train_data_ngrams.shape[1],)))\n",
    "neu_ng.add(layers.Dropout(0.3))\n",
    "neu_ng.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu_ng.add(layers.Dropout(0.3))\n",
    "neu_ng.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu_ng.add(layers.Dropout(0.3))\n",
    "neu_ng.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "neu_ng.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "neu_ng.summary()\n",
    "history = neu_ng.fit(X_scaled_train_data_ngrams, y_train,\n",
    "                    validation_data=(X_scaled_val_data_ngrams, y_val),\n",
    "                    epochs=1500,\n",
    "                    batch_size=class_size,\n",
    "                    callbacks=callbacks_list_neu_ngrams,\n",
    "                    verbose= 1\n",
    "                   )\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "print(max(val_acc))\n",
    "l_model = load_model('my_model_neu_ngrams.h5')\n",
    "yhat = l_model.predict(scaled_test_data_ngrams)\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print('my_model_neu_ngrams Test Accuracy: %.3f' % acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model_neu_ngrams Test Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "l_model = load_model('my_model_neu_ngrams.h5')\n",
    "yhat = l_model.predict(scaled_test_data_ngrams)\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print('my_model_neu_ngrams Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 32)                243968    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 250,825\n",
      "Trainable params: 250,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 63 samples, validate on 756 samples\n",
      "Epoch 1/2000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 6.3877 - acc: 0.1270 - val_loss: 6.2967 - val_acc: 0.1402\n",
      "Epoch 2/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.2173 - acc: 0.1429 - val_loss: 6.1583 - val_acc: 0.1481\n",
      "Epoch 3/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 6.0948 - acc: 0.2063 - val_loss: 6.0358 - val_acc: 0.1521\n",
      "Epoch 4/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.9704 - acc: 0.1746 - val_loss: 5.9209 - val_acc: 0.1601\n",
      "Epoch 5/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.8781 - acc: 0.1429 - val_loss: 5.8120 - val_acc: 0.1587\n",
      "Epoch 6/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.7594 - acc: 0.2222 - val_loss: 5.7071 - val_acc: 0.1733\n",
      "Epoch 7/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.6607 - acc: 0.1429 - val_loss: 5.6040 - val_acc: 0.1958\n",
      "Epoch 8/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.5447 - acc: 0.1905 - val_loss: 5.5058 - val_acc: 0.2011\n",
      "Epoch 9/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.4479 - acc: 0.2540 - val_loss: 5.4104 - val_acc: 0.2302\n",
      "Epoch 10/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.3466 - acc: 0.2857 - val_loss: 5.3177 - val_acc: 0.2540\n",
      "Epoch 11/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.2697 - acc: 0.2063 - val_loss: 5.2271 - val_acc: 0.2632\n",
      "Epoch 12/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1925 - acc: 0.2222 - val_loss: 5.1406 - val_acc: 0.3082\n",
      "Epoch 13/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.1138 - acc: 0.2698 - val_loss: 5.0580 - val_acc: 0.3294\n",
      "Epoch 14/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 5.0210 - acc: 0.2698 - val_loss: 4.9778 - val_acc: 0.3558\n",
      "Epoch 15/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.9332 - acc: 0.3175 - val_loss: 4.9004 - val_acc: 0.3717\n",
      "Epoch 16/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8861 - acc: 0.2222 - val_loss: 4.8259 - val_acc: 0.3889\n",
      "Epoch 17/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.8219 - acc: 0.3016 - val_loss: 4.7540 - val_acc: 0.4392\n",
      "Epoch 18/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.7585 - acc: 0.2540 - val_loss: 4.6854 - val_acc: 0.4788\n",
      "Epoch 19/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6995 - acc: 0.3175 - val_loss: 4.6176 - val_acc: 0.5238\n",
      "Epoch 20/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.6546 - acc: 0.2857 - val_loss: 4.5501 - val_acc: 0.5741\n",
      "Epoch 21/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.5608 - acc: 0.3175 - val_loss: 4.4847 - val_acc: 0.6124\n",
      "Epoch 22/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4911 - acc: 0.3968 - val_loss: 4.4212 - val_acc: 0.6349\n",
      "Epoch 23/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.4740 - acc: 0.3333 - val_loss: 4.3585 - val_acc: 0.6587\n",
      "Epoch 24/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.3630 - acc: 0.3810 - val_loss: 4.2943 - val_acc: 0.6958\n",
      "Epoch 25/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2803 - acc: 0.4603 - val_loss: 4.2298 - val_acc: 0.7222\n",
      "Epoch 26/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2596 - acc: 0.3810 - val_loss: 4.1697 - val_acc: 0.7394\n",
      "Epoch 27/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2311 - acc: 0.4286 - val_loss: 4.1109 - val_acc: 0.7513\n",
      "Epoch 28/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.2009 - acc: 0.3810 - val_loss: 4.0530 - val_acc: 0.7659\n",
      "Epoch 29/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.1662 - acc: 0.3810 - val_loss: 4.0016 - val_acc: 0.7950\n",
      "Epoch 30/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0544 - acc: 0.5397 - val_loss: 3.9476 - val_acc: 0.8148\n",
      "Epoch 31/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 4.0532 - acc: 0.4921 - val_loss: 3.8951 - val_acc: 0.8333\n",
      "Epoch 32/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9214 - acc: 0.4444 - val_loss: 3.8383 - val_acc: 0.8426\n",
      "Epoch 33/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9715 - acc: 0.4603 - val_loss: 3.7836 - val_acc: 0.8664\n",
      "Epoch 34/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.9551 - acc: 0.4286 - val_loss: 3.7326 - val_acc: 0.8849\n",
      "Epoch 35/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8336 - acc: 0.5238 - val_loss: 3.6825 - val_acc: 0.9074\n",
      "Epoch 36/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.8084 - acc: 0.5397 - val_loss: 3.6302 - val_acc: 0.9524\n",
      "Epoch 37/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.7605 - acc: 0.6349 - val_loss: 3.5778 - val_acc: 0.9735\n",
      "Epoch 38/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.6763 - acc: 0.5714 - val_loss: 3.5225 - val_acc: 0.9828\n",
      "Epoch 39/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.6274 - acc: 0.5873 - val_loss: 3.4663 - val_acc: 0.9921\n",
      "Epoch 40/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5697 - acc: 0.6190 - val_loss: 3.4118 - val_acc: 0.9987\n",
      "Epoch 41/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.6397 - acc: 0.6349 - val_loss: 3.3613 - val_acc: 1.0000\n",
      "Epoch 42/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5016 - acc: 0.6349 - val_loss: 3.3116 - val_acc: 1.0000\n",
      "Epoch 43/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.4967 - acc: 0.6190 - val_loss: 3.2621 - val_acc: 1.0000\n",
      "Epoch 44/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3777 - acc: 0.6667 - val_loss: 3.2124 - val_acc: 1.0000\n",
      "Epoch 45/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5010 - acc: 0.5873 - val_loss: 3.1681 - val_acc: 1.0000\n",
      "Epoch 46/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3825 - acc: 0.6984 - val_loss: 3.1200 - val_acc: 1.0000\n",
      "Epoch 47/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.4203 - acc: 0.5873 - val_loss: 3.0744 - val_acc: 1.0000\n",
      "Epoch 48/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.3136 - acc: 0.5873 - val_loss: 3.0304 - val_acc: 1.0000\n",
      "Epoch 49/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2979 - acc: 0.6667 - val_loss: 2.9862 - val_acc: 1.0000\n",
      "Epoch 50/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1493 - acc: 0.7143 - val_loss: 2.9408 - val_acc: 1.0000\n",
      "Epoch 51/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1852 - acc: 0.6825 - val_loss: 2.8957 - val_acc: 1.0000\n",
      "Epoch 52/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.2309 - acc: 0.6825 - val_loss: 2.8519 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.1184 - acc: 0.7460 - val_loss: 2.8135 - val_acc: 1.0000\n",
      "Epoch 54/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 3.0925 - acc: 0.7460 - val_loss: 2.7737 - val_acc: 1.0000\n",
      "Epoch 55/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9835 - acc: 0.7619 - val_loss: 2.7321 - val_acc: 1.0000\n",
      "Epoch 56/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9371 - acc: 0.7778 - val_loss: 2.6913 - val_acc: 1.0000\n",
      "Epoch 57/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9697 - acc: 0.7619 - val_loss: 2.6533 - val_acc: 1.0000\n",
      "Epoch 58/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.9131 - acc: 0.7778 - val_loss: 2.6162 - val_acc: 1.0000\n",
      "Epoch 59/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8940 - acc: 0.7778 - val_loss: 2.5781 - val_acc: 1.0000\n",
      "Epoch 60/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8764 - acc: 0.7619 - val_loss: 2.5420 - val_acc: 1.0000\n",
      "Epoch 61/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8543 - acc: 0.7937 - val_loss: 2.5086 - val_acc: 1.0000\n",
      "Epoch 62/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.8030 - acc: 0.7778 - val_loss: 2.4743 - val_acc: 1.0000\n",
      "Epoch 63/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6621 - acc: 0.8889 - val_loss: 2.4386 - val_acc: 1.0000\n",
      "Epoch 64/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7798 - acc: 0.6984 - val_loss: 2.4038 - val_acc: 1.0000\n",
      "Epoch 65/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.7465 - acc: 0.8095 - val_loss: 2.3736 - val_acc: 1.0000\n",
      "Epoch 66/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6270 - acc: 0.7778 - val_loss: 2.3430 - val_acc: 1.0000\n",
      "Epoch 67/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5506 - acc: 0.8889 - val_loss: 2.3105 - val_acc: 1.0000\n",
      "Epoch 68/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.6106 - acc: 0.8730 - val_loss: 2.2803 - val_acc: 1.0000\n",
      "Epoch 69/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5852 - acc: 0.8730 - val_loss: 2.2510 - val_acc: 1.0000\n",
      "Epoch 70/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5728 - acc: 0.8095 - val_loss: 2.2227 - val_acc: 1.0000\n",
      "Epoch 71/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5411 - acc: 0.8095 - val_loss: 2.1965 - val_acc: 1.0000\n",
      "Epoch 72/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5084 - acc: 0.7619 - val_loss: 2.1717 - val_acc: 1.0000\n",
      "Epoch 73/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3660 - acc: 0.8413 - val_loss: 2.1479 - val_acc: 1.0000\n",
      "Epoch 74/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4845 - acc: 0.8254 - val_loss: 2.1254 - val_acc: 1.0000\n",
      "Epoch 75/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4593 - acc: 0.7937 - val_loss: 2.1051 - val_acc: 1.0000\n",
      "Epoch 76/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3792 - acc: 0.8571 - val_loss: 2.0823 - val_acc: 1.0000\n",
      "Epoch 77/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.5611 - acc: 0.7619 - val_loss: 2.0619 - val_acc: 1.0000\n",
      "Epoch 78/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4819 - acc: 0.7778 - val_loss: 2.0441 - val_acc: 1.0000\n",
      "Epoch 79/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4741 - acc: 0.7460 - val_loss: 2.0254 - val_acc: 1.0000\n",
      "Epoch 80/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3194 - acc: 0.8730 - val_loss: 2.0042 - val_acc: 1.0000\n",
      "Epoch 81/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.4235 - acc: 0.8571 - val_loss: 1.9822 - val_acc: 1.0000\n",
      "Epoch 82/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3294 - acc: 0.8730 - val_loss: 1.9632 - val_acc: 1.0000\n",
      "Epoch 83/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3422 - acc: 0.8889 - val_loss: 1.9430 - val_acc: 1.0000\n",
      "Epoch 84/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.3058 - acc: 0.7937 - val_loss: 1.9244 - val_acc: 1.0000\n",
      "Epoch 85/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2867 - acc: 0.9048 - val_loss: 1.9060 - val_acc: 1.0000\n",
      "Epoch 86/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1932 - acc: 0.8254 - val_loss: 1.8854 - val_acc: 1.0000\n",
      "Epoch 87/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1731 - acc: 0.9048 - val_loss: 1.8685 - val_acc: 1.0000\n",
      "Epoch 88/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2155 - acc: 0.8571 - val_loss: 1.8521 - val_acc: 1.0000\n",
      "Epoch 89/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2679 - acc: 0.8095 - val_loss: 1.8378 - val_acc: 1.0000\n",
      "Epoch 90/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2232 - acc: 0.8254 - val_loss: 1.8229 - val_acc: 1.0000\n",
      "Epoch 91/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1547 - acc: 0.9206 - val_loss: 1.8079 - val_acc: 1.0000\n",
      "Epoch 92/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1364 - acc: 0.8571 - val_loss: 1.7921 - val_acc: 1.0000\n",
      "Epoch 93/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2618 - acc: 0.8413 - val_loss: 1.7804 - val_acc: 1.0000\n",
      "Epoch 94/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2163 - acc: 0.8571 - val_loss: 1.7685 - val_acc: 1.0000\n",
      "Epoch 95/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0643 - acc: 0.9524 - val_loss: 1.7539 - val_acc: 1.0000\n",
      "Epoch 96/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2097 - acc: 0.8889 - val_loss: 1.7381 - val_acc: 1.0000\n",
      "Epoch 97/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0919 - acc: 0.8730 - val_loss: 1.7238 - val_acc: 1.0000\n",
      "Epoch 98/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2049 - acc: 0.8571 - val_loss: 1.7120 - val_acc: 1.0000\n",
      "Epoch 99/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9356 - acc: 0.9365 - val_loss: 1.6995 - val_acc: 1.0000\n",
      "Epoch 100/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9842 - acc: 0.9365 - val_loss: 1.6854 - val_acc: 1.0000\n",
      "Epoch 101/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0454 - acc: 0.8571 - val_loss: 1.6726 - val_acc: 1.0000\n",
      "Epoch 102/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.1715 - acc: 0.8571 - val_loss: 1.6613 - val_acc: 1.0000\n",
      "Epoch 103/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.0239 - acc: 0.8730 - val_loss: 1.6534 - val_acc: 1.0000\n",
      "Epoch 104/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9823 - acc: 0.8730 - val_loss: 1.6436 - val_acc: 1.0000\n",
      "Epoch 105/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8948 - acc: 0.9048 - val_loss: 1.6309 - val_acc: 1.0000\n",
      "Epoch 106/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9891 - acc: 0.9206 - val_loss: 1.6186 - val_acc: 1.0000\n",
      "Epoch 107/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9639 - acc: 0.8730 - val_loss: 1.6093 - val_acc: 1.0000\n",
      "Epoch 108/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9566 - acc: 0.9048 - val_loss: 1.6026 - val_acc: 1.0000\n",
      "Epoch 109/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9524 - acc: 0.8730 - val_loss: 1.5930 - val_acc: 1.0000\n",
      "Epoch 110/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8847 - acc: 0.8889 - val_loss: 1.5842 - val_acc: 1.0000\n",
      "Epoch 111/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8413 - acc: 0.9365 - val_loss: 1.5737 - val_acc: 1.0000\n",
      "Epoch 112/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9282 - acc: 0.9206 - val_loss: 1.5636 - val_acc: 1.0000\n",
      "Epoch 113/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9149 - acc: 0.9206 - val_loss: 1.5543 - val_acc: 1.0000\n",
      "Epoch 114/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8378 - acc: 0.8571 - val_loss: 1.5484 - val_acc: 1.0000\n",
      "Epoch 115/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8363 - acc: 0.9365 - val_loss: 1.5400 - val_acc: 1.0000\n",
      "Epoch 116/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8129 - acc: 0.9524 - val_loss: 1.5314 - val_acc: 1.0000\n",
      "Epoch 117/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8292 - acc: 0.8889 - val_loss: 1.5242 - val_acc: 1.0000\n",
      "Epoch 118/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9064 - acc: 0.8889 - val_loss: 1.5162 - val_acc: 1.0000\n",
      "Epoch 119/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.9420 - acc: 0.8254 - val_loss: 1.5091 - val_acc: 1.0000\n",
      "Epoch 120/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7785 - acc: 0.9683 - val_loss: 1.5028 - val_acc: 1.0000\n",
      "Epoch 121/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8339 - acc: 0.8889 - val_loss: 1.4983 - val_acc: 1.0000\n",
      "Epoch 122/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8750 - acc: 0.8730 - val_loss: 1.4918 - val_acc: 1.0000\n",
      "Epoch 123/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7513 - acc: 0.9206 - val_loss: 1.4835 - val_acc: 1.0000\n",
      "Epoch 124/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8824 - acc: 0.9206 - val_loss: 1.4775 - val_acc: 1.0000\n",
      "Epoch 125/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7900 - acc: 0.9206 - val_loss: 1.4701 - val_acc: 1.0000\n",
      "Epoch 126/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7489 - acc: 0.9048 - val_loss: 1.4626 - val_acc: 1.0000\n",
      "Epoch 127/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8512 - acc: 0.9206 - val_loss: 1.4563 - val_acc: 1.0000\n",
      "Epoch 128/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8079 - acc: 0.9524 - val_loss: 1.4538 - val_acc: 1.0000\n",
      "Epoch 129/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6882 - acc: 0.9841 - val_loss: 1.4471 - val_acc: 1.0000\n",
      "Epoch 130/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7820 - acc: 0.8889 - val_loss: 1.4385 - val_acc: 1.0000\n",
      "Epoch 131/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8016 - acc: 0.9206 - val_loss: 1.4337 - val_acc: 1.0000\n",
      "Epoch 132/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8812 - acc: 0.9206 - val_loss: 1.4325 - val_acc: 1.0000\n",
      "Epoch 133/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7576 - acc: 0.9206 - val_loss: 1.4270 - val_acc: 1.0000\n",
      "Epoch 134/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7546 - acc: 0.9206 - val_loss: 1.4204 - val_acc: 1.0000\n",
      "Epoch 135/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6705 - acc: 0.9365 - val_loss: 1.4122 - val_acc: 1.0000\n",
      "Epoch 136/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7954 - acc: 0.8889 - val_loss: 1.4075 - val_acc: 1.0000\n",
      "Epoch 137/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7302 - acc: 0.9048 - val_loss: 1.4021 - val_acc: 1.0000\n",
      "Epoch 138/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7493 - acc: 0.9524 - val_loss: 1.3986 - val_acc: 1.0000\n",
      "Epoch 139/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7978 - acc: 0.8889 - val_loss: 1.3979 - val_acc: 1.0000\n",
      "Epoch 140/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5782 - acc: 1.0000 - val_loss: 1.3916 - val_acc: 1.0000\n",
      "Epoch 141/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7209 - acc: 0.9524 - val_loss: 1.3838 - val_acc: 1.0000\n",
      "Epoch 142/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7415 - acc: 0.8889 - val_loss: 1.3798 - val_acc: 1.0000\n",
      "Epoch 143/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7665 - acc: 0.8889 - val_loss: 1.3784 - val_acc: 1.0000\n",
      "Epoch 144/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7561 - acc: 0.9048 - val_loss: 1.3749 - val_acc: 1.0000\n",
      "Epoch 145/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.8186 - acc: 0.8730 - val_loss: 1.3735 - val_acc: 1.0000\n",
      "Epoch 146/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6407 - acc: 0.9206 - val_loss: 1.3711 - val_acc: 1.0000\n",
      "Epoch 147/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7030 - acc: 0.8889 - val_loss: 1.3664 - val_acc: 1.0000\n",
      "Epoch 148/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6846 - acc: 0.9524 - val_loss: 1.3623 - val_acc: 1.0000\n",
      "Epoch 149/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6398 - acc: 0.9365 - val_loss: 1.3580 - val_acc: 1.0000\n",
      "Epoch 150/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5462 - acc: 0.9841 - val_loss: 1.3508 - val_acc: 1.0000\n",
      "Epoch 151/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6707 - acc: 0.9524 - val_loss: 1.3427 - val_acc: 1.0000\n",
      "Epoch 152/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6368 - acc: 0.9365 - val_loss: 1.3395 - val_acc: 1.0000\n",
      "Epoch 153/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5797 - acc: 0.9683 - val_loss: 1.3334 - val_acc: 1.0000\n",
      "Epoch 154/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6293 - acc: 0.9365 - val_loss: 1.3291 - val_acc: 1.0000\n",
      "Epoch 155/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5366 - acc: 0.9206 - val_loss: 1.3258 - val_acc: 1.0000\n",
      "Epoch 156/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6941 - acc: 0.8889 - val_loss: 1.3221 - val_acc: 1.0000\n",
      "Epoch 157/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5059 - acc: 0.9524 - val_loss: 1.3188 - val_acc: 1.0000\n",
      "Epoch 158/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5678 - acc: 0.9206 - val_loss: 1.3107 - val_acc: 1.0000\n",
      "Epoch 159/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6370 - acc: 0.9365 - val_loss: 1.3086 - val_acc: 1.0000\n",
      "Epoch 160/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5658 - acc: 0.9524 - val_loss: 1.3042 - val_acc: 1.0000\n",
      "Epoch 161/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5522 - acc: 0.9841 - val_loss: 1.2985 - val_acc: 1.0000\n",
      "Epoch 162/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5679 - acc: 0.9365 - val_loss: 1.2949 - val_acc: 1.0000\n",
      "Epoch 163/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5135 - acc: 0.9841 - val_loss: 1.2917 - val_acc: 1.0000\n",
      "Epoch 164/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5482 - acc: 0.9365 - val_loss: 1.2884 - val_acc: 1.0000\n",
      "Epoch 165/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5321 - acc: 0.9365 - val_loss: 1.2848 - val_acc: 1.0000\n",
      "Epoch 166/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4851 - acc: 0.9524 - val_loss: 1.2817 - val_acc: 1.0000\n",
      "Epoch 167/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5629 - acc: 0.9524 - val_loss: 1.2778 - val_acc: 1.0000\n",
      "Epoch 168/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5677 - acc: 0.9841 - val_loss: 1.2764 - val_acc: 1.0000\n",
      "Epoch 169/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5950 - acc: 0.9524 - val_loss: 1.2737 - val_acc: 1.0000\n",
      "Epoch 170/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6353 - acc: 0.8889 - val_loss: 1.2707 - val_acc: 1.0000\n",
      "Epoch 171/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4467 - acc: 0.9841 - val_loss: 1.2654 - val_acc: 1.0000\n",
      "Epoch 172/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5563 - acc: 0.9365 - val_loss: 1.2623 - val_acc: 1.0000\n",
      "Epoch 173/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4975 - acc: 0.9524 - val_loss: 1.2588 - val_acc: 1.0000\n",
      "Epoch 174/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5548 - acc: 0.9365 - val_loss: 1.2558 - val_acc: 1.0000\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5460 - acc: 0.9524 - val_loss: 1.2551 - val_acc: 1.0000\n",
      "Epoch 176/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4340 - acc: 1.0000 - val_loss: 1.2507 - val_acc: 1.0000\n",
      "Epoch 177/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4282 - acc: 0.9524 - val_loss: 1.2456 - val_acc: 1.0000\n",
      "Epoch 178/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5808 - acc: 0.9365 - val_loss: 1.2421 - val_acc: 1.0000\n",
      "Epoch 179/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4811 - acc: 0.9524 - val_loss: 1.2405 - val_acc: 1.0000\n",
      "Epoch 180/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6595 - acc: 0.8413 - val_loss: 1.2418 - val_acc: 1.0000\n",
      "Epoch 181/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5225 - acc: 0.9524 - val_loss: 1.2437 - val_acc: 1.0000\n",
      "Epoch 182/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5843 - acc: 0.9048 - val_loss: 1.2447 - val_acc: 1.0000\n",
      "Epoch 183/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4704 - acc: 0.9365 - val_loss: 1.2426 - val_acc: 1.0000\n",
      "Epoch 184/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5235 - acc: 0.9206 - val_loss: 1.2380 - val_acc: 1.0000\n",
      "Epoch 185/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4126 - acc: 1.0000 - val_loss: 1.2338 - val_acc: 1.0000\n",
      "Epoch 186/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4755 - acc: 0.9524 - val_loss: 1.2272 - val_acc: 1.0000\n",
      "Epoch 187/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4630 - acc: 0.9524 - val_loss: 1.2243 - val_acc: 1.0000\n",
      "Epoch 188/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4748 - acc: 0.9524 - val_loss: 1.2204 - val_acc: 1.0000\n",
      "Epoch 189/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4738 - acc: 0.9683 - val_loss: 1.2197 - val_acc: 1.0000\n",
      "Epoch 190/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4986 - acc: 0.9365 - val_loss: 1.2182 - val_acc: 1.0000\n",
      "Epoch 191/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5031 - acc: 0.9524 - val_loss: 1.2190 - val_acc: 1.0000\n",
      "Epoch 192/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4682 - acc: 0.9524 - val_loss: 1.2164 - val_acc: 1.0000\n",
      "Epoch 193/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4734 - acc: 0.9365 - val_loss: 1.2105 - val_acc: 1.0000\n",
      "Epoch 194/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4713 - acc: 0.9365 - val_loss: 1.2039 - val_acc: 1.0000\n",
      "Epoch 195/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4523 - acc: 0.9841 - val_loss: 1.1995 - val_acc: 1.0000\n",
      "Epoch 196/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4469 - acc: 0.9365 - val_loss: 1.1961 - val_acc: 1.0000\n",
      "Epoch 197/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4709 - acc: 0.9048 - val_loss: 1.1941 - val_acc: 1.0000\n",
      "Epoch 198/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3683 - acc: 0.9841 - val_loss: 1.1909 - val_acc: 1.0000\n",
      "Epoch 199/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3890 - acc: 0.9524 - val_loss: 1.1875 - val_acc: 1.0000\n",
      "Epoch 200/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4838 - acc: 0.9206 - val_loss: 1.1883 - val_acc: 1.0000\n",
      "Epoch 201/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4450 - acc: 0.9524 - val_loss: 1.1883 - val_acc: 1.0000\n",
      "Epoch 202/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4420 - acc: 0.9524 - val_loss: 1.1849 - val_acc: 1.0000\n",
      "Epoch 203/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4572 - acc: 0.9365 - val_loss: 1.1865 - val_acc: 1.0000\n",
      "Epoch 204/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4095 - acc: 0.9683 - val_loss: 1.1848 - val_acc: 1.0000\n",
      "Epoch 205/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4141 - acc: 0.9365 - val_loss: 1.1801 - val_acc: 1.0000\n",
      "Epoch 206/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4086 - acc: 0.9683 - val_loss: 1.1762 - val_acc: 1.0000\n",
      "Epoch 207/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4115 - acc: 0.9524 - val_loss: 1.1725 - val_acc: 1.0000\n",
      "Epoch 208/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2995 - acc: 1.0000 - val_loss: 1.1675 - val_acc: 1.0000\n",
      "Epoch 209/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3422 - acc: 0.9524 - val_loss: 1.1639 - val_acc: 1.0000\n",
      "Epoch 210/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4541 - acc: 0.9683 - val_loss: 1.1625 - val_acc: 1.0000\n",
      "Epoch 211/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4064 - acc: 0.9841 - val_loss: 1.1642 - val_acc: 1.0000\n",
      "Epoch 212/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3901 - acc: 0.9683 - val_loss: 1.1608 - val_acc: 1.0000\n",
      "Epoch 213/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3176 - acc: 1.0000 - val_loss: 1.1566 - val_acc: 1.0000\n",
      "Epoch 214/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3244 - acc: 0.9841 - val_loss: 1.1523 - val_acc: 1.0000\n",
      "Epoch 215/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4125 - acc: 0.9365 - val_loss: 1.1493 - val_acc: 1.0000\n",
      "Epoch 216/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3400 - acc: 0.9524 - val_loss: 1.1465 - val_acc: 1.0000\n",
      "Epoch 217/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4295 - acc: 0.9206 - val_loss: 1.1451 - val_acc: 1.0000\n",
      "Epoch 218/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4595 - acc: 0.8889 - val_loss: 1.1471 - val_acc: 1.0000\n",
      "Epoch 219/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3517 - acc: 0.9683 - val_loss: 1.1477 - val_acc: 1.0000\n",
      "Epoch 220/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3909 - acc: 0.9206 - val_loss: 1.1463 - val_acc: 1.0000\n",
      "Epoch 221/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3746 - acc: 0.9683 - val_loss: 1.1453 - val_acc: 1.0000\n",
      "Epoch 222/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3477 - acc: 0.9365 - val_loss: 1.1439 - val_acc: 1.0000\n",
      "Epoch 223/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4009 - acc: 0.9365 - val_loss: 1.1405 - val_acc: 1.0000\n",
      "Epoch 224/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4209 - acc: 0.9206 - val_loss: 1.1417 - val_acc: 1.0000\n",
      "Epoch 225/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3682 - acc: 0.9683 - val_loss: 1.1414 - val_acc: 1.0000\n",
      "Epoch 226/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3873 - acc: 0.9206 - val_loss: 1.1389 - val_acc: 1.0000\n",
      "Epoch 227/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4397 - acc: 0.8889 - val_loss: 1.1367 - val_acc: 1.0000\n",
      "Epoch 228/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3506 - acc: 0.9683 - val_loss: 1.1366 - val_acc: 1.0000\n",
      "Epoch 229/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3776 - acc: 0.9683 - val_loss: 1.1347 - val_acc: 1.0000\n",
      "Epoch 230/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4204 - acc: 0.9683 - val_loss: 1.1353 - val_acc: 1.0000\n",
      "Epoch 231/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3624 - acc: 0.9524 - val_loss: 1.1342 - val_acc: 1.0000\n",
      "Epoch 232/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3043 - acc: 0.9683 - val_loss: 1.1290 - val_acc: 1.0000\n",
      "Epoch 233/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3443 - acc: 0.9206 - val_loss: 1.1258 - val_acc: 1.0000\n",
      "Epoch 234/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3086 - acc: 0.9524 - val_loss: 1.1222 - val_acc: 1.0000\n",
      "Epoch 235/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3699 - acc: 0.9524 - val_loss: 1.1239 - val_acc: 1.0000\n",
      "Epoch 236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3871 - acc: 1.0000 - val_loss: 1.1262 - val_acc: 1.0000\n",
      "Epoch 237/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3143 - acc: 0.9683 - val_loss: 1.1235 - val_acc: 1.0000\n",
      "Epoch 238/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3324 - acc: 0.9841 - val_loss: 1.1197 - val_acc: 1.0000\n",
      "Epoch 239/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3643 - acc: 0.9524 - val_loss: 1.1163 - val_acc: 1.0000\n",
      "Epoch 240/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3044 - acc: 0.9683 - val_loss: 1.1147 - val_acc: 1.0000\n",
      "Epoch 241/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3819 - acc: 0.9683 - val_loss: 1.1137 - val_acc: 1.0000\n",
      "Epoch 242/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3926 - acc: 0.9524 - val_loss: 1.1149 - val_acc: 1.0000\n",
      "Epoch 243/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3686 - acc: 0.9365 - val_loss: 1.1149 - val_acc: 1.0000\n",
      "Epoch 244/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3763 - acc: 0.9683 - val_loss: 1.1139 - val_acc: 1.0000\n",
      "Epoch 245/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4213 - acc: 0.9524 - val_loss: 1.1132 - val_acc: 1.0000\n",
      "Epoch 246/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3071 - acc: 0.9365 - val_loss: 1.1132 - val_acc: 1.0000\n",
      "Epoch 247/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3245 - acc: 0.9524 - val_loss: 1.1085 - val_acc: 1.0000\n",
      "Epoch 248/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3405 - acc: 0.9365 - val_loss: 1.1053 - val_acc: 1.0000\n",
      "Epoch 249/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2880 - acc: 1.0000 - val_loss: 1.1037 - val_acc: 1.0000\n",
      "Epoch 250/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2435 - acc: 1.0000 - val_loss: 1.0998 - val_acc: 1.0000\n",
      "Epoch 251/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3284 - acc: 0.9206 - val_loss: 1.0982 - val_acc: 1.0000\n",
      "Epoch 252/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3620 - acc: 0.9683 - val_loss: 1.0975 - val_acc: 1.0000\n",
      "Epoch 253/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2511 - acc: 0.9841 - val_loss: 1.0950 - val_acc: 1.0000\n",
      "Epoch 254/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2752 - acc: 1.0000 - val_loss: 1.0917 - val_acc: 1.0000\n",
      "Epoch 255/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3170 - acc: 0.9524 - val_loss: 1.0900 - val_acc: 1.0000\n",
      "Epoch 256/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.4022 - acc: 0.9048 - val_loss: 1.0910 - val_acc: 1.0000\n",
      "Epoch 257/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3362 - acc: 0.9683 - val_loss: 1.0939 - val_acc: 1.0000\n",
      "Epoch 258/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2487 - acc: 0.9524 - val_loss: 1.0916 - val_acc: 1.0000\n",
      "Epoch 259/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3210 - acc: 0.9683 - val_loss: 1.0876 - val_acc: 1.0000\n",
      "Epoch 260/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3579 - acc: 0.9365 - val_loss: 1.0856 - val_acc: 1.0000\n",
      "Epoch 261/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2926 - acc: 0.9683 - val_loss: 1.0828 - val_acc: 1.0000\n",
      "Epoch 262/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2536 - acc: 0.9841 - val_loss: 1.0807 - val_acc: 1.0000\n",
      "Epoch 263/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3269 - acc: 0.9683 - val_loss: 1.0811 - val_acc: 1.0000\n",
      "Epoch 264/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3458 - acc: 0.9048 - val_loss: 1.0818 - val_acc: 1.0000\n",
      "Epoch 265/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2741 - acc: 0.9524 - val_loss: 1.0796 - val_acc: 1.0000\n",
      "Epoch 266/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2238 - acc: 0.9841 - val_loss: 1.0753 - val_acc: 1.0000\n",
      "Epoch 267/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2698 - acc: 0.9683 - val_loss: 1.0692 - val_acc: 1.0000\n",
      "Epoch 268/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2732 - acc: 0.9524 - val_loss: 1.0659 - val_acc: 1.0000\n",
      "Epoch 269/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2739 - acc: 1.0000 - val_loss: 1.0643 - val_acc: 1.0000\n",
      "Epoch 270/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2834 - acc: 0.9524 - val_loss: 1.0655 - val_acc: 1.0000\n",
      "Epoch 271/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2183 - acc: 0.9841 - val_loss: 1.0640 - val_acc: 1.0000\n",
      "Epoch 272/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2302 - acc: 0.9841 - val_loss: 1.0601 - val_acc: 1.0000\n",
      "Epoch 273/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2070 - acc: 0.9683 - val_loss: 1.0566 - val_acc: 1.0000\n",
      "Epoch 274/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1923 - acc: 1.0000 - val_loss: 1.0537 - val_acc: 1.0000\n",
      "Epoch 275/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2463 - acc: 0.9524 - val_loss: 1.0505 - val_acc: 1.0000\n",
      "Epoch 276/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1712 - acc: 0.9841 - val_loss: 1.0463 - val_acc: 1.0000\n",
      "Epoch 277/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2144 - acc: 0.9841 - val_loss: 1.0432 - val_acc: 1.0000\n",
      "Epoch 278/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1318 - acc: 0.9841 - val_loss: 1.0415 - val_acc: 1.0000\n",
      "Epoch 279/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3116 - acc: 0.9524 - val_loss: 1.0430 - val_acc: 1.0000\n",
      "Epoch 280/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2627 - acc: 0.9524 - val_loss: 1.0461 - val_acc: 1.0000\n",
      "Epoch 281/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2085 - acc: 0.9841 - val_loss: 1.0460 - val_acc: 1.0000\n",
      "Epoch 282/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2388 - acc: 0.9683 - val_loss: 1.0483 - val_acc: 1.0000\n",
      "Epoch 283/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2252 - acc: 0.9683 - val_loss: 1.0481 - val_acc: 1.0000\n",
      "Epoch 284/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1731 - acc: 0.9841 - val_loss: 1.0443 - val_acc: 1.0000\n",
      "Epoch 285/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2459 - acc: 0.9524 - val_loss: 1.0420 - val_acc: 1.0000\n",
      "Epoch 286/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1464 - acc: 0.9841 - val_loss: 1.0380 - val_acc: 1.0000\n",
      "Epoch 287/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3605 - acc: 0.9365 - val_loss: 1.0403 - val_acc: 1.0000\n",
      "Epoch 288/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1782 - acc: 0.9841 - val_loss: 1.0405 - val_acc: 1.0000\n",
      "Epoch 289/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1786 - acc: 0.9841 - val_loss: 1.0371 - val_acc: 1.0000\n",
      "Epoch 290/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2097 - acc: 0.9683 - val_loss: 1.0347 - val_acc: 1.0000\n",
      "Epoch 291/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2461 - acc: 0.9206 - val_loss: 1.0339 - val_acc: 1.0000\n",
      "Epoch 292/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2310 - acc: 0.9524 - val_loss: 1.0336 - val_acc: 1.0000\n",
      "Epoch 293/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3080 - acc: 0.9365 - val_loss: 1.0374 - val_acc: 1.0000\n",
      "Epoch 294/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3294 - acc: 0.9365 - val_loss: 1.0419 - val_acc: 1.0000\n",
      "Epoch 295/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1991 - acc: 0.9683 - val_loss: 1.0409 - val_acc: 1.0000\n",
      "Epoch 296/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2491 - acc: 0.9683 - val_loss: 1.0389 - val_acc: 1.0000\n",
      "Epoch 297/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3166 - acc: 0.9206 - val_loss: 1.0395 - val_acc: 1.0000\n",
      "Epoch 298/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2089 - acc: 0.9841 - val_loss: 1.0368 - val_acc: 1.0000\n",
      "Epoch 299/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1503 - acc: 1.0000 - val_loss: 1.0326 - val_acc: 1.0000\n",
      "Epoch 300/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2088 - acc: 0.9683 - val_loss: 1.0306 - val_acc: 1.0000\n",
      "Epoch 301/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2785 - acc: 0.9048 - val_loss: 1.0319 - val_acc: 1.0000\n",
      "Epoch 302/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2959 - acc: 0.9524 - val_loss: 1.0353 - val_acc: 1.0000\n",
      "Epoch 303/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1897 - acc: 1.0000 - val_loss: 1.0352 - val_acc: 1.0000\n",
      "Epoch 304/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1354 - acc: 1.0000 - val_loss: 1.0300 - val_acc: 1.0000\n",
      "Epoch 305/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1822 - acc: 1.0000 - val_loss: 1.0253 - val_acc: 1.0000\n",
      "Epoch 306/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1776 - acc: 0.9683 - val_loss: 1.0238 - val_acc: 1.0000\n",
      "Epoch 307/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2260 - acc: 0.9524 - val_loss: 1.0207 - val_acc: 1.0000\n",
      "Epoch 308/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2268 - acc: 0.9683 - val_loss: 1.0213 - val_acc: 1.0000\n",
      "Epoch 309/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1767 - acc: 0.9841 - val_loss: 1.0199 - val_acc: 1.0000\n",
      "Epoch 310/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1757 - acc: 0.9841 - val_loss: 1.0188 - val_acc: 1.0000\n",
      "Epoch 311/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1726 - acc: 0.9524 - val_loss: 1.0146 - val_acc: 1.0000\n",
      "Epoch 312/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1709 - acc: 0.9841 - val_loss: 1.0122 - val_acc: 1.0000\n",
      "Epoch 313/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1950 - acc: 0.9524 - val_loss: 1.0129 - val_acc: 1.0000\n",
      "Epoch 314/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3018 - acc: 0.9206 - val_loss: 1.0150 - val_acc: 1.0000\n",
      "Epoch 315/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1735 - acc: 0.9841 - val_loss: 1.0162 - val_acc: 1.0000\n",
      "Epoch 316/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2018 - acc: 0.9683 - val_loss: 1.0144 - val_acc: 1.0000\n",
      "Epoch 317/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1893 - acc: 0.9841 - val_loss: 1.0140 - val_acc: 1.0000\n",
      "Epoch 318/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2470 - acc: 0.9365 - val_loss: 1.0137 - val_acc: 1.0000\n",
      "Epoch 319/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1338 - acc: 1.0000 - val_loss: 1.0109 - val_acc: 1.0000\n",
      "Epoch 320/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1683 - acc: 0.9841 - val_loss: 1.0081 - val_acc: 1.0000\n",
      "Epoch 321/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1682 - acc: 0.9365 - val_loss: 1.0074 - val_acc: 1.0000\n",
      "Epoch 322/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2011 - acc: 0.9524 - val_loss: 1.0078 - val_acc: 1.0000\n",
      "Epoch 323/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1511 - acc: 1.0000 - val_loss: 1.0073 - val_acc: 1.0000\n",
      "Epoch 324/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1916 - acc: 1.0000 - val_loss: 1.0067 - val_acc: 1.0000\n",
      "Epoch 325/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2167 - acc: 0.9365 - val_loss: 1.0058 - val_acc: 1.0000\n",
      "Epoch 326/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1627 - acc: 1.0000 - val_loss: 1.0041 - val_acc: 1.0000\n",
      "Epoch 327/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1381 - acc: 0.9683 - val_loss: 1.0016 - val_acc: 1.0000\n",
      "Epoch 328/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1338 - acc: 1.0000 - val_loss: 1.0000 - val_acc: 1.0000\n",
      "Epoch 329/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1892 - acc: 0.9524 - val_loss: 0.9985 - val_acc: 1.0000\n",
      "Epoch 330/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1708 - acc: 0.9524 - val_loss: 1.0005 - val_acc: 1.0000\n",
      "Epoch 331/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1541 - acc: 1.0000 - val_loss: 1.0010 - val_acc: 1.0000\n",
      "Epoch 332/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1571 - acc: 0.9841 - val_loss: 0.9981 - val_acc: 1.0000\n",
      "Epoch 333/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1696 - acc: 0.9683 - val_loss: 0.9986 - val_acc: 1.0000\n",
      "Epoch 334/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1944 - acc: 0.9683 - val_loss: 0.9984 - val_acc: 1.0000\n",
      "Epoch 335/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1249 - acc: 0.9524 - val_loss: 0.9959 - val_acc: 1.0000\n",
      "Epoch 336/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2097 - acc: 0.9683 - val_loss: 0.9922 - val_acc: 1.0000\n",
      "Epoch 337/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1890 - acc: 0.9683 - val_loss: 0.9923 - val_acc: 1.0000\n",
      "Epoch 338/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1829 - acc: 0.9841 - val_loss: 0.9909 - val_acc: 1.0000\n",
      "Epoch 339/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2144 - acc: 0.9524 - val_loss: 0.9905 - val_acc: 1.0000\n",
      "Epoch 340/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1572 - acc: 0.9365 - val_loss: 0.9922 - val_acc: 1.0000\n",
      "Epoch 341/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1431 - acc: 0.9683 - val_loss: 0.9916 - val_acc: 1.0000\n",
      "Epoch 342/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1727 - acc: 0.9524 - val_loss: 0.9921 - val_acc: 1.0000\n",
      "Epoch 343/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1057 - acc: 1.0000 - val_loss: 0.9895 - val_acc: 1.0000\n",
      "Epoch 344/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0885 - acc: 1.0000 - val_loss: 0.9825 - val_acc: 1.0000\n",
      "Epoch 345/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1772 - acc: 0.9524 - val_loss: 0.9793 - val_acc: 1.0000\n",
      "Epoch 346/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1598 - acc: 0.9841 - val_loss: 0.9811 - val_acc: 1.0000\n",
      "Epoch 347/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1890 - acc: 0.9841 - val_loss: 0.9823 - val_acc: 1.0000\n",
      "Epoch 348/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2073 - acc: 0.9683 - val_loss: 0.9835 - val_acc: 1.0000\n",
      "Epoch 349/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1278 - acc: 0.9841 - val_loss: 0.9836 - val_acc: 1.0000\n",
      "Epoch 350/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1652 - acc: 0.9683 - val_loss: 0.9826 - val_acc: 1.0000\n",
      "Epoch 351/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1067 - acc: 0.9841 - val_loss: 0.9793 - val_acc: 1.0000\n",
      "Epoch 352/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1061 - acc: 0.9524 - val_loss: 0.9741 - val_acc: 1.0000\n",
      "Epoch 353/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1518 - acc: 0.9683 - val_loss: 0.9730 - val_acc: 1.0000\n",
      "Epoch 354/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1148 - acc: 0.9841 - val_loss: 0.9726 - val_acc: 1.0000\n",
      "Epoch 355/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1030 - acc: 0.9841 - val_loss: 0.9718 - val_acc: 1.0000\n",
      "Epoch 356/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1526 - acc: 1.0000 - val_loss: 0.9688 - val_acc: 1.0000\n",
      "Epoch 357/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1735 - acc: 0.9524 - val_loss: 0.9709 - val_acc: 1.0000\n",
      "Epoch 358/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0788 - acc: 0.9841 - val_loss: 0.9714 - val_acc: 1.0000\n",
      "Epoch 359/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1395 - acc: 0.9524 - val_loss: 0.9688 - val_acc: 1.0000\n",
      "Epoch 360/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0718 - acc: 1.0000 - val_loss: 0.9652 - val_acc: 1.0000\n",
      "Epoch 361/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2242 - acc: 0.9683 - val_loss: 0.9673 - val_acc: 1.0000\n",
      "Epoch 362/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1136 - acc: 1.0000 - val_loss: 0.9669 - val_acc: 1.0000\n",
      "Epoch 363/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1945 - acc: 0.9365 - val_loss: 0.9666 - val_acc: 1.0000\n",
      "Epoch 364/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1086 - acc: 0.9524 - val_loss: 0.9700 - val_acc: 1.0000\n",
      "Epoch 365/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1290 - acc: 1.0000 - val_loss: 0.9701 - val_acc: 1.0000\n",
      "Epoch 366/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1331 - acc: 0.9683 - val_loss: 0.9684 - val_acc: 1.0000\n",
      "Epoch 367/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1689 - acc: 0.9365 - val_loss: 0.9668 - val_acc: 1.0000\n",
      "Epoch 368/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0732 - acc: 0.9841 - val_loss: 0.9622 - val_acc: 1.0000\n",
      "Epoch 369/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0824 - acc: 1.0000 - val_loss: 0.9581 - val_acc: 1.0000\n",
      "Epoch 370/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1021 - acc: 1.0000 - val_loss: 0.9548 - val_acc: 1.0000\n",
      "Epoch 371/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1288 - acc: 0.9683 - val_loss: 0.9575 - val_acc: 1.0000\n",
      "Epoch 372/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1104 - acc: 0.9841 - val_loss: 0.9600 - val_acc: 1.0000\n",
      "Epoch 373/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1295 - acc: 0.9841 - val_loss: 0.9591 - val_acc: 1.0000\n",
      "Epoch 374/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1064 - acc: 0.9841 - val_loss: 0.9571 - val_acc: 1.0000\n",
      "Epoch 375/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1206 - acc: 0.9841 - val_loss: 0.9565 - val_acc: 1.0000\n",
      "Epoch 376/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0598 - acc: 0.9841 - val_loss: 0.9543 - val_acc: 1.0000\n",
      "Epoch 377/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2073 - acc: 0.9683 - val_loss: 0.9564 - val_acc: 1.0000\n",
      "Epoch 378/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0915 - acc: 1.0000 - val_loss: 0.9579 - val_acc: 1.0000\n",
      "Epoch 379/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0502 - acc: 1.0000 - val_loss: 0.9554 - val_acc: 1.0000\n",
      "Epoch 380/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1934 - acc: 0.9524 - val_loss: 0.9561 - val_acc: 1.0000\n",
      "Epoch 381/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2009 - acc: 0.9048 - val_loss: 0.9647 - val_acc: 1.0000\n",
      "Epoch 382/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1134 - acc: 0.9841 - val_loss: 0.9685 - val_acc: 1.0000\n",
      "Epoch 383/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1896 - acc: 0.9365 - val_loss: 0.9697 - val_acc: 1.0000\n",
      "Epoch 384/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0950 - acc: 0.9683 - val_loss: 0.9669 - val_acc: 1.0000\n",
      "Epoch 385/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0675 - acc: 0.9841 - val_loss: 0.9636 - val_acc: 1.0000\n",
      "Epoch 386/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1349 - acc: 0.9841 - val_loss: 0.9602 - val_acc: 1.0000\n",
      "Epoch 387/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1748 - acc: 0.9683 - val_loss: 0.9604 - val_acc: 1.0000\n",
      "Epoch 388/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1256 - acc: 0.9683 - val_loss: 0.9598 - val_acc: 1.0000\n",
      "Epoch 389/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0751 - acc: 1.0000 - val_loss: 0.9579 - val_acc: 1.0000\n",
      "Epoch 390/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0777 - acc: 0.9841 - val_loss: 0.9533 - val_acc: 1.0000\n",
      "Epoch 391/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0938 - acc: 0.9841 - val_loss: 0.9492 - val_acc: 1.0000\n",
      "Epoch 392/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0495 - acc: 1.0000 - val_loss: 0.9460 - val_acc: 1.0000\n",
      "Epoch 393/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1574 - acc: 0.9365 - val_loss: 0.9424 - val_acc: 1.0000\n",
      "Epoch 394/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0941 - acc: 0.9524 - val_loss: 0.9452 - val_acc: 1.0000\n",
      "Epoch 395/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1769 - acc: 0.9365 - val_loss: 0.9480 - val_acc: 1.0000\n",
      "Epoch 396/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1554 - acc: 0.9683 - val_loss: 0.9516 - val_acc: 1.0000\n",
      "Epoch 397/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1353 - acc: 0.9683 - val_loss: 0.9516 - val_acc: 1.0000\n",
      "Epoch 398/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0835 - acc: 0.9841 - val_loss: 0.9482 - val_acc: 1.0000\n",
      "Epoch 399/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1658 - acc: 0.9683 - val_loss: 0.9472 - val_acc: 1.0000\n",
      "Epoch 400/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0976 - acc: 0.9683 - val_loss: 0.9459 - val_acc: 1.0000\n",
      "Epoch 401/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0717 - acc: 0.9841 - val_loss: 0.9407 - val_acc: 1.0000\n",
      "Epoch 402/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1021 - acc: 0.9841 - val_loss: 0.9395 - val_acc: 1.0000\n",
      "Epoch 403/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0995 - acc: 0.9841 - val_loss: 0.9389 - val_acc: 1.0000\n",
      "Epoch 404/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1850 - acc: 0.9524 - val_loss: 0.9396 - val_acc: 1.0000\n",
      "Epoch 405/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1104 - acc: 0.9841 - val_loss: 0.9409 - val_acc: 1.0000\n",
      "Epoch 406/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0741 - acc: 0.9683 - val_loss: 0.9380 - val_acc: 1.0000\n",
      "Epoch 407/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1065 - acc: 0.9524 - val_loss: 0.9367 - val_acc: 1.0000\n",
      "Epoch 408/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0737 - acc: 0.9841 - val_loss: 0.9360 - val_acc: 1.0000\n",
      "Epoch 409/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1073 - acc: 1.0000 - val_loss: 0.9353 - val_acc: 1.0000\n",
      "Epoch 410/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0714 - acc: 0.9841 - val_loss: 0.9344 - val_acc: 1.0000\n",
      "Epoch 411/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0432 - acc: 0.9683 - val_loss: 0.9311 - val_acc: 1.0000\n",
      "Epoch 412/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0976 - acc: 1.0000 - val_loss: 0.9285 - val_acc: 1.0000\n",
      "Epoch 413/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0457 - acc: 0.9841 - val_loss: 0.9274 - val_acc: 1.0000\n",
      "Epoch 414/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0725 - acc: 0.9683 - val_loss: 0.9278 - val_acc: 1.0000\n",
      "Epoch 415/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0904 - acc: 0.9841 - val_loss: 0.9285 - val_acc: 1.0000\n",
      "Epoch 416/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1142 - acc: 0.9683 - val_loss: 0.9276 - val_acc: 1.0000\n",
      "Epoch 417/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1107 - acc: 0.9524 - val_loss: 0.9271 - val_acc: 1.0000\n",
      "Epoch 418/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0208 - acc: 1.0000 - val_loss: 0.9260 - val_acc: 1.0000\n",
      "Epoch 419/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0405 - acc: 0.9841 - val_loss: 0.9217 - val_acc: 1.0000\n",
      "Epoch 420/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0862 - acc: 0.9683 - val_loss: 0.9240 - val_acc: 1.0000\n",
      "Epoch 421/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1975 - acc: 0.9048 - val_loss: 0.9308 - val_acc: 1.0000\n",
      "Epoch 422/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0448 - acc: 0.9683 - val_loss: 0.9302 - val_acc: 1.0000\n",
      "Epoch 423/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9948 - acc: 1.0000 - val_loss: 0.9261 - val_acc: 1.0000\n",
      "Epoch 424/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0720 - acc: 0.9841 - val_loss: 0.9201 - val_acc: 1.0000\n",
      "Epoch 425/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0255 - acc: 1.0000 - val_loss: 0.9166 - val_acc: 1.0000\n",
      "Epoch 426/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0568 - acc: 0.9524 - val_loss: 0.9148 - val_acc: 1.0000\n",
      "Epoch 427/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0149 - acc: 0.9841 - val_loss: 0.9130 - val_acc: 1.0000\n",
      "Epoch 428/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1480 - acc: 0.9365 - val_loss: 0.9167 - val_acc: 1.0000\n",
      "Epoch 429/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0412 - acc: 1.0000 - val_loss: 0.9177 - val_acc: 1.0000\n",
      "Epoch 430/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0560 - acc: 0.9683 - val_loss: 0.9167 - val_acc: 1.0000\n",
      "Epoch 431/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0599 - acc: 0.9524 - val_loss: 0.9150 - val_acc: 1.0000\n",
      "Epoch 432/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1016 - acc: 0.9524 - val_loss: 0.9167 - val_acc: 1.0000\n",
      "Epoch 433/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0348 - acc: 0.9841 - val_loss: 0.9138 - val_acc: 1.0000\n",
      "Epoch 434/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0304 - acc: 0.9841 - val_loss: 0.9100 - val_acc: 1.0000\n",
      "Epoch 435/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1121 - acc: 0.9365 - val_loss: 0.9088 - val_acc: 1.0000\n",
      "Epoch 436/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0282 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 1.0000\n",
      "Epoch 437/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1511 - acc: 0.9206 - val_loss: 0.9139 - val_acc: 1.0000\n",
      "Epoch 438/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9844 - acc: 1.0000 - val_loss: 0.9137 - val_acc: 1.0000\n",
      "Epoch 439/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0498 - acc: 0.9683 - val_loss: 0.9108 - val_acc: 1.0000\n",
      "Epoch 440/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0139 - acc: 1.0000 - val_loss: 0.9068 - val_acc: 1.0000\n",
      "Epoch 441/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0281 - acc: 1.0000 - val_loss: 0.9033 - val_acc: 1.0000\n",
      "Epoch 442/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9869 - acc: 1.0000 - val_loss: 0.8986 - val_acc: 1.0000\n",
      "Epoch 443/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0392 - acc: 0.9683 - val_loss: 0.8986 - val_acc: 1.0000\n",
      "Epoch 444/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1542 - acc: 0.9683 - val_loss: 0.9035 - val_acc: 1.0000\n",
      "Epoch 445/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0598 - acc: 0.9841 - val_loss: 0.9078 - val_acc: 1.0000\n",
      "Epoch 446/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0505 - acc: 0.9841 - val_loss: 0.9073 - val_acc: 1.0000\n",
      "Epoch 447/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9919 - acc: 1.0000 - val_loss: 0.9047 - val_acc: 1.0000\n",
      "Epoch 448/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0048 - acc: 1.0000 - val_loss: 0.9019 - val_acc: 1.0000\n",
      "Epoch 449/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0348 - acc: 0.9841 - val_loss: 0.9000 - val_acc: 1.0000\n",
      "Epoch 450/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0471 - acc: 0.9841 - val_loss: 0.9004 - val_acc: 1.0000\n",
      "Epoch 451/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0273 - acc: 0.9841 - val_loss: 0.9002 - val_acc: 1.0000\n",
      "Epoch 452/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0986 - acc: 0.9524 - val_loss: 0.9034 - val_acc: 1.0000\n",
      "Epoch 453/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0608 - acc: 0.9841 - val_loss: 0.9058 - val_acc: 1.0000\n",
      "Epoch 454/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0854 - acc: 0.9524 - val_loss: 0.9057 - val_acc: 1.0000\n",
      "Epoch 455/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0758 - acc: 0.9683 - val_loss: 0.9045 - val_acc: 1.0000\n",
      "Epoch 456/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1238 - acc: 0.9683 - val_loss: 0.9068 - val_acc: 1.0000\n",
      "Epoch 457/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0734 - acc: 0.9524 - val_loss: 0.9098 - val_acc: 1.0000\n",
      "Epoch 458/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0384 - acc: 0.9841 - val_loss: 0.9095 - val_acc: 1.0000\n",
      "Epoch 459/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0317 - acc: 1.0000 - val_loss: 0.9063 - val_acc: 1.0000\n",
      "Epoch 460/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1332 - acc: 0.9524 - val_loss: 0.9028 - val_acc: 1.0000\n",
      "Epoch 461/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0174 - acc: 1.0000 - val_loss: 0.9007 - val_acc: 1.0000\n",
      "Epoch 462/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0754 - acc: 0.9365 - val_loss: 0.8976 - val_acc: 1.0000\n",
      "Epoch 463/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0888 - acc: 0.9683 - val_loss: 0.8983 - val_acc: 1.0000\n",
      "Epoch 464/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0918 - acc: 0.9524 - val_loss: 0.9020 - val_acc: 1.0000\n",
      "Epoch 465/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9735 - acc: 1.0000 - val_loss: 0.8997 - val_acc: 1.0000\n",
      "Epoch 466/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1133 - acc: 0.9524 - val_loss: 0.8976 - val_acc: 1.0000\n",
      "Epoch 467/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0863 - acc: 0.9683 - val_loss: 0.8968 - val_acc: 1.0000\n",
      "Epoch 468/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0158 - acc: 0.9841 - val_loss: 0.8961 - val_acc: 1.0000\n",
      "Epoch 469/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0605 - acc: 0.9683 - val_loss: 0.8967 - val_acc: 1.0000\n",
      "Epoch 470/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0556 - acc: 0.9841 - val_loss: 0.8975 - val_acc: 1.0000\n",
      "Epoch 471/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0001 - acc: 0.9683 - val_loss: 0.8959 - val_acc: 1.0000\n",
      "Epoch 472/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9895 - acc: 0.9841 - val_loss: 0.8918 - val_acc: 1.0000\n",
      "Epoch 473/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9779 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 1.0000\n",
      "Epoch 474/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0300 - acc: 0.9841 - val_loss: 0.8845 - val_acc: 1.0000\n",
      "Epoch 475/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0317 - acc: 0.9841 - val_loss: 0.8859 - val_acc: 1.0000\n",
      "Epoch 476/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9859 - acc: 1.0000 - val_loss: 0.8858 - val_acc: 1.0000\n",
      "Epoch 477/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9802 - acc: 1.0000 - val_loss: 0.8817 - val_acc: 1.0000\n",
      "Epoch 478/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0011 - acc: 1.0000 - val_loss: 0.8769 - val_acc: 1.0000\n",
      "Epoch 479/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0472 - acc: 0.9841 - val_loss: 0.8762 - val_acc: 1.0000\n",
      "Epoch 480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0578 - acc: 0.9841 - val_loss: 0.8813 - val_acc: 1.0000\n",
      "Epoch 481/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0287 - acc: 0.9683 - val_loss: 0.8858 - val_acc: 1.0000\n",
      "Epoch 482/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9946 - acc: 0.9841 - val_loss: 0.8879 - val_acc: 1.0000\n",
      "Epoch 483/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0432 - acc: 0.9524 - val_loss: 0.8867 - val_acc: 1.0000\n",
      "Epoch 484/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0055 - acc: 0.9841 - val_loss: 0.8854 - val_acc: 1.0000\n",
      "Epoch 485/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9950 - acc: 0.9841 - val_loss: 0.8824 - val_acc: 1.0000\n",
      "Epoch 486/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9876 - acc: 1.0000 - val_loss: 0.8790 - val_acc: 1.0000\n",
      "Epoch 487/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0540 - acc: 0.9841 - val_loss: 0.8774 - val_acc: 1.0000\n",
      "Epoch 488/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0918 - acc: 0.9365 - val_loss: 0.8806 - val_acc: 1.0000\n",
      "Epoch 489/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9927 - acc: 1.0000 - val_loss: 0.8835 - val_acc: 1.0000\n",
      "Epoch 490/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0091 - acc: 0.9841 - val_loss: 0.8816 - val_acc: 1.0000\n",
      "Epoch 491/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9446 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 1.0000\n",
      "Epoch 492/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9438 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 1.0000\n",
      "Epoch 493/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9868 - acc: 1.0000 - val_loss: 0.8662 - val_acc: 1.0000\n",
      "Epoch 494/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9784 - acc: 0.9841 - val_loss: 0.8653 - val_acc: 1.0000\n",
      "Epoch 495/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0282 - acc: 0.9683 - val_loss: 0.8671 - val_acc: 1.0000\n",
      "Epoch 496/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9986 - acc: 0.9683 - val_loss: 0.8679 - val_acc: 1.0000\n",
      "Epoch 497/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0104 - acc: 0.9841 - val_loss: 0.8694 - val_acc: 1.0000\n",
      "Epoch 498/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0060 - acc: 0.9841 - val_loss: 0.8705 - val_acc: 1.0000\n",
      "Epoch 499/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0461 - acc: 0.9683 - val_loss: 0.8714 - val_acc: 1.0000\n",
      "Epoch 500/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9960 - acc: 0.9841 - val_loss: 0.8729 - val_acc: 1.0000\n",
      "Epoch 501/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0372 - acc: 0.9524 - val_loss: 0.8712 - val_acc: 1.0000\n",
      "Epoch 502/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0282 - acc: 0.9683 - val_loss: 0.8728 - val_acc: 1.0000\n",
      "Epoch 503/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9836 - acc: 1.0000 - val_loss: 0.8726 - val_acc: 1.0000\n",
      "Epoch 504/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0086 - acc: 0.9683 - val_loss: 0.8703 - val_acc: 1.0000\n",
      "Epoch 505/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9827 - acc: 0.9841 - val_loss: 0.8697 - val_acc: 1.0000\n",
      "Epoch 506/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0946 - acc: 0.9048 - val_loss: 0.8724 - val_acc: 1.0000\n",
      "Epoch 507/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0116 - acc: 0.9683 - val_loss: 0.8751 - val_acc: 1.0000\n",
      "Epoch 508/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0328 - acc: 0.9683 - val_loss: 0.8769 - val_acc: 1.0000\n",
      "Epoch 509/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9648 - acc: 0.9841 - val_loss: 0.8754 - val_acc: 1.0000\n",
      "Epoch 510/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9659 - acc: 0.9841 - val_loss: 0.8725 - val_acc: 1.0000\n",
      "Epoch 511/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9844 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 1.0000\n",
      "Epoch 512/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0054 - acc: 0.9683 - val_loss: 0.8689 - val_acc: 1.0000\n",
      "Epoch 513/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9860 - acc: 1.0000 - val_loss: 0.8685 - val_acc: 1.0000\n",
      "Epoch 514/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9565 - acc: 0.9841 - val_loss: 0.8679 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00514: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 515/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9786 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 1.0000\n",
      "Epoch 516/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0863 - acc: 0.9524 - val_loss: 0.8632 - val_acc: 1.0000\n",
      "Epoch 517/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0065 - acc: 0.9683 - val_loss: 0.8630 - val_acc: 1.0000\n",
      "Epoch 518/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0029 - acc: 0.9841 - val_loss: 0.8609 - val_acc: 1.0000\n",
      "Epoch 519/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9890 - acc: 0.9841 - val_loss: 0.8586 - val_acc: 1.0000\n",
      "Epoch 520/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0033 - acc: 0.9841 - val_loss: 0.8569 - val_acc: 1.0000\n",
      "Epoch 521/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0373 - acc: 0.9524 - val_loss: 0.8547 - val_acc: 1.0000\n",
      "Epoch 522/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9284 - acc: 1.0000 - val_loss: 0.8518 - val_acc: 1.0000\n",
      "Epoch 523/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0052 - acc: 0.9841 - val_loss: 0.8499 - val_acc: 1.0000\n",
      "Epoch 524/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9347 - acc: 0.9841 - val_loss: 0.8473 - val_acc: 1.0000\n",
      "Epoch 525/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9718 - acc: 0.9841 - val_loss: 0.8455 - val_acc: 1.0000\n",
      "Epoch 526/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9769 - acc: 0.9841 - val_loss: 0.8450 - val_acc: 1.0000\n",
      "Epoch 527/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0119 - acc: 0.9524 - val_loss: 0.8439 - val_acc: 1.0000\n",
      "Epoch 528/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0046 - acc: 0.9524 - val_loss: 0.8434 - val_acc: 1.0000\n",
      "Epoch 529/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9820 - acc: 0.9683 - val_loss: 0.8431 - val_acc: 1.0000\n",
      "Epoch 530/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9845 - acc: 0.9841 - val_loss: 0.8442 - val_acc: 1.0000\n",
      "Epoch 531/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0135 - acc: 0.9524 - val_loss: 0.8443 - val_acc: 1.0000\n",
      "Epoch 532/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9576 - acc: 0.9841 - val_loss: 0.8440 - val_acc: 1.0000\n",
      "Epoch 533/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9817 - acc: 0.9841 - val_loss: 0.8438 - val_acc: 1.0000\n",
      "Epoch 534/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0027 - acc: 0.9524 - val_loss: 0.8439 - val_acc: 1.0000\n",
      "Epoch 535/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9866 - acc: 0.9683 - val_loss: 0.8423 - val_acc: 1.0000\n",
      "Epoch 536/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9766 - acc: 0.9524 - val_loss: 0.8404 - val_acc: 1.0000\n",
      "Epoch 537/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9535 - acc: 0.9683 - val_loss: 0.8388 - val_acc: 1.0000\n",
      "Epoch 538/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9371 - acc: 1.0000 - val_loss: 0.8362 - val_acc: 1.0000\n",
      "Epoch 539/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0141 - acc: 0.9841 - val_loss: 0.8352 - val_acc: 1.0000\n",
      "Epoch 540/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0326 - acc: 0.9365 - val_loss: 0.8373 - val_acc: 1.0000\n",
      "Epoch 541/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9659 - acc: 0.9841 - val_loss: 0.8381 - val_acc: 1.0000\n",
      "Epoch 542/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9756 - acc: 1.0000 - val_loss: 0.8381 - val_acc: 1.0000\n",
      "Epoch 543/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0093 - acc: 0.9683 - val_loss: 0.8383 - val_acc: 1.0000\n",
      "Epoch 544/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9673 - acc: 0.9841 - val_loss: 0.8378 - val_acc: 1.0000\n",
      "Epoch 545/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9386 - acc: 0.9683 - val_loss: 0.8354 - val_acc: 1.0000\n",
      "Epoch 546/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0143 - acc: 0.9683 - val_loss: 0.8347 - val_acc: 1.0000\n",
      "Epoch 547/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9321 - acc: 0.9841 - val_loss: 0.8350 - val_acc: 1.0000\n",
      "Epoch 548/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0273 - acc: 0.9683 - val_loss: 0.8345 - val_acc: 1.0000\n",
      "Epoch 549/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9500 - acc: 1.0000 - val_loss: 0.8348 - val_acc: 1.0000\n",
      "Epoch 550/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9696 - acc: 0.9683 - val_loss: 0.8330 - val_acc: 1.0000\n",
      "Epoch 551/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9273 - acc: 1.0000 - val_loss: 0.8300 - val_acc: 1.0000\n",
      "Epoch 552/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9718 - acc: 0.9683 - val_loss: 0.8289 - val_acc: 1.0000\n",
      "Epoch 553/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8859 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 1.0000\n",
      "Epoch 554/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9930 - acc: 0.9524 - val_loss: 0.8266 - val_acc: 1.0000\n",
      "Epoch 555/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9878 - acc: 0.9841 - val_loss: 0.8275 - val_acc: 1.0000\n",
      "Epoch 556/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9081 - acc: 1.0000 - val_loss: 0.8276 - val_acc: 1.0000\n",
      "Epoch 557/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9492 - acc: 0.9841 - val_loss: 0.8264 - val_acc: 1.0000\n",
      "Epoch 558/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9507 - acc: 0.9841 - val_loss: 0.8256 - val_acc: 1.0000\n",
      "Epoch 559/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9177 - acc: 0.9841 - val_loss: 0.8244 - val_acc: 1.0000\n",
      "Epoch 560/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9708 - acc: 0.9524 - val_loss: 0.8240 - val_acc: 1.0000\n",
      "Epoch 561/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9212 - acc: 0.9841 - val_loss: 0.8227 - val_acc: 1.0000\n",
      "Epoch 562/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9503 - acc: 0.9683 - val_loss: 0.8217 - val_acc: 1.0000\n",
      "Epoch 563/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9490 - acc: 0.9683 - val_loss: 0.8229 - val_acc: 1.0000\n",
      "Epoch 564/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9686 - acc: 0.9683 - val_loss: 0.8236 - val_acc: 1.0000\n",
      "Epoch 565/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9507 - acc: 0.9683 - val_loss: 0.8242 - val_acc: 1.0000\n",
      "Epoch 566/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9789 - acc: 0.9683 - val_loss: 0.8248 - val_acc: 1.0000\n",
      "Epoch 567/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9195 - acc: 1.0000 - val_loss: 0.8257 - val_acc: 1.0000\n",
      "Epoch 568/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9641 - acc: 0.9683 - val_loss: 0.8244 - val_acc: 1.0000\n",
      "Epoch 569/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9593 - acc: 0.9841 - val_loss: 0.8241 - val_acc: 1.0000\n",
      "Epoch 570/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9512 - acc: 0.9841 - val_loss: 0.8226 - val_acc: 1.0000\n",
      "Epoch 571/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9807 - acc: 0.9841 - val_loss: 0.8213 - val_acc: 1.0000\n",
      "Epoch 572/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9691 - acc: 0.9683 - val_loss: 0.8222 - val_acc: 1.0000\n",
      "Epoch 573/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9847 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 1.0000\n",
      "Epoch 574/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0172 - acc: 0.9524 - val_loss: 0.8256 - val_acc: 1.0000\n",
      "Epoch 575/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9650 - acc: 0.9841 - val_loss: 0.8259 - val_acc: 1.0000\n",
      "Epoch 576/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9845 - acc: 0.9683 - val_loss: 0.8267 - val_acc: 1.0000\n",
      "Epoch 577/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9700 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 1.0000\n",
      "Epoch 578/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8859 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 1.0000\n",
      "Epoch 579/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0324 - acc: 0.9524 - val_loss: 0.8261 - val_acc: 1.0000\n",
      "Epoch 580/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9573 - acc: 0.9683 - val_loss: 0.8267 - val_acc: 1.0000\n",
      "Epoch 581/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9395 - acc: 1.0000 - val_loss: 0.8257 - val_acc: 1.0000\n",
      "Epoch 582/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8770 - acc: 1.0000 - val_loss: 0.8234 - val_acc: 1.0000\n",
      "Epoch 583/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9123 - acc: 0.9841 - val_loss: 0.8208 - val_acc: 1.0000\n",
      "Epoch 584/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9534 - acc: 0.9524 - val_loss: 0.8191 - val_acc: 1.0000\n",
      "Epoch 585/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9444 - acc: 0.9841 - val_loss: 0.8191 - val_acc: 1.0000\n",
      "Epoch 586/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9257 - acc: 1.0000 - val_loss: 0.8183 - val_acc: 1.0000\n",
      "Epoch 587/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9504 - acc: 0.9683 - val_loss: 0.8175 - val_acc: 1.0000\n",
      "Epoch 588/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9792 - acc: 0.9365 - val_loss: 0.8171 - val_acc: 1.0000\n",
      "Epoch 589/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9533 - acc: 0.9683 - val_loss: 0.8169 - val_acc: 1.0000\n",
      "Epoch 590/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9333 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 1.0000\n",
      "Epoch 591/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9685 - acc: 1.0000 - val_loss: 0.8175 - val_acc: 1.0000\n",
      "Epoch 592/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0004 - acc: 0.9524 - val_loss: 0.8194 - val_acc: 1.0000\n",
      "Epoch 593/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9022 - acc: 1.0000 - val_loss: 0.8184 - val_acc: 1.0000\n",
      "Epoch 594/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9031 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 1.0000\n",
      "Epoch 595/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9340 - acc: 1.0000 - val_loss: 0.8142 - val_acc: 1.0000\n",
      "Epoch 596/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9492 - acc: 0.9683 - val_loss: 0.8153 - val_acc: 1.0000\n",
      "Epoch 597/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9510 - acc: 0.9683 - val_loss: 0.8151 - val_acc: 1.0000\n",
      "Epoch 598/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9384 - acc: 0.9841 - val_loss: 0.8156 - val_acc: 1.0000\n",
      "Epoch 599/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0132 - acc: 0.9524 - val_loss: 0.8162 - val_acc: 1.0000\n",
      "Epoch 600/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9612 - acc: 0.9841 - val_loss: 0.8162 - val_acc: 1.0000\n",
      "Epoch 601/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9763 - acc: 0.9524 - val_loss: 0.8169 - val_acc: 1.0000\n",
      "Epoch 602/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9134 - acc: 1.0000 - val_loss: 0.8157 - val_acc: 1.0000\n",
      "Epoch 603/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9153 - acc: 1.0000 - val_loss: 0.8129 - val_acc: 1.0000\n",
      "Epoch 604/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8987 - acc: 1.0000 - val_loss: 0.8106 - val_acc: 1.0000\n",
      "Epoch 605/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9330 - acc: 1.0000 - val_loss: 0.8104 - val_acc: 1.0000\n",
      "Epoch 606/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9107 - acc: 0.9841 - val_loss: 0.8096 - val_acc: 1.0000\n",
      "Epoch 607/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9086 - acc: 1.0000 - val_loss: 0.8081 - val_acc: 1.0000\n",
      "Epoch 608/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9262 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 1.0000\n",
      "Epoch 609/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9090 - acc: 0.9841 - val_loss: 0.8064 - val_acc: 1.0000\n",
      "Epoch 610/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9016 - acc: 1.0000 - val_loss: 0.8061 - val_acc: 1.0000\n",
      "Epoch 611/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8816 - acc: 1.0000 - val_loss: 0.8048 - val_acc: 1.0000\n",
      "Epoch 612/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9673 - acc: 0.9841 - val_loss: 0.8050 - val_acc: 1.0000\n",
      "Epoch 613/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9038 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 1.0000\n",
      "Epoch 614/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9546 - acc: 0.9683 - val_loss: 0.8047 - val_acc: 1.0000\n",
      "Epoch 615/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9099 - acc: 1.0000 - val_loss: 0.8048 - val_acc: 1.0000\n",
      "Epoch 616/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9131 - acc: 0.9841 - val_loss: 0.8052 - val_acc: 1.0000\n",
      "Epoch 617/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9838 - acc: 0.9841 - val_loss: 0.8064 - val_acc: 1.0000\n",
      "Epoch 618/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9715 - acc: 0.9524 - val_loss: 0.8078 - val_acc: 1.0000\n",
      "Epoch 619/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9446 - acc: 0.9841 - val_loss: 0.8076 - val_acc: 1.0000\n",
      "Epoch 620/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8723 - acc: 1.0000 - val_loss: 0.8063 - val_acc: 1.0000\n",
      "Epoch 621/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8943 - acc: 1.0000 - val_loss: 0.8050 - val_acc: 1.0000\n",
      "Epoch 622/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9516 - acc: 0.9683 - val_loss: 0.8053 - val_acc: 1.0000\n",
      "Epoch 623/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9109 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 1.0000\n",
      "Epoch 624/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9427 - acc: 0.9683 - val_loss: 0.8051 - val_acc: 1.0000\n",
      "Epoch 625/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8981 - acc: 0.9841 - val_loss: 0.8039 - val_acc: 1.0000\n",
      "Epoch 626/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9016 - acc: 0.9841 - val_loss: 0.8037 - val_acc: 1.0000\n",
      "Epoch 627/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9299 - acc: 0.9841 - val_loss: 0.8026 - val_acc: 1.0000\n",
      "Epoch 628/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9189 - acc: 1.0000 - val_loss: 0.8017 - val_acc: 1.0000\n",
      "Epoch 629/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8889 - acc: 1.0000 - val_loss: 0.8006 - val_acc: 1.0000\n",
      "Epoch 630/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8986 - acc: 0.9841 - val_loss: 0.7989 - val_acc: 1.0000\n",
      "Epoch 631/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9462 - acc: 0.9683 - val_loss: 0.8002 - val_acc: 1.0000\n",
      "Epoch 632/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9468 - acc: 0.9683 - val_loss: 0.8021 - val_acc: 1.0000\n",
      "Epoch 633/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9334 - acc: 1.0000 - val_loss: 0.8032 - val_acc: 1.0000\n",
      "Epoch 634/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8792 - acc: 1.0000 - val_loss: 0.8030 - val_acc: 1.0000\n",
      "Epoch 635/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9400 - acc: 0.9524 - val_loss: 0.8028 - val_acc: 1.0000\n",
      "Epoch 636/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9179 - acc: 0.9683 - val_loss: 0.8027 - val_acc: 1.0000\n",
      "Epoch 637/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0233 - acc: 0.9683 - val_loss: 0.8042 - val_acc: 1.0000\n",
      "Epoch 638/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9377 - acc: 0.9524 - val_loss: 0.8058 - val_acc: 1.0000\n",
      "Epoch 639/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0188 - acc: 0.9683 - val_loss: 0.8072 - val_acc: 1.0000\n",
      "Epoch 640/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9476 - acc: 0.9841 - val_loss: 0.8087 - val_acc: 1.0000\n",
      "Epoch 641/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9466 - acc: 0.9841 - val_loss: 0.8083 - val_acc: 1.0000\n",
      "Epoch 642/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8785 - acc: 1.0000 - val_loss: 0.8066 - val_acc: 1.0000\n",
      "Epoch 643/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9231 - acc: 0.9841 - val_loss: 0.8043 - val_acc: 1.0000\n",
      "Epoch 644/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9770 - acc: 0.9683 - val_loss: 0.8044 - val_acc: 1.0000\n",
      "Epoch 645/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0154 - acc: 0.9683 - val_loss: 0.8056 - val_acc: 1.0000\n",
      "Epoch 646/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9229 - acc: 1.0000 - val_loss: 0.8057 - val_acc: 1.0000\n",
      "Epoch 647/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9095 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 1.0000\n",
      "Epoch 648/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9405 - acc: 0.9841 - val_loss: 0.8050 - val_acc: 1.0000\n",
      "Epoch 649/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9349 - acc: 0.9841 - val_loss: 0.8057 - val_acc: 1.0000\n",
      "Epoch 650/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9503 - acc: 1.0000 - val_loss: 0.8066 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00650: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 651/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9055 - acc: 0.9841 - val_loss: 0.8054 - val_acc: 1.0000\n",
      "Epoch 652/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8874 - acc: 1.0000 - val_loss: 0.8037 - val_acc: 1.0000\n",
      "Epoch 653/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9103 - acc: 0.9841 - val_loss: 0.8022 - val_acc: 1.0000\n",
      "Epoch 654/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9391 - acc: 1.0000 - val_loss: 0.8002 - val_acc: 1.0000\n",
      "Epoch 655/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9193 - acc: 1.0000 - val_loss: 0.7989 - val_acc: 1.0000\n",
      "Epoch 656/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9153 - acc: 1.0000 - val_loss: 0.7978 - val_acc: 1.0000\n",
      "Epoch 657/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9666 - acc: 0.9524 - val_loss: 0.7976 - val_acc: 1.0000\n",
      "Epoch 658/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8834 - acc: 1.0000 - val_loss: 0.7967 - val_acc: 1.0000\n",
      "Epoch 659/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8770 - acc: 0.9841 - val_loss: 0.7947 - val_acc: 1.0000\n",
      "Epoch 660/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9258 - acc: 0.9841 - val_loss: 0.7930 - val_acc: 1.0000\n",
      "Epoch 661/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8975 - acc: 0.9841 - val_loss: 0.7919 - val_acc: 1.0000\n",
      "Epoch 662/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9058 - acc: 0.9841 - val_loss: 0.7913 - val_acc: 1.0000\n",
      "Epoch 663/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8922 - acc: 1.0000 - val_loss: 0.7909 - val_acc: 1.0000\n",
      "Epoch 664/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8457 - acc: 1.0000 - val_loss: 0.7899 - val_acc: 1.0000\n",
      "Epoch 665/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9387 - acc: 0.9841 - val_loss: 0.7884 - val_acc: 1.0000\n",
      "Epoch 666/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9095 - acc: 0.9683 - val_loss: 0.7883 - val_acc: 1.0000\n",
      "Epoch 667/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8964 - acc: 1.0000 - val_loss: 0.7883 - val_acc: 1.0000\n",
      "Epoch 668/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9169 - acc: 1.0000 - val_loss: 0.7885 - val_acc: 1.0000\n",
      "Epoch 669/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9656 - acc: 0.9683 - val_loss: 0.7886 - val_acc: 1.0000\n",
      "Epoch 670/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9814 - acc: 0.9524 - val_loss: 0.7892 - val_acc: 1.0000\n",
      "Epoch 671/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9169 - acc: 0.9524 - val_loss: 0.7899 - val_acc: 1.0000\n",
      "Epoch 672/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9075 - acc: 0.9841 - val_loss: 0.7896 - val_acc: 1.0000\n",
      "Epoch 673/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8921 - acc: 0.9841 - val_loss: 0.7889 - val_acc: 1.0000\n",
      "Epoch 674/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9227 - acc: 0.9841 - val_loss: 0.7882 - val_acc: 1.0000\n",
      "Epoch 675/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9409 - acc: 0.9524 - val_loss: 0.7877 - val_acc: 1.0000\n",
      "Epoch 676/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9134 - acc: 0.9524 - val_loss: 0.7876 - val_acc: 1.0000\n",
      "Epoch 677/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8929 - acc: 0.9841 - val_loss: 0.7866 - val_acc: 1.0000\n",
      "Epoch 678/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9195 - acc: 0.9841 - val_loss: 0.7863 - val_acc: 1.0000\n",
      "Epoch 679/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9309 - acc: 0.9524 - val_loss: 0.7861 - val_acc: 1.0000\n",
      "Epoch 680/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8933 - acc: 0.9841 - val_loss: 0.7861 - val_acc: 1.0000\n",
      "Epoch 681/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9226 - acc: 1.0000 - val_loss: 0.7868 - val_acc: 1.0000\n",
      "Epoch 682/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9582 - acc: 0.9683 - val_loss: 0.7872 - val_acc: 1.0000\n",
      "Epoch 683/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8723 - acc: 1.0000 - val_loss: 0.7866 - val_acc: 1.0000\n",
      "Epoch 684/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9019 - acc: 0.9841 - val_loss: 0.7858 - val_acc: 1.0000\n",
      "Epoch 685/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8895 - acc: 0.9841 - val_loss: 0.7845 - val_acc: 1.0000\n",
      "Epoch 686/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8799 - acc: 0.9841 - val_loss: 0.7832 - val_acc: 1.0000\n",
      "Epoch 687/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8745 - acc: 1.0000 - val_loss: 0.7825 - val_acc: 1.0000\n",
      "Epoch 688/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9179 - acc: 0.9683 - val_loss: 0.7821 - val_acc: 1.0000\n",
      "Epoch 689/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8990 - acc: 0.9841 - val_loss: 0.7822 - val_acc: 1.0000\n",
      "Epoch 690/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8963 - acc: 0.9841 - val_loss: 0.7816 - val_acc: 1.0000\n",
      "Epoch 691/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8949 - acc: 1.0000 - val_loss: 0.7814 - val_acc: 1.0000\n",
      "Epoch 692/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8930 - acc: 1.0000 - val_loss: 0.7815 - val_acc: 1.0000\n",
      "Epoch 693/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9176 - acc: 0.9683 - val_loss: 0.7816 - val_acc: 1.0000\n",
      "Epoch 694/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8823 - acc: 0.9683 - val_loss: 0.7812 - val_acc: 1.0000\n",
      "Epoch 695/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9007 - acc: 1.0000 - val_loss: 0.7808 - val_acc: 1.0000\n",
      "Epoch 696/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9079 - acc: 0.9683 - val_loss: 0.7806 - val_acc: 1.0000\n",
      "Epoch 697/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9354 - acc: 0.9841 - val_loss: 0.7815 - val_acc: 1.0000\n",
      "Epoch 698/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8758 - acc: 1.0000 - val_loss: 0.7816 - val_acc: 1.0000\n",
      "Epoch 699/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9270 - acc: 0.9683 - val_loss: 0.7815 - val_acc: 1.0000\n",
      "Epoch 700/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8716 - acc: 1.0000 - val_loss: 0.7811 - val_acc: 1.0000\n",
      "Epoch 701/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9077 - acc: 0.9524 - val_loss: 0.7806 - val_acc: 1.0000\n",
      "Epoch 702/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9269 - acc: 0.9683 - val_loss: 0.7805 - val_acc: 1.0000\n",
      "Epoch 703/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8991 - acc: 1.0000 - val_loss: 0.7804 - val_acc: 1.0000\n",
      "Epoch 704/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8742 - acc: 1.0000 - val_loss: 0.7798 - val_acc: 1.0000\n",
      "Epoch 705/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9053 - acc: 1.0000 - val_loss: 0.7794 - val_acc: 1.0000\n",
      "Epoch 706/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9211 - acc: 0.9841 - val_loss: 0.7801 - val_acc: 1.0000\n",
      "Epoch 707/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8645 - acc: 0.9841 - val_loss: 0.7802 - val_acc: 1.0000\n",
      "Epoch 708/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9175 - acc: 0.9683 - val_loss: 0.7806 - val_acc: 1.0000\n",
      "Epoch 709/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9038 - acc: 0.9841 - val_loss: 0.7805 - val_acc: 1.0000\n",
      "Epoch 710/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8609 - acc: 1.0000 - val_loss: 0.7802 - val_acc: 1.0000\n",
      "Epoch 711/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8385 - acc: 1.0000 - val_loss: 0.7786 - val_acc: 1.0000\n",
      "Epoch 712/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9746 - acc: 0.9524 - val_loss: 0.7788 - val_acc: 1.0000\n",
      "Epoch 713/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8978 - acc: 0.9841 - val_loss: 0.7792 - val_acc: 1.0000\n",
      "Epoch 714/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9307 - acc: 0.9524 - val_loss: 0.7792 - val_acc: 1.0000\n",
      "Epoch 715/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9361 - acc: 0.9841 - val_loss: 0.7795 - val_acc: 1.0000\n",
      "Epoch 716/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8804 - acc: 1.0000 - val_loss: 0.7792 - val_acc: 1.0000\n",
      "Epoch 717/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8681 - acc: 1.0000 - val_loss: 0.7782 - val_acc: 1.0000\n",
      "Epoch 718/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8670 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 1.0000\n",
      "Epoch 719/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9420 - acc: 0.9683 - val_loss: 0.7769 - val_acc: 1.0000\n",
      "Epoch 720/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9103 - acc: 0.9683 - val_loss: 0.7777 - val_acc: 1.0000\n",
      "Epoch 721/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9285 - acc: 0.9841 - val_loss: 0.7784 - val_acc: 1.0000\n",
      "Epoch 722/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8842 - acc: 0.9841 - val_loss: 0.7791 - val_acc: 1.0000\n",
      "Epoch 723/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8469 - acc: 1.0000 - val_loss: 0.7784 - val_acc: 1.0000\n",
      "Epoch 724/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8617 - acc: 1.0000 - val_loss: 0.7770 - val_acc: 1.0000\n",
      "Epoch 725/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8897 - acc: 1.0000 - val_loss: 0.7768 - val_acc: 1.0000\n",
      "Epoch 726/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8952 - acc: 0.9841 - val_loss: 0.7771 - val_acc: 1.0000\n",
      "Epoch 727/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8827 - acc: 1.0000 - val_loss: 0.7770 - val_acc: 1.0000\n",
      "Epoch 728/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8694 - acc: 1.0000 - val_loss: 0.7761 - val_acc: 1.0000\n",
      "Epoch 729/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8965 - acc: 0.9841 - val_loss: 0.7761 - val_acc: 1.0000\n",
      "Epoch 730/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9024 - acc: 1.0000 - val_loss: 0.7764 - val_acc: 1.0000\n",
      "Epoch 731/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8458 - acc: 0.9841 - val_loss: 0.7756 - val_acc: 1.0000\n",
      "Epoch 732/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8996 - acc: 0.9841 - val_loss: 0.7745 - val_acc: 1.0000\n",
      "Epoch 733/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8911 - acc: 0.9683 - val_loss: 0.7747 - val_acc: 1.0000\n",
      "Epoch 734/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8757 - acc: 0.9841 - val_loss: 0.7742 - val_acc: 1.0000\n",
      "Epoch 735/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8905 - acc: 0.9841 - val_loss: 0.7736 - val_acc: 1.0000\n",
      "Epoch 736/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9083 - acc: 0.9683 - val_loss: 0.7744 - val_acc: 1.0000\n",
      "Epoch 737/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8743 - acc: 0.9841 - val_loss: 0.7739 - val_acc: 1.0000\n",
      "Epoch 738/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8714 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 1.0000\n",
      "Epoch 739/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9397 - acc: 0.9683 - val_loss: 0.7738 - val_acc: 1.0000\n",
      "Epoch 740/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8810 - acc: 0.9841 - val_loss: 0.7743 - val_acc: 1.0000\n",
      "Epoch 741/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8944 - acc: 0.9841 - val_loss: 0.7741 - val_acc: 1.0000\n",
      "Epoch 742/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9008 - acc: 1.0000 - val_loss: 0.7742 - val_acc: 1.0000\n",
      "Epoch 743/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8927 - acc: 0.9841 - val_loss: 0.7741 - val_acc: 1.0000\n",
      "Epoch 744/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8810 - acc: 0.9841 - val_loss: 0.7741 - val_acc: 1.0000\n",
      "Epoch 745/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8598 - acc: 1.0000 - val_loss: 0.7736 - val_acc: 1.0000\n",
      "Epoch 746/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8789 - acc: 0.9841 - val_loss: 0.7726 - val_acc: 1.0000\n",
      "Epoch 747/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8948 - acc: 0.9683 - val_loss: 0.7725 - val_acc: 1.0000\n",
      "Epoch 748/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8631 - acc: 0.9841 - val_loss: 0.7719 - val_acc: 1.0000\n",
      "Epoch 749/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9062 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 1.0000\n",
      "Epoch 750/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9045 - acc: 0.9841 - val_loss: 0.7730 - val_acc: 1.0000\n",
      "Epoch 751/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8656 - acc: 0.9841 - val_loss: 0.7727 - val_acc: 1.0000\n",
      "Epoch 752/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8587 - acc: 0.9841 - val_loss: 0.7718 - val_acc: 1.0000\n",
      "Epoch 753/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9125 - acc: 1.0000 - val_loss: 0.7716 - val_acc: 1.0000\n",
      "Epoch 754/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8840 - acc: 1.0000 - val_loss: 0.7717 - val_acc: 1.0000\n",
      "Epoch 755/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0682 - acc: 0.9206 - val_loss: 0.7731 - val_acc: 1.0000\n",
      "Epoch 756/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8889 - acc: 0.9841 - val_loss: 0.7742 - val_acc: 1.0000\n",
      "Epoch 757/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8773 - acc: 0.9841 - val_loss: 0.7737 - val_acc: 1.0000\n",
      "Epoch 758/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8770 - acc: 0.9841 - val_loss: 0.7731 - val_acc: 1.0000\n",
      "Epoch 759/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 1.0000\n",
      "Epoch 760/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9121 - acc: 0.9683 - val_loss: 0.7728 - val_acc: 1.0000\n",
      "Epoch 761/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8539 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 1.0000\n",
      "Epoch 762/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9317 - acc: 0.9683 - val_loss: 0.7719 - val_acc: 1.0000\n",
      "Epoch 763/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8717 - acc: 0.9841 - val_loss: 0.7714 - val_acc: 1.0000\n",
      "Epoch 764/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9129 - acc: 0.9524 - val_loss: 0.7711 - val_acc: 1.0000\n",
      "Epoch 765/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8759 - acc: 1.0000 - val_loss: 0.7713 - val_acc: 1.0000\n",
      "Epoch 766/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8745 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 1.0000\n",
      "Epoch 767/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9632 - acc: 0.9683 - val_loss: 0.7720 - val_acc: 1.0000\n",
      "Epoch 768/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8863 - acc: 0.9841 - val_loss: 0.7725 - val_acc: 1.0000\n",
      "Epoch 769/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8927 - acc: 0.9841 - val_loss: 0.7726 - val_acc: 1.0000\n",
      "Epoch 770/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8807 - acc: 0.9841 - val_loss: 0.7718 - val_acc: 1.0000\n",
      "Epoch 771/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8892 - acc: 1.0000 - val_loss: 0.7711 - val_acc: 1.0000\n",
      "Epoch 772/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8577 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 1.0000\n",
      "Epoch 773/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8980 - acc: 0.9683 - val_loss: 0.7702 - val_acc: 1.0000\n",
      "Epoch 774/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9463 - acc: 0.9524 - val_loss: 0.7703 - val_acc: 1.0000\n",
      "Epoch 775/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9181 - acc: 0.9524 - val_loss: 0.7706 - val_acc: 1.0000\n",
      "Epoch 776/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8457 - acc: 1.0000 - val_loss: 0.7697 - val_acc: 1.0000\n",
      "Epoch 777/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9141 - acc: 0.9683 - val_loss: 0.7696 - val_acc: 1.0000\n",
      "Epoch 778/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8754 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 1.0000\n",
      "Epoch 779/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 1.0000\n",
      "Epoch 780/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8428 - acc: 0.9841 - val_loss: 0.7691 - val_acc: 1.0000\n",
      "Epoch 781/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8973 - acc: 0.9841 - val_loss: 0.7691 - val_acc: 1.0000\n",
      "Epoch 782/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9064 - acc: 0.9841 - val_loss: 0.7690 - val_acc: 1.0000\n",
      "Epoch 783/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8397 - acc: 0.9841 - val_loss: 0.7681 - val_acc: 1.0000\n",
      "Epoch 784/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9573 - acc: 0.9683 - val_loss: 0.7689 - val_acc: 1.0000\n",
      "Epoch 785/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8532 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 1.0000\n",
      "Epoch 786/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8540 - acc: 0.9841 - val_loss: 0.7687 - val_acc: 1.0000\n",
      "Epoch 787/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8723 - acc: 0.9841 - val_loss: 0.7682 - val_acc: 1.0000\n",
      "Epoch 788/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8611 - acc: 1.0000 - val_loss: 0.7679 - val_acc: 1.0000\n",
      "Epoch 789/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8597 - acc: 0.9683 - val_loss: 0.7671 - val_acc: 1.0000\n",
      "Epoch 790/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8714 - acc: 0.9683 - val_loss: 0.7672 - val_acc: 1.0000\n",
      "Epoch 791/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9137 - acc: 0.9524 - val_loss: 0.7672 - val_acc: 1.0000\n",
      "Epoch 792/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8704 - acc: 1.0000 - val_loss: 0.7674 - val_acc: 1.0000\n",
      "Epoch 793/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9126 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 1.0000\n",
      "Epoch 794/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8906 - acc: 0.9841 - val_loss: 0.7671 - val_acc: 1.0000\n",
      "Epoch 795/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9438 - acc: 0.9683 - val_loss: 0.7673 - val_acc: 1.0000\n",
      "Epoch 796/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8683 - acc: 0.9841 - val_loss: 0.7679 - val_acc: 1.0000\n",
      "Epoch 797/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8900 - acc: 1.0000 - val_loss: 0.7677 - val_acc: 1.0000\n",
      "Epoch 798/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9072 - acc: 0.9524 - val_loss: 0.7676 - val_acc: 1.0000\n",
      "Epoch 799/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8389 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 1.0000\n",
      "Epoch 800/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8522 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 1.0000\n",
      "Epoch 801/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8887 - acc: 1.0000 - val_loss: 0.7659 - val_acc: 1.0000\n",
      "Epoch 802/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8456 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 1.0000\n",
      "Epoch 803/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8624 - acc: 1.0000 - val_loss: 0.7652 - val_acc: 1.0000\n",
      "Epoch 804/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9213 - acc: 0.9683 - val_loss: 0.7653 - val_acc: 1.0000\n",
      "Epoch 805/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9190 - acc: 0.9841 - val_loss: 0.7664 - val_acc: 1.0000\n",
      "Epoch 806/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9001 - acc: 1.0000 - val_loss: 0.7660 - val_acc: 1.0000\n",
      "Epoch 807/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9674 - acc: 0.9365 - val_loss: 0.7660 - val_acc: 1.0000\n",
      "Epoch 808/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8811 - acc: 0.9841 - val_loss: 0.7662 - val_acc: 1.0000\n",
      "Epoch 809/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9109 - acc: 0.9683 - val_loss: 0.7662 - val_acc: 1.0000\n",
      "Epoch 810/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8717 - acc: 1.0000 - val_loss: 0.7662 - val_acc: 1.0000\n",
      "Epoch 811/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8895 - acc: 0.9841 - val_loss: 0.7664 - val_acc: 1.0000\n",
      "Epoch 812/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8616 - acc: 1.0000 - val_loss: 0.7659 - val_acc: 1.0000\n",
      "Epoch 813/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8189 - acc: 1.0000 - val_loss: 0.7648 - val_acc: 1.0000\n",
      "Epoch 814/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8693 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 1.0000\n",
      "Epoch 815/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9291 - acc: 0.9683 - val_loss: 0.7633 - val_acc: 1.0000\n",
      "Epoch 816/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8688 - acc: 0.9841 - val_loss: 0.7644 - val_acc: 1.0000\n",
      "Epoch 817/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8871 - acc: 0.9524 - val_loss: 0.7644 - val_acc: 1.0000\n",
      "Epoch 818/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8907 - acc: 0.9841 - val_loss: 0.7642 - val_acc: 1.0000\n",
      "Epoch 819/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8701 - acc: 0.9841 - val_loss: 0.7644 - val_acc: 1.0000\n",
      "Epoch 820/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9343 - acc: 0.9683 - val_loss: 0.7648 - val_acc: 1.0000\n",
      "Epoch 821/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8874 - acc: 0.9841 - val_loss: 0.7652 - val_acc: 1.0000\n",
      "Epoch 822/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8477 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 1.0000\n",
      "Epoch 823/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8394 - acc: 0.9841 - val_loss: 0.7641 - val_acc: 1.0000\n",
      "Epoch 824/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8621 - acc: 0.9683 - val_loss: 0.7631 - val_acc: 1.0000\n",
      "Epoch 825/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8991 - acc: 0.9841 - val_loss: 0.7625 - val_acc: 1.0000\n",
      "Epoch 826/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9213 - acc: 0.9683 - val_loss: 0.7626 - val_acc: 1.0000\n",
      "Epoch 827/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8498 - acc: 1.0000 - val_loss: 0.7622 - val_acc: 1.0000\n",
      "Epoch 828/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8441 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 1.0000\n",
      "Epoch 829/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9899 - acc: 0.9365 - val_loss: 0.7620 - val_acc: 1.0000\n",
      "Epoch 830/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9354 - acc: 0.9841 - val_loss: 0.7627 - val_acc: 1.0000\n",
      "Epoch 831/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8905 - acc: 1.0000 - val_loss: 0.7632 - val_acc: 1.0000\n",
      "Epoch 832/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8497 - acc: 0.9841 - val_loss: 0.7630 - val_acc: 1.0000\n",
      "Epoch 833/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8813 - acc: 0.9841 - val_loss: 0.7626 - val_acc: 1.0000\n",
      "Epoch 834/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8672 - acc: 0.9841 - val_loss: 0.7626 - val_acc: 1.0000\n",
      "Epoch 835/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8974 - acc: 0.9841 - val_loss: 0.7627 - val_acc: 1.0000\n",
      "Epoch 836/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9069 - acc: 0.9683 - val_loss: 0.7625 - val_acc: 1.0000\n",
      "Epoch 837/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9051 - acc: 0.9841 - val_loss: 0.7626 - val_acc: 1.0000\n",
      "Epoch 838/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8646 - acc: 1.0000 - val_loss: 0.7621 - val_acc: 1.0000\n",
      "Epoch 839/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8558 - acc: 0.9683 - val_loss: 0.7614 - val_acc: 1.0000\n",
      "Epoch 840/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8743 - acc: 0.9841 - val_loss: 0.7608 - val_acc: 1.0000\n",
      "Epoch 841/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8591 - acc: 0.9841 - val_loss: 0.7600 - val_acc: 1.0000\n",
      "Epoch 842/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9253 - acc: 0.9683 - val_loss: 0.7598 - val_acc: 1.0000\n",
      "Epoch 843/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9134 - acc: 0.9841 - val_loss: 0.7600 - val_acc: 1.0000\n",
      "Epoch 844/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9410 - acc: 0.9524 - val_loss: 0.7608 - val_acc: 1.0000\n",
      "Epoch 845/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8707 - acc: 0.9683 - val_loss: 0.7611 - val_acc: 1.0000\n",
      "Epoch 846/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8920 - acc: 0.9841 - val_loss: 0.7604 - val_acc: 1.0000\n",
      "Epoch 847/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8935 - acc: 0.9841 - val_loss: 0.7609 - val_acc: 1.0000\n",
      "Epoch 848/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8341 - acc: 1.0000 - val_loss: 0.7606 - val_acc: 1.0000\n",
      "Epoch 849/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8733 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 1.0000\n",
      "Epoch 850/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8756 - acc: 0.9683 - val_loss: 0.7592 - val_acc: 1.0000\n",
      "Epoch 851/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9152 - acc: 0.9841 - val_loss: 0.7596 - val_acc: 1.0000\n",
      "Epoch 852/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8915 - acc: 0.9683 - val_loss: 0.7598 - val_acc: 1.0000\n",
      "Epoch 853/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8771 - acc: 0.9841 - val_loss: 0.7600 - val_acc: 1.0000\n",
      "Epoch 854/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8402 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 1.0000\n",
      "Epoch 855/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8716 - acc: 0.9524 - val_loss: 0.7598 - val_acc: 1.0000\n",
      "Epoch 856/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8997 - acc: 1.0000 - val_loss: 0.7597 - val_acc: 1.0000\n",
      "Epoch 857/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8946 - acc: 0.9841 - val_loss: 0.7598 - val_acc: 1.0000\n",
      "Epoch 858/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8452 - acc: 0.9841 - val_loss: 0.7596 - val_acc: 1.0000\n",
      "Epoch 859/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9234 - acc: 0.9683 - val_loss: 0.7593 - val_acc: 1.0000\n",
      "Epoch 860/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8922 - acc: 1.0000 - val_loss: 0.7591 - val_acc: 1.0000\n",
      "Epoch 861/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9197 - acc: 0.9365 - val_loss: 0.7594 - val_acc: 1.0000\n",
      "Epoch 862/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8343 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 1.0000\n",
      "Epoch 863/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8672 - acc: 1.0000 - val_loss: 0.7589 - val_acc: 1.0000\n",
      "Epoch 864/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8810 - acc: 0.9524 - val_loss: 0.7592 - val_acc: 1.0000\n",
      "Epoch 865/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8259 - acc: 1.0000 - val_loss: 0.7586 - val_acc: 1.0000\n",
      "Epoch 866/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8635 - acc: 1.0000 - val_loss: 0.7583 - val_acc: 1.0000\n",
      "Epoch 867/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8543 - acc: 0.9841 - val_loss: 0.7582 - val_acc: 1.0000\n",
      "Epoch 868/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8434 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 1.0000\n",
      "Epoch 869/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8483 - acc: 0.9841 - val_loss: 0.7576 - val_acc: 1.0000\n",
      "Epoch 870/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8757 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 1.0000\n",
      "Epoch 871/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8566 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 1.0000\n",
      "Epoch 872/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8759 - acc: 0.9683 - val_loss: 0.7569 - val_acc: 1.0000\n",
      "Epoch 873/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8662 - acc: 1.0000 - val_loss: 0.7563 - val_acc: 1.0000\n",
      "Epoch 874/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9279 - acc: 0.9841 - val_loss: 0.7566 - val_acc: 1.0000\n",
      "Epoch 875/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8279 - acc: 1.0000 - val_loss: 0.7564 - val_acc: 1.0000\n",
      "Epoch 876/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8728 - acc: 1.0000 - val_loss: 0.7560 - val_acc: 1.0000\n",
      "Epoch 877/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8739 - acc: 0.9683 - val_loss: 0.7558 - val_acc: 1.0000\n",
      "Epoch 878/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8430 - acc: 1.0000 - val_loss: 0.7554 - val_acc: 1.0000\n",
      "Epoch 879/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8524 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 1.0000\n",
      "Epoch 880/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8481 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 1.0000\n",
      "Epoch 881/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8485 - acc: 0.9841 - val_loss: 0.7537 - val_acc: 1.0000\n",
      "Epoch 882/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8828 - acc: 0.9524 - val_loss: 0.7536 - val_acc: 1.0000\n",
      "Epoch 883/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8590 - acc: 0.9841 - val_loss: 0.7538 - val_acc: 1.0000\n",
      "Epoch 884/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8786 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 1.0000\n",
      "Epoch 885/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9692 - acc: 0.9524 - val_loss: 0.7555 - val_acc: 1.0000\n",
      "Epoch 886/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8470 - acc: 0.9683 - val_loss: 0.7566 - val_acc: 1.0000\n",
      "Epoch 887/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8789 - acc: 0.9841 - val_loss: 0.7564 - val_acc: 1.0000\n",
      "Epoch 888/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8853 - acc: 0.9841 - val_loss: 0.7564 - val_acc: 1.0000\n",
      "Epoch 889/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9056 - acc: 0.9683 - val_loss: 0.7568 - val_acc: 1.0000\n",
      "Epoch 890/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8758 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 1.0000\n",
      "Epoch 891/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9426 - acc: 0.9524 - val_loss: 0.7574 - val_acc: 1.0000\n",
      "Epoch 892/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8497 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 1.0000\n",
      "Epoch 893/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8685 - acc: 0.9841 - val_loss: 0.7560 - val_acc: 1.0000\n",
      "Epoch 894/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9347 - acc: 0.9683 - val_loss: 0.7563 - val_acc: 1.0000\n",
      "Epoch 895/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8368 - acc: 0.9841 - val_loss: 0.7557 - val_acc: 1.0000\n",
      "Epoch 896/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8272 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 1.0000\n",
      "Epoch 897/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9139 - acc: 0.9841 - val_loss: 0.7548 - val_acc: 1.0000\n",
      "Epoch 898/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8986 - acc: 1.0000 - val_loss: 0.7557 - val_acc: 1.0000\n",
      "Epoch 899/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8855 - acc: 0.9841 - val_loss: 0.7556 - val_acc: 1.0000\n",
      "Epoch 900/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9198 - acc: 0.9841 - val_loss: 0.7557 - val_acc: 1.0000\n",
      "Epoch 901/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8794 - acc: 0.9683 - val_loss: 0.7561 - val_acc: 1.0000\n",
      "Epoch 902/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8269 - acc: 1.0000 - val_loss: 0.7558 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00902: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 903/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8367 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 1.0000\n",
      "Epoch 904/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8849 - acc: 0.9841 - val_loss: 0.7542 - val_acc: 1.0000\n",
      "Epoch 905/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8386 - acc: 0.9841 - val_loss: 0.7533 - val_acc: 1.0000\n",
      "Epoch 906/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8891 - acc: 0.9841 - val_loss: 0.7526 - val_acc: 1.0000\n",
      "Epoch 907/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8767 - acc: 0.9841 - val_loss: 0.7524 - val_acc: 1.0000\n",
      "Epoch 908/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8212 - acc: 1.0000 - val_loss: 0.7519 - val_acc: 1.0000\n",
      "Epoch 909/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8743 - acc: 1.0000 - val_loss: 0.7513 - val_acc: 1.0000\n",
      "Epoch 910/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9341 - acc: 0.9524 - val_loss: 0.7508 - val_acc: 1.0000\n",
      "Epoch 911/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8822 - acc: 0.9841 - val_loss: 0.7504 - val_acc: 1.0000\n",
      "Epoch 912/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8859 - acc: 1.0000 - val_loss: 0.7500 - val_acc: 1.0000\n",
      "Epoch 913/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8448 - acc: 0.9841 - val_loss: 0.7497 - val_acc: 1.0000\n",
      "Epoch 914/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9134 - acc: 0.9524 - val_loss: 0.7495 - val_acc: 1.0000\n",
      "Epoch 915/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8564 - acc: 0.9683 - val_loss: 0.7495 - val_acc: 1.0000\n",
      "Epoch 916/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8372 - acc: 0.9841 - val_loss: 0.7492 - val_acc: 1.0000\n",
      "Epoch 917/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8018 - acc: 1.0000 - val_loss: 0.7489 - val_acc: 1.0000\n",
      "Epoch 918/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8233 - acc: 1.0000 - val_loss: 0.7484 - val_acc: 1.0000\n",
      "Epoch 919/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8614 - acc: 1.0000 - val_loss: 0.7479 - val_acc: 1.0000\n",
      "Epoch 920/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8136 - acc: 1.0000 - val_loss: 0.7473 - val_acc: 1.0000\n",
      "Epoch 921/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8661 - acc: 0.9524 - val_loss: 0.7468 - val_acc: 1.0000\n",
      "Epoch 922/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8670 - acc: 0.9841 - val_loss: 0.7465 - val_acc: 1.0000\n",
      "Epoch 923/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8592 - acc: 0.9841 - val_loss: 0.7461 - val_acc: 1.0000\n",
      "Epoch 924/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8405 - acc: 0.9683 - val_loss: 0.7458 - val_acc: 1.0000\n",
      "Epoch 925/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8404 - acc: 0.9683 - val_loss: 0.7454 - val_acc: 1.0000\n",
      "Epoch 926/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8273 - acc: 1.0000 - val_loss: 0.7450 - val_acc: 1.0000\n",
      "Epoch 927/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8112 - acc: 0.9841 - val_loss: 0.7447 - val_acc: 1.0000\n",
      "Epoch 928/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8115 - acc: 1.0000 - val_loss: 0.7443 - val_acc: 1.0000\n",
      "Epoch 929/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8357 - acc: 0.9841 - val_loss: 0.7440 - val_acc: 1.0000\n",
      "Epoch 930/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8131 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 1.0000\n",
      "Epoch 931/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8432 - acc: 1.0000 - val_loss: 0.7434 - val_acc: 1.0000\n",
      "Epoch 932/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8320 - acc: 1.0000 - val_loss: 0.7434 - val_acc: 1.0000\n",
      "Epoch 933/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8454 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 1.0000\n",
      "Epoch 934/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8598 - acc: 0.9841 - val_loss: 0.7432 - val_acc: 1.0000\n",
      "Epoch 935/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9545 - acc: 0.9365 - val_loss: 0.7435 - val_acc: 1.0000\n",
      "Epoch 936/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8292 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 1.0000\n",
      "Epoch 937/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8042 - acc: 0.9841 - val_loss: 0.7434 - val_acc: 1.0000\n",
      "Epoch 938/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8203 - acc: 1.0000 - val_loss: 0.7427 - val_acc: 1.0000\n",
      "Epoch 939/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8964 - acc: 0.9683 - val_loss: 0.7429 - val_acc: 1.0000\n",
      "Epoch 940/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8231 - acc: 1.0000 - val_loss: 0.7431 - val_acc: 1.0000\n",
      "Epoch 941/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8437 - acc: 0.9841 - val_loss: 0.7429 - val_acc: 1.0000\n",
      "Epoch 942/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8159 - acc: 1.0000 - val_loss: 0.7429 - val_acc: 1.0000\n",
      "Epoch 943/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8979 - acc: 0.9683 - val_loss: 0.7433 - val_acc: 1.0000\n",
      "Epoch 944/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9499 - acc: 0.9524 - val_loss: 0.7436 - val_acc: 1.0000\n",
      "Epoch 945/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8545 - acc: 0.9841 - val_loss: 0.7440 - val_acc: 1.0000\n",
      "Epoch 946/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9174 - acc: 0.9683 - val_loss: 0.7443 - val_acc: 1.0000\n",
      "Epoch 947/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8292 - acc: 1.0000 - val_loss: 0.7445 - val_acc: 1.0000\n",
      "Epoch 948/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8565 - acc: 1.0000 - val_loss: 0.7443 - val_acc: 1.0000\n",
      "Epoch 949/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8368 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 1.0000\n",
      "Epoch 950/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8538 - acc: 1.0000 - val_loss: 0.7432 - val_acc: 1.0000\n",
      "Epoch 951/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8662 - acc: 0.9841 - val_loss: 0.7431 - val_acc: 1.0000\n",
      "Epoch 952/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8399 - acc: 0.9841 - val_loss: 0.7434 - val_acc: 1.0000\n",
      "Epoch 953/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8686 - acc: 0.9683 - val_loss: 0.7433 - val_acc: 1.0000\n",
      "Epoch 954/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8231 - acc: 1.0000 - val_loss: 0.7430 - val_acc: 1.0000\n",
      "Epoch 955/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8009 - acc: 0.9841 - val_loss: 0.7426 - val_acc: 1.0000\n",
      "Epoch 956/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8279 - acc: 1.0000 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 957/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8481 - acc: 0.9841 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 958/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8544 - acc: 0.9841 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 959/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8526 - acc: 0.9841 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 960/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8646 - acc: 0.9841 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 961/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7993 - acc: 1.0000 - val_loss: 0.7418 - val_acc: 1.0000\n",
      "Epoch 962/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8405 - acc: 0.9841 - val_loss: 0.7412 - val_acc: 1.0000\n",
      "Epoch 963/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9270 - acc: 0.9683 - val_loss: 0.7414 - val_acc: 1.0000\n",
      "Epoch 964/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8260 - acc: 1.0000 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 965/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8631 - acc: 0.9683 - val_loss: 0.7420 - val_acc: 1.0000\n",
      "Epoch 966/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9313 - acc: 0.9365 - val_loss: 0.7422 - val_acc: 1.0000\n",
      "Epoch 967/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9139 - acc: 0.9841 - val_loss: 0.7427 - val_acc: 1.0000\n",
      "Epoch 968/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8273 - acc: 1.0000 - val_loss: 0.7428 - val_acc: 1.0000\n",
      "Epoch 969/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9038 - acc: 0.9841 - val_loss: 0.7426 - val_acc: 1.0000\n",
      "Epoch 970/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8717 - acc: 0.9841 - val_loss: 0.7426 - val_acc: 1.0000\n",
      "Epoch 971/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8314 - acc: 0.9841 - val_loss: 0.7423 - val_acc: 1.0000\n",
      "Epoch 972/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8789 - acc: 0.9841 - val_loss: 0.7422 - val_acc: 1.0000\n",
      "Epoch 973/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8171 - acc: 1.0000 - val_loss: 0.7418 - val_acc: 1.0000\n",
      "Epoch 974/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8287 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 1.0000\n",
      "Epoch 975/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9461 - acc: 0.9206 - val_loss: 0.7418 - val_acc: 1.0000\n",
      "Epoch 976/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8425 - acc: 0.9841 - val_loss: 0.7417 - val_acc: 1.0000\n",
      "Epoch 977/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8393 - acc: 0.9841 - val_loss: 0.7416 - val_acc: 1.0000\n",
      "Epoch 978/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8181 - acc: 1.0000 - val_loss: 0.7413 - val_acc: 1.0000\n",
      "Epoch 979/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8978 - acc: 0.9841 - val_loss: 0.7410 - val_acc: 1.0000\n",
      "Epoch 980/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8453 - acc: 0.9841 - val_loss: 0.7409 - val_acc: 1.0000\n",
      "Epoch 981/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8500 - acc: 0.9841 - val_loss: 0.7410 - val_acc: 1.0000\n",
      "Epoch 982/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8446 - acc: 0.9841 - val_loss: 0.7411 - val_acc: 1.0000\n",
      "Epoch 983/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8306 - acc: 1.0000 - val_loss: 0.7407 - val_acc: 1.0000\n",
      "Epoch 984/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7952 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 1.0000\n",
      "Epoch 985/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8430 - acc: 0.9841 - val_loss: 0.7394 - val_acc: 1.0000\n",
      "Epoch 986/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9487 - acc: 0.9524 - val_loss: 0.7401 - val_acc: 1.0000\n",
      "Epoch 987/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8955 - acc: 0.9841 - val_loss: 0.7410 - val_acc: 1.0000\n",
      "Epoch 988/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8440 - acc: 0.9683 - val_loss: 0.7414 - val_acc: 1.0000\n",
      "Epoch 989/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8308 - acc: 0.9841 - val_loss: 0.7411 - val_acc: 1.0000\n",
      "Epoch 990/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8171 - acc: 0.9841 - val_loss: 0.7406 - val_acc: 1.0000\n",
      "Epoch 991/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8618 - acc: 1.0000 - val_loss: 0.7405 - val_acc: 1.0000\n",
      "Epoch 992/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9238 - acc: 0.9524 - val_loss: 0.7410 - val_acc: 1.0000\n",
      "Epoch 993/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8758 - acc: 1.0000 - val_loss: 0.7417 - val_acc: 1.0000\n",
      "Epoch 994/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8130 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 1.0000\n",
      "Epoch 995/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8248 - acc: 1.0000 - val_loss: 0.7409 - val_acc: 1.0000\n",
      "Epoch 996/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9118 - acc: 0.9365 - val_loss: 0.7406 - val_acc: 1.0000\n",
      "Epoch 997/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8778 - acc: 0.9841 - val_loss: 0.7406 - val_acc: 1.0000\n",
      "Epoch 998/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8760 - acc: 0.9365 - val_loss: 0.7408 - val_acc: 1.0000\n",
      "Epoch 999/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8633 - acc: 0.9841 - val_loss: 0.7414 - val_acc: 1.0000\n",
      "Epoch 1000/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9108 - acc: 0.9524 - val_loss: 0.7415 - val_acc: 1.0000\n",
      "Epoch 1001/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8711 - acc: 0.9683 - val_loss: 0.7417 - val_acc: 1.0000\n",
      "Epoch 1002/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8676 - acc: 0.9841 - val_loss: 0.7418 - val_acc: 1.0000\n",
      "Epoch 1003/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8707 - acc: 0.9683 - val_loss: 0.7418 - val_acc: 1.0000\n",
      "Epoch 1004/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9131 - acc: 0.9683 - val_loss: 0.7421 - val_acc: 1.0000\n",
      "Epoch 1005/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8005 - acc: 1.0000 - val_loss: 0.7417 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01005: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 1006/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8135 - acc: 1.0000 - val_loss: 0.7412 - val_acc: 1.0000\n",
      "Epoch 1007/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8087 - acc: 0.9841 - val_loss: 0.7406 - val_acc: 1.0000\n",
      "Epoch 1008/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8464 - acc: 0.9683 - val_loss: 0.7402 - val_acc: 1.0000\n",
      "Epoch 1009/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8527 - acc: 0.9841 - val_loss: 0.7398 - val_acc: 1.0000\n",
      "Epoch 1010/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8506 - acc: 1.0000 - val_loss: 0.7395 - val_acc: 1.0000\n",
      "Epoch 1011/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8945 - acc: 0.9841 - val_loss: 0.7393 - val_acc: 1.0000\n",
      "Epoch 1012/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8300 - acc: 1.0000 - val_loss: 0.7389 - val_acc: 1.0000\n",
      "Epoch 1013/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9091 - acc: 0.9524 - val_loss: 0.7388 - val_acc: 1.0000\n",
      "Epoch 1014/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9103 - acc: 0.9365 - val_loss: 0.7388 - val_acc: 1.0000\n",
      "Epoch 1015/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8142 - acc: 1.0000 - val_loss: 0.7386 - val_acc: 1.0000\n",
      "Epoch 1016/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8475 - acc: 0.9841 - val_loss: 0.7383 - val_acc: 1.0000\n",
      "Epoch 1017/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8662 - acc: 0.9841 - val_loss: 0.7380 - val_acc: 1.0000\n",
      "Epoch 1018/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8543 - acc: 0.9683 - val_loss: 0.7379 - val_acc: 1.0000\n",
      "Epoch 1019/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8036 - acc: 1.0000 - val_loss: 0.7376 - val_acc: 1.0000\n",
      "Epoch 1020/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8218 - acc: 1.0000 - val_loss: 0.7373 - val_acc: 1.0000\n",
      "Epoch 1021/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8672 - acc: 0.9841 - val_loss: 0.7371 - val_acc: 1.0000\n",
      "Epoch 1022/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8485 - acc: 0.9841 - val_loss: 0.7370 - val_acc: 1.0000\n",
      "Epoch 1023/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8741 - acc: 0.9683 - val_loss: 0.7370 - val_acc: 1.0000\n",
      "Epoch 1024/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9279 - acc: 0.9206 - val_loss: 0.7371 - val_acc: 1.0000\n",
      "Epoch 1025/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9025 - acc: 0.9683 - val_loss: 0.7374 - val_acc: 1.0000\n",
      "Epoch 1026/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8152 - acc: 0.9841 - val_loss: 0.7373 - val_acc: 1.0000\n",
      "Epoch 1027/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8100 - acc: 1.0000 - val_loss: 0.7369 - val_acc: 1.0000\n",
      "Epoch 1028/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8134 - acc: 0.9841 - val_loss: 0.7366 - val_acc: 1.0000\n",
      "Epoch 1029/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8280 - acc: 1.0000 - val_loss: 0.7364 - val_acc: 1.0000\n",
      "Epoch 1030/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8517 - acc: 0.9841 - val_loss: 0.7362 - val_acc: 1.0000\n",
      "Epoch 1031/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8543 - acc: 0.9683 - val_loss: 0.7361 - val_acc: 1.0000\n",
      "Epoch 1032/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8054 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 1.0000\n",
      "Epoch 1033/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8234 - acc: 0.9841 - val_loss: 0.7356 - val_acc: 1.0000\n",
      "Epoch 1034/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8484 - acc: 0.9841 - val_loss: 0.7354 - val_acc: 1.0000\n",
      "Epoch 1035/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8246 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 1.0000\n",
      "Epoch 1036/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8746 - acc: 0.9524 - val_loss: 0.7352 - val_acc: 1.0000\n",
      "Epoch 1037/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8829 - acc: 0.9841 - val_loss: 0.7352 - val_acc: 1.0000\n",
      "Epoch 1038/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8917 - acc: 0.9683 - val_loss: 0.7353 - val_acc: 1.0000\n",
      "Epoch 1039/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8423 - acc: 0.9841 - val_loss: 0.7352 - val_acc: 1.0000\n",
      "Epoch 1040/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8111 - acc: 1.0000 - val_loss: 0.7350 - val_acc: 1.0000\n",
      "Epoch 1041/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8422 - acc: 0.9841 - val_loss: 0.7347 - val_acc: 1.0000\n",
      "Epoch 1042/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7978 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 1.0000\n",
      "Epoch 1043/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8948 - acc: 0.9365 - val_loss: 0.7348 - val_acc: 1.0000\n",
      "Epoch 1044/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8438 - acc: 0.9841 - val_loss: 0.7350 - val_acc: 1.0000\n",
      "Epoch 1045/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8375 - acc: 0.9841 - val_loss: 0.7350 - val_acc: 1.0000\n",
      "Epoch 1046/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7964 - acc: 1.0000 - val_loss: 0.7347 - val_acc: 1.0000\n",
      "Epoch 1047/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8305 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 1.0000\n",
      "Epoch 1048/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8692 - acc: 0.9524 - val_loss: 0.7342 - val_acc: 1.0000\n",
      "Epoch 1049/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8593 - acc: 0.9841 - val_loss: 0.7343 - val_acc: 1.0000\n",
      "Epoch 1050/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8521 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 1.0000\n",
      "Epoch 1051/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8488 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 1.0000\n",
      "Epoch 1052/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8395 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 1.0000\n",
      "Epoch 1053/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8359 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 1.0000\n",
      "Epoch 1054/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8385 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 1.0000\n",
      "Epoch 1055/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8495 - acc: 0.9841 - val_loss: 0.7345 - val_acc: 1.0000\n",
      "Epoch 1056/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8736 - acc: 0.9683 - val_loss: 0.7343 - val_acc: 1.0000\n",
      "Epoch 1057/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8401 - acc: 0.9841 - val_loss: 0.7344 - val_acc: 1.0000\n",
      "Epoch 1058/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8192 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 1.0000\n",
      "Epoch 1059/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8351 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 1.0000\n",
      "Epoch 1060/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8768 - acc: 0.9524 - val_loss: 0.7338 - val_acc: 1.0000\n",
      "Epoch 1061/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8949 - acc: 0.9841 - val_loss: 0.7340 - val_acc: 1.0000\n",
      "Epoch 1062/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8486 - acc: 0.9841 - val_loss: 0.7341 - val_acc: 1.0000\n",
      "Epoch 1063/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9008 - acc: 0.9524 - val_loss: 0.7343 - val_acc: 1.0000\n",
      "Epoch 1064/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8732 - acc: 0.9524 - val_loss: 0.7346 - val_acc: 1.0000\n",
      "Epoch 1065/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8431 - acc: 0.9683 - val_loss: 0.7345 - val_acc: 1.0000\n",
      "Epoch 1066/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9002 - acc: 0.9841 - val_loss: 0.7346 - val_acc: 1.0000\n",
      "Epoch 1067/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8548 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 1.0000\n",
      "Epoch 1068/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8256 - acc: 0.9841 - val_loss: 0.7344 - val_acc: 1.0000\n",
      "Epoch 1069/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8435 - acc: 0.9841 - val_loss: 0.7343 - val_acc: 1.0000\n",
      "Epoch 1070/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8043 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 1.0000\n",
      "Epoch 1071/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8278 - acc: 0.9841 - val_loss: 0.7337 - val_acc: 1.0000\n",
      "Epoch 1072/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8596 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 1.0000\n",
      "Epoch 1073/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8227 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 1.0000\n",
      "Epoch 1074/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8372 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 1.0000\n",
      "Epoch 1075/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7754 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 1.0000\n",
      "Epoch 1076/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8546 - acc: 0.9683 - val_loss: 0.7330 - val_acc: 1.0000\n",
      "Epoch 1077/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8839 - acc: 0.9524 - val_loss: 0.7330 - val_acc: 1.0000\n",
      "Epoch 1078/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8189 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 1.0000\n",
      "Epoch 1079/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8508 - acc: 0.9841 - val_loss: 0.7329 - val_acc: 1.0000\n",
      "Epoch 1080/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8690 - acc: 0.9683 - val_loss: 0.7331 - val_acc: 1.0000\n",
      "Epoch 1081/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8980 - acc: 0.9683 - val_loss: 0.7332 - val_acc: 1.0000\n",
      "Epoch 1082/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8056 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 1.0000\n",
      "Epoch 1083/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8913 - acc: 0.9683 - val_loss: 0.7332 - val_acc: 1.0000\n",
      "Epoch 1084/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8934 - acc: 0.9683 - val_loss: 0.7333 - val_acc: 1.0000\n",
      "Epoch 1085/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8082 - acc: 0.9841 - val_loss: 0.7332 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1086/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8323 - acc: 0.9683 - val_loss: 0.7330 - val_acc: 1.0000\n",
      "Epoch 1087/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8439 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 1.0000\n",
      "Epoch 1088/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7956 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 1.0000\n",
      "Epoch 1089/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8477 - acc: 0.9841 - val_loss: 0.7325 - val_acc: 1.0000\n",
      "Epoch 1090/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8369 - acc: 0.9841 - val_loss: 0.7325 - val_acc: 1.0000\n",
      "Epoch 1091/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7953 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 1.0000\n",
      "Epoch 1092/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8733 - acc: 0.9841 - val_loss: 0.7322 - val_acc: 1.0000\n",
      "Epoch 1093/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8559 - acc: 0.9683 - val_loss: 0.7322 - val_acc: 1.0000\n",
      "Epoch 1094/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8678 - acc: 0.9841 - val_loss: 0.7323 - val_acc: 1.0000\n",
      "Epoch 1095/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8240 - acc: 0.9683 - val_loss: 0.7323 - val_acc: 1.0000\n",
      "Epoch 1096/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8317 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 1.0000\n",
      "Epoch 1097/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8183 - acc: 0.9841 - val_loss: 0.7325 - val_acc: 1.0000\n",
      "Epoch 1098/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8674 - acc: 0.9841 - val_loss: 0.7324 - val_acc: 1.0000\n",
      "Epoch 1099/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8052 - acc: 0.9841 - val_loss: 0.7325 - val_acc: 1.0000\n",
      "Epoch 1100/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8272 - acc: 0.9683 - val_loss: 0.7324 - val_acc: 1.0000\n",
      "Epoch 1101/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8468 - acc: 0.9683 - val_loss: 0.7324 - val_acc: 1.0000\n",
      "Epoch 1102/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8001 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1103/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8018 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 1.0000\n",
      "Epoch 1104/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8302 - acc: 1.0000 - val_loss: 0.7317 - val_acc: 1.0000\n",
      "Epoch 1105/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8573 - acc: 0.9841 - val_loss: 0.7316 - val_acc: 1.0000\n",
      "Epoch 1106/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8400 - acc: 1.0000 - val_loss: 0.7317 - val_acc: 1.0000\n",
      "Epoch 1107/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8578 - acc: 0.9841 - val_loss: 0.7319 - val_acc: 1.0000\n",
      "Epoch 1108/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8315 - acc: 0.9841 - val_loss: 0.7318 - val_acc: 1.0000\n",
      "Epoch 1109/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8753 - acc: 0.9683 - val_loss: 0.7318 - val_acc: 1.0000\n",
      "Epoch 1110/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8444 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 1.0000\n",
      "Epoch 1111/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8553 - acc: 0.9841 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1112/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8808 - acc: 0.9524 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1113/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8766 - acc: 0.9524 - val_loss: 0.7320 - val_acc: 1.0000\n",
      "Epoch 1114/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8363 - acc: 0.9841 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1115/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9067 - acc: 0.9365 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1116/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8131 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1117/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8551 - acc: 0.9841 - val_loss: 0.7320 - val_acc: 1.0000\n",
      "Epoch 1118/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8451 - acc: 0.9841 - val_loss: 0.7319 - val_acc: 1.0000\n",
      "Epoch 1119/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8836 - acc: 0.9524 - val_loss: 0.7322 - val_acc: 1.0000\n",
      "Epoch 1120/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8441 - acc: 0.9841 - val_loss: 0.7323 - val_acc: 1.0000\n",
      "Epoch 1121/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8633 - acc: 0.9841 - val_loss: 0.7323 - val_acc: 1.0000\n",
      "Epoch 1122/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8202 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 1.0000\n",
      "Epoch 1123/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8125 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 1.0000\n",
      "Epoch 1124/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8235 - acc: 1.0000 - val_loss: 0.7318 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01124: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 1125/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8359 - acc: 1.0000 - val_loss: 0.7317 - val_acc: 1.0000\n",
      "Epoch 1126/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8698 - acc: 0.9841 - val_loss: 0.7315 - val_acc: 1.0000\n",
      "Epoch 1127/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8514 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 1.0000\n",
      "Epoch 1128/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8662 - acc: 0.9524 - val_loss: 0.7314 - val_acc: 1.0000\n",
      "Epoch 1129/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9321 - acc: 0.9524 - val_loss: 0.7314 - val_acc: 1.0000\n",
      "Epoch 1130/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8789 - acc: 0.9841 - val_loss: 0.7315 - val_acc: 1.0000\n",
      "Epoch 1131/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8170 - acc: 0.9841 - val_loss: 0.7315 - val_acc: 1.0000\n",
      "Epoch 1132/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8621 - acc: 0.9683 - val_loss: 0.7315 - val_acc: 1.0000\n",
      "Epoch 1133/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8413 - acc: 0.9683 - val_loss: 0.7314 - val_acc: 1.0000\n",
      "Epoch 1134/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8176 - acc: 1.0000 - val_loss: 0.7312 - val_acc: 1.0000\n",
      "Epoch 1135/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8168 - acc: 0.9841 - val_loss: 0.7311 - val_acc: 1.0000\n",
      "Epoch 1136/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8076 - acc: 1.0000 - val_loss: 0.7310 - val_acc: 1.0000\n",
      "Epoch 1137/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7931 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 1.0000\n",
      "Epoch 1138/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7876 - acc: 1.0000 - val_loss: 0.7305 - val_acc: 1.0000\n",
      "Epoch 1139/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8628 - acc: 0.9683 - val_loss: 0.7304 - val_acc: 1.0000\n",
      "Epoch 1140/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8346 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 1.0000\n",
      "Epoch 1141/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8145 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 1.0000\n",
      "Epoch 1142/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8288 - acc: 0.9841 - val_loss: 0.7303 - val_acc: 1.0000\n",
      "Epoch 1143/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8089 - acc: 1.0000 - val_loss: 0.7302 - val_acc: 1.0000\n",
      "Epoch 1144/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8072 - acc: 1.0000 - val_loss: 0.7300 - val_acc: 1.0000\n",
      "Epoch 1145/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8379 - acc: 0.9841 - val_loss: 0.7300 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1146/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8469 - acc: 0.9841 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1147/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8302 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1148/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8296 - acc: 0.9524 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1149/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8782 - acc: 0.9683 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 1150/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8513 - acc: 0.9841 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1151/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8006 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 1152/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7987 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 1153/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8296 - acc: 0.9841 - val_loss: 0.7297 - val_acc: 1.0000\n",
      "Epoch 1154/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8264 - acc: 0.9841 - val_loss: 0.7296 - val_acc: 1.0000\n",
      "Epoch 1155/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8567 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 1.0000\n",
      "Epoch 1156/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8336 - acc: 0.9841 - val_loss: 0.7296 - val_acc: 1.0000\n",
      "Epoch 1157/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8929 - acc: 0.9683 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 1158/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8470 - acc: 0.9841 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1159/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8467 - acc: 0.9683 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1160/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8712 - acc: 0.9683 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1161/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8612 - acc: 0.9683 - val_loss: 0.7300 - val_acc: 1.0000\n",
      "Epoch 1162/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7890 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1163/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8966 - acc: 0.9683 - val_loss: 0.7299 - val_acc: 1.0000\n",
      "Epoch 1164/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7987 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 1165/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8200 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 1.0000\n",
      "Epoch 1166/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8102 - acc: 0.9841 - val_loss: 0.7296 - val_acc: 1.0000\n",
      "Epoch 1167/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8368 - acc: 0.9683 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1168/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8564 - acc: 0.9841 - val_loss: 0.7294 - val_acc: 1.0000\n",
      "Epoch 1169/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8616 - acc: 0.9841 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1170/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8403 - acc: 0.9841 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1171/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8605 - acc: 0.9683 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1172/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8799 - acc: 0.9683 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1173/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8518 - acc: 0.9841 - val_loss: 0.7296 - val_acc: 1.0000\n",
      "Epoch 1174/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8371 - acc: 0.9841 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1175/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9095 - acc: 0.9683 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1176/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8638 - acc: 0.9841 - val_loss: 0.7296 - val_acc: 1.0000\n",
      "Epoch 1177/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8124 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1178/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9313 - acc: 0.9206 - val_loss: 0.7295 - val_acc: 1.0000\n",
      "Epoch 1179/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8296 - acc: 0.9683 - val_loss: 0.7294 - val_acc: 1.0000\n",
      "Epoch 1180/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7997 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 1.0000\n",
      "Epoch 1181/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8350 - acc: 0.9841 - val_loss: 0.7292 - val_acc: 1.0000\n",
      "Epoch 1182/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8286 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 1.0000\n",
      "Epoch 1183/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8335 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 1.0000\n",
      "Epoch 1184/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8810 - acc: 0.9683 - val_loss: 0.7290 - val_acc: 1.0000\n",
      "Epoch 1185/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8183 - acc: 1.0000 - val_loss: 0.7290 - val_acc: 1.0000\n",
      "Epoch 1186/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8166 - acc: 1.0000 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1187/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8809 - acc: 0.9683 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1188/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8504 - acc: 0.9683 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1189/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8289 - acc: 0.9841 - val_loss: 0.7290 - val_acc: 1.0000\n",
      "Epoch 1190/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8405 - acc: 0.9841 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1191/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8780 - acc: 1.0000 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1192/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8200 - acc: 0.9841 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1193/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8280 - acc: 0.9841 - val_loss: 0.7288 - val_acc: 1.0000\n",
      "Epoch 1194/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8046 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 1.0000\n",
      "Epoch 1195/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8740 - acc: 0.9683 - val_loss: 0.7287 - val_acc: 1.0000\n",
      "Epoch 1196/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8691 - acc: 0.9683 - val_loss: 0.7288 - val_acc: 1.0000\n",
      "Epoch 1197/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8999 - acc: 0.9683 - val_loss: 0.7288 - val_acc: 1.0000\n",
      "Epoch 1198/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8876 - acc: 0.9683 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1199/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8131 - acc: 0.9683 - val_loss: 0.7288 - val_acc: 1.0000\n",
      "Epoch 1200/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8868 - acc: 0.9683 - val_loss: 0.7289 - val_acc: 1.0000\n",
      "Epoch 1201/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7643 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 1.0000\n",
      "Epoch 1202/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8395 - acc: 0.9683 - val_loss: 0.7287 - val_acc: 1.0000\n",
      "Epoch 1203/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8345 - acc: 0.9841 - val_loss: 0.7286 - val_acc: 1.0000\n",
      "Epoch 1204/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8120 - acc: 0.9841 - val_loss: 0.7286 - val_acc: 1.0000\n",
      "Epoch 1205/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8720 - acc: 0.9841 - val_loss: 0.7285 - val_acc: 1.0000\n",
      "Epoch 1206/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8594 - acc: 0.9683 - val_loss: 0.7285 - val_acc: 1.0000\n",
      "Epoch 1207/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8998 - acc: 0.9683 - val_loss: 0.7285 - val_acc: 1.0000\n",
      "Epoch 1208/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8437 - acc: 0.9841 - val_loss: 0.7286 - val_acc: 1.0000\n",
      "Epoch 1209/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8432 - acc: 0.9683 - val_loss: 0.7286 - val_acc: 1.0000\n",
      "Epoch 1210/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8076 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 1.0000\n",
      "Epoch 1211/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8284 - acc: 0.9841 - val_loss: 0.7284 - val_acc: 1.0000\n",
      "Epoch 1212/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8250 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 1.0000\n",
      "Epoch 1213/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8183 - acc: 0.9841 - val_loss: 0.7282 - val_acc: 1.0000\n",
      "Epoch 1214/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8120 - acc: 1.0000 - val_loss: 0.7281 - val_acc: 1.0000\n",
      "Epoch 1215/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8739 - acc: 0.9683 - val_loss: 0.7281 - val_acc: 1.0000\n",
      "Epoch 1216/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8230 - acc: 0.9841 - val_loss: 0.7281 - val_acc: 1.0000\n",
      "Epoch 1217/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7853 - acc: 0.9841 - val_loss: 0.7279 - val_acc: 1.0000\n",
      "Epoch 1218/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8735 - acc: 0.9683 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1219/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8587 - acc: 1.0000 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1220/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8487 - acc: 0.9841 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1221/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8848 - acc: 0.9365 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1222/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8248 - acc: 0.9683 - val_loss: 0.7279 - val_acc: 1.0000\n",
      "Epoch 1223/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9117 - acc: 0.9524 - val_loss: 0.7280 - val_acc: 1.0000\n",
      "Epoch 1224/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8318 - acc: 0.9683 - val_loss: 0.7281 - val_acc: 1.0000\n",
      "Epoch 1225/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7925 - acc: 1.0000 - val_loss: 0.7281 - val_acc: 1.0000\n",
      "Epoch 1226/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8322 - acc: 0.9841 - val_loss: 0.7280 - val_acc: 1.0000\n",
      "Epoch 1227/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8182 - acc: 0.9683 - val_loss: 0.7280 - val_acc: 1.0000\n",
      "Epoch 1228/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8157 - acc: 0.9683 - val_loss: 0.7280 - val_acc: 1.0000\n",
      "Epoch 1229/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8643 - acc: 0.9683 - val_loss: 0.7280 - val_acc: 1.0000\n",
      "Epoch 1230/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8111 - acc: 0.9841 - val_loss: 0.7280 - val_acc: 1.0000\n",
      "Epoch 1231/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8347 - acc: 1.0000 - val_loss: 0.7279 - val_acc: 1.0000\n",
      "Epoch 1232/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8406 - acc: 0.9683 - val_loss: 0.7279 - val_acc: 1.0000\n",
      "Epoch 1233/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8343 - acc: 0.9683 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1234/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8923 - acc: 0.9683 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1235/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8467 - acc: 1.0000 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1236/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8498 - acc: 0.9841 - val_loss: 0.7279 - val_acc: 1.0000\n",
      "Epoch 1237/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7983 - acc: 1.0000 - val_loss: 0.7278 - val_acc: 1.0000\n",
      "Epoch 1238/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8832 - acc: 0.9683 - val_loss: 0.7277 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01238: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 1239/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8402 - acc: 0.9841 - val_loss: 0.7277 - val_acc: 1.0000\n",
      "Epoch 1240/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7998 - acc: 1.0000 - val_loss: 0.7276 - val_acc: 1.0000\n",
      "Epoch 1241/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8613 - acc: 0.9841 - val_loss: 0.7276 - val_acc: 1.0000\n",
      "Epoch 1242/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8603 - acc: 0.9841 - val_loss: 0.7276 - val_acc: 1.0000\n",
      "Epoch 1243/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7953 - acc: 0.9841 - val_loss: 0.7275 - val_acc: 1.0000\n",
      "Epoch 1244/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8112 - acc: 1.0000 - val_loss: 0.7274 - val_acc: 1.0000\n",
      "Epoch 1245/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8808 - acc: 0.9841 - val_loss: 0.7274 - val_acc: 1.0000\n",
      "Epoch 1246/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8727 - acc: 0.9683 - val_loss: 0.7274 - val_acc: 1.0000\n",
      "Epoch 1247/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8310 - acc: 1.0000 - val_loss: 0.7274 - val_acc: 1.0000\n",
      "Epoch 1248/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8090 - acc: 0.9841 - val_loss: 0.7273 - val_acc: 1.0000\n",
      "Epoch 1249/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8332 - acc: 1.0000 - val_loss: 0.7273 - val_acc: 1.0000\n",
      "Epoch 1250/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8872 - acc: 0.9683 - val_loss: 0.7272 - val_acc: 1.0000\n",
      "Epoch 1251/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8074 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 1.0000\n",
      "Epoch 1252/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8817 - acc: 0.9683 - val_loss: 0.7271 - val_acc: 1.0000\n",
      "Epoch 1253/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8219 - acc: 0.9841 - val_loss: 0.7271 - val_acc: 1.0000\n",
      "Epoch 1254/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8362 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 1.0000\n",
      "Epoch 1255/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8372 - acc: 0.9683 - val_loss: 0.7271 - val_acc: 1.0000\n",
      "Epoch 1256/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8176 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 1.0000\n",
      "Epoch 1257/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9038 - acc: 0.9683 - val_loss: 0.7270 - val_acc: 1.0000\n",
      "Epoch 1258/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8707 - acc: 0.9683 - val_loss: 0.7270 - val_acc: 1.0000\n",
      "Epoch 1259/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8311 - acc: 1.0000 - val_loss: 0.7270 - val_acc: 1.0000\n",
      "Epoch 1260/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7805 - acc: 0.9841 - val_loss: 0.7270 - val_acc: 1.0000\n",
      "Epoch 1261/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8056 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 1.0000\n",
      "Epoch 1262/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8133 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 1.0000\n",
      "Epoch 1263/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9075 - acc: 0.9683 - val_loss: 0.7269 - val_acc: 1.0000\n",
      "Epoch 1264/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8337 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 1.0000\n",
      "Epoch 1265/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8347 - acc: 0.9841 - val_loss: 0.7268 - val_acc: 1.0000\n",
      "Epoch 1266/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7942 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 1.0000\n",
      "Epoch 1267/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8008 - acc: 0.9683 - val_loss: 0.7267 - val_acc: 1.0000\n",
      "Epoch 1268/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8313 - acc: 1.0000 - val_loss: 0.7267 - val_acc: 1.0000\n",
      "Epoch 1269/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7982 - acc: 1.0000 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1270/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8662 - acc: 0.9841 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1271/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8730 - acc: 0.9683 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1272/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8680 - acc: 0.9683 - val_loss: 0.7267 - val_acc: 1.0000\n",
      "Epoch 1273/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7922 - acc: 0.9841 - val_loss: 0.7267 - val_acc: 1.0000\n",
      "Epoch 1274/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8908 - acc: 0.9524 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1275/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8390 - acc: 0.9683 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1276/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8813 - acc: 0.9524 - val_loss: 0.7267 - val_acc: 1.0000\n",
      "Epoch 1277/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8074 - acc: 0.9841 - val_loss: 0.7267 - val_acc: 1.0000\n",
      "Epoch 1278/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8393 - acc: 1.0000 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1279/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8187 - acc: 0.9841 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1280/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8669 - acc: 0.9683 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1281/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8422 - acc: 0.9841 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1282/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8347 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1283/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8187 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1284/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8440 - acc: 0.9841 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1285/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8371 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1286/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8154 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1287/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8684 - acc: 0.9683 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1288/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8698 - acc: 0.9683 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1289/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8389 - acc: 1.0000 - val_loss: 0.7266 - val_acc: 1.0000\n",
      "Epoch 1290/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8576 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1291/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7811 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 1.0000\n",
      "Epoch 1292/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8753 - acc: 0.9365 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1293/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8163 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1294/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8029 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1295/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8097 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1296/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8323 - acc: 0.9841 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1297/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9103 - acc: 0.9524 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1298/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8372 - acc: 0.9683 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1299/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7951 - acc: 0.9841 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1300/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9053 - acc: 0.9524 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1301/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9241 - acc: 0.9365 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1302/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8122 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1303/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8439 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1304/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9001 - acc: 0.9524 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1305/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8260 - acc: 0.9841 - val_loss: 0.7264 - val_acc: 1.0000\n",
      "Epoch 1306/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8407 - acc: 0.9683 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1307/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8700 - acc: 0.9841 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1308/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8622 - acc: 0.9683 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1309/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8810 - acc: 0.9683 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1310/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8776 - acc: 0.9683 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1311/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8214 - acc: 0.9841 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1312/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8301 - acc: 0.9841 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1313/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8412 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 1.0000\n",
      "Epoch 1314/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8173 - acc: 0.9841 - val_loss: 0.7262 - val_acc: 1.0000\n",
      "Epoch 1315/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8217 - acc: 0.9683 - val_loss: 0.7262 - val_acc: 1.0000\n",
      "Epoch 1316/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9155 - acc: 0.9683 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1317/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7993 - acc: 0.9841 - val_loss: 0.7263 - val_acc: 1.0000\n",
      "Epoch 1318/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8129 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 1.0000\n",
      "Epoch 1319/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8022 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1320/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8499 - acc: 0.9841 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1321/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8550 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1322/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8040 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1323/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8351 - acc: 0.9841 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1324/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8039 - acc: 0.9683 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1325/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8920 - acc: 0.9683 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1326/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7958 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1327/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9199 - acc: 0.9365 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1328/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8411 - acc: 0.9683 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1329/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8548 - acc: 0.9841 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1330/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8465 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1331/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8152 - acc: 0.9841 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1332/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8216 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1333/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9260 - acc: 0.9683 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1334/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8251 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1335/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8384 - acc: 0.9683 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1336/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8706 - acc: 0.9683 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1337/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8588 - acc: 0.9524 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1338/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8258 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1339/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8405 - acc: 0.9683 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 1340/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8295 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1341/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8276 - acc: 0.9683 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1342/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8263 - acc: 0.9841 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1343/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8569 - acc: 0.9683 - val_loss: 0.7260 - val_acc: 1.0000\n",
      "Epoch 1344/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8566 - acc: 1.0000 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "Epoch 1345/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8307 - acc: 0.9841 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "Epoch 1346/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8685 - acc: 0.9841 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "Epoch 1347/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8719 - acc: 0.9841 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01347: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 1348/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8335 - acc: 0.9841 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "Epoch 1349/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9298 - acc: 0.9365 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "Epoch 1350/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7796 - acc: 1.0000 - val_loss: 0.7259 - val_acc: 1.0000\n",
      "Epoch 1351/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8249 - acc: 0.9841 - val_loss: 0.7258 - val_acc: 1.0000\n",
      "Epoch 1352/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7905 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 1.0000\n",
      "Epoch 1353/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7829 - acc: 1.0000 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1354/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8532 - acc: 0.9841 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1355/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8646 - acc: 0.9841 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1356/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8383 - acc: 0.9841 - val_loss: 0.7256 - val_acc: 1.0000\n",
      "Epoch 1357/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9128 - acc: 0.9683 - val_loss: 0.7256 - val_acc: 1.0000\n",
      "Epoch 1358/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8200 - acc: 0.9841 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1359/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8723 - acc: 1.0000 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1360/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8066 - acc: 1.0000 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1361/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9326 - acc: 0.9524 - val_loss: 0.7257 - val_acc: 1.0000\n",
      "Epoch 1362/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8396 - acc: 0.9841 - val_loss: 0.7256 - val_acc: 1.0000\n",
      "Epoch 1363/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8141 - acc: 0.9841 - val_loss: 0.7256 - val_acc: 1.0000\n",
      "Epoch 1364/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8194 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 1.0000\n",
      "Epoch 1365/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8045 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 1.0000\n",
      "Epoch 1366/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8365 - acc: 0.9841 - val_loss: 0.7255 - val_acc: 1.0000\n",
      "Epoch 1367/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8369 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 1.0000\n",
      "Epoch 1368/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8429 - acc: 0.9683 - val_loss: 0.7255 - val_acc: 1.0000\n",
      "Epoch 1369/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8301 - acc: 0.9841 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1370/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8447 - acc: 0.9841 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1371/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8899 - acc: 0.9683 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1372/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8400 - acc: 0.9841 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1373/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8011 - acc: 1.0000 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1374/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8128 - acc: 1.0000 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1375/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8394 - acc: 0.9683 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1376/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8216 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1377/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8206 - acc: 0.9841 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1378/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8210 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1379/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8841 - acc: 0.9683 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1380/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8386 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1381/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8296 - acc: 0.9683 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1382/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8142 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1383/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8212 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1384/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8380 - acc: 0.9841 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1385/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9186 - acc: 0.9683 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1386/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8313 - acc: 0.9841 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1387/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8599 - acc: 0.9683 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1388/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8616 - acc: 0.9841 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1389/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8660 - acc: 0.9683 - val_loss: 0.7254 - val_acc: 1.0000\n",
      "Epoch 1390/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8142 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1391/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8094 - acc: 0.9841 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1392/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8189 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1393/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7802 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 1.0000\n",
      "Epoch 1394/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8377 - acc: 0.9683 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1395/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8272 - acc: 0.9841 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1396/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8747 - acc: 0.9683 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1397/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8147 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1398/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8326 - acc: 0.9683 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1399/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8186 - acc: 0.9841 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1400/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8946 - acc: 0.9524 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1401/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8194 - acc: 0.9683 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1402/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9001 - acc: 0.9524 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1403/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8208 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1404/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7974 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1405/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8191 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 1.0000\n",
      "Epoch 1406/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8070 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1407/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8197 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1408/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8265 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1409/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8296 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1410/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8542 - acc: 0.9841 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1411/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8256 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1412/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8306 - acc: 0.9841 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1413/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8355 - acc: 0.9841 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1414/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8611 - acc: 0.9524 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1415/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8746 - acc: 0.9841 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1416/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8682 - acc: 0.9841 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1417/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8652 - acc: 0.9683 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1418/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8150 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1419/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8795 - acc: 0.9524 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1420/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8568 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1421/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8191 - acc: 0.9841 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1422/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8256 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1423/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9105 - acc: 0.9365 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1424/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8495 - acc: 0.9841 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1425/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8331 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1426/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8643 - acc: 0.9683 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1427/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8799 - acc: 0.9524 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "\n",
      "Epoch 01427: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "Epoch 1428/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8186 - acc: 0.9841 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1429/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8386 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1430/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8634 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 1.0000\n",
      "Epoch 1431/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9115 - acc: 0.9841 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1432/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8842 - acc: 0.9524 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1433/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8499 - acc: 0.9683 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1434/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8300 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1435/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7703 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1436/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8276 - acc: 0.9841 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1437/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8104 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 1.0000\n",
      "Epoch 1438/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8594 - acc: 0.9841 - val_loss: 0.7249 - val_acc: 1.0000\n",
      "Epoch 1439/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7961 - acc: 1.0000 - val_loss: 0.7249 - val_acc: 1.0000\n",
      "Epoch 1440/2000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7937 - acc: 1.0000 - val_loss: 0.7249 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "neu_wo = Sequential()\n",
    "neu_wo.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "                               input_shape=(scaled_train_data_words.shape[1],)))\n",
    "neu_wo.add(layers.Dropout(0.3))\n",
    "neu_wo.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu_wo.add(layers.Dropout(0.3))\n",
    "neu_wo.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu_wo.add(layers.Dropout(0.3))\n",
    "neu_wo.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "\n",
    "neu_wo.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "neu_wo.summary()\n",
    "history = neu_wo.fit(X_scaled_train_data_words, y_train,\n",
    "                    validation_data=(X_scaled_val_data_words, y_val),\n",
    "                    epochs=2000,\n",
    "                    batch_size=class_size,\n",
    "                    callbacks=callbacks_list_neu_words,\n",
    "                    verbose= 1\n",
    "                   )\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "print(max(val_acc))\n",
    "l_model = load_model('my_model_neu_words.h5')\n",
    "yhat = l_model.predict( scaled_test_data_words)\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print('my_model_neu_words Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "word_input_tensor = Input(shape=(scaled_train_data_words.shape[1],) , name='words')\n",
    "ngram_input_tensor = Input(shape=(scaled_train_data_ngrams.shape[1],) , name='n_grams')\n",
    "\n",
    "neu0 = Sequential()\n",
    "neu0.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "                               input_shape=(scaled_train_data_ngrams.shape[1],)))\n",
    "neu0.add(layers.Dropout(0.3))\n",
    "neu0.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu0.add(layers.Dropout(0.3))\n",
    "neu0.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu0.add(layers.Dropout(0.3))\n",
    "\n",
    "neu1 = Sequential()\n",
    "neu1.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "                               input_shape=(scaled_train_data_words.shape[1],)))\n",
    "neu1.add(layers.Dropout(0.3))\n",
    "neu1.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu1.add(layers.Dropout(0.3))\n",
    "neu1.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "neu1.add(layers.Dropout(0.3))\n",
    "\n",
    "output_tensor_0 = neu0(ngram_input_tensor)\n",
    "output_tensor_1 = neu1(word_input_tensor)\n",
    "\n",
    "\n",
    "# conv_input_tensor = Input(shape=(maxlen,) , name='convnets')\n",
    "\n",
    "# conv_1d_s3_model = Sequential()\n",
    "# conv_1d_s3_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "# conv_1d_s3_model.add(layers.Dropout(0.2))\n",
    "# conv_1d_s3_model.add(layers.SeparableConv1D(32, 3, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "# conv_1d_s3_model.add(layers.BatchNormalization())\n",
    "# conv_1d_s3_model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "# conv_output_tensor_0 = conv_1d_s3_model(conv_input_tensor)\n",
    "\n",
    "\n",
    "# conv_1d_s1_model = Sequential()\n",
    "# conv_1d_s1_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "# conv_1d_s1_model.add(layers.Dropout(0.2))\n",
    "# conv_1d_s1_model.add(layers.SeparableConv1D(32, 1, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "# conv_1d_s1_model.add(layers.BatchNormalization())\n",
    "# conv_1d_s1_model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "# conv_output_tensor_1 = conv_1d_s1_model(conv_input_tensor)\n",
    "\n",
    "# conv_1d_complex_model = Sequential()\n",
    "# conv_1d_complex_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "# conv_1d_complex_model.add(layers.Dropout(0.2))\n",
    "# conv_1d_complex_model.add(layers.SeparableConv1D(32, 2, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "# conv_1d_complex_model.add(layers.BatchNormalization())\n",
    "# conv_1d_complex_model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "# conv_output_tensor_2 = conv_1d_complex_model(conv_input_tensor)\n",
    "\n",
    "\n",
    "\n",
    "concatenated = layers.concatenate([output_tensor_0,\n",
    "                                   output_tensor_1,\n",
    "#                                    conv_output_tensor_0,\n",
    "#                                    conv_output_tensor_1,\n",
    "#                                    conv_output_tensor_2,\n",
    "                                  ], axis=-1)\n",
    "\n",
    "concatenated = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(concatenated)\n",
    "concatenated = layers.Dropout(0.3)(concatenated)\n",
    "concatenated = layers.Dense(len(set(train_labels)), activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([ngram_input_tensor, word_input_tensor,\n",
    "#                conv_input_tensor\n",
    "              ], concatenated)\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "print(X_scaled_train_data_ngrams.shape, X_scaled_train_data_words.shape, y_train.shape) \n",
    "history = model.fit([X_scaled_train_data_ngrams, X_scaled_train_data_words, \n",
    "#                      X_train\n",
    "                    ], y_train,\n",
    "                    validation_data=([X_scaled_val_data_ngrams, X_scaled_val_data_words,\n",
    "#                                       X_val\n",
    "                                     ], y_val),\n",
    "                    epochs=2000,\n",
    "                    batch_size=class_size,\n",
    "                    callbacks=callbacks_list_neu,\n",
    "                    verbose= 1\n",
    "                   )\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "print(max(val_acc))\n",
    "l_model = load_model('my_model_neu.h5')\n",
    "yhat = l_model.predict([scaled_test_data_ngrams, scaled_test_data_words])\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print('my_model_neu Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "convnet_input_tensor = Input(shape=(maxlen,) , name='convnet_words')\n",
    "\n",
    "conv_1d_s3_model = Sequential()\n",
    "conv_1d_s3_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "conv_1d_s3_model.add(layers.Dropout(0.3))\n",
    "conv_1d_s3_model.add(layers.SeparableConv1D(64, 3, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "conv_1d_s3_model.add(layers.BatchNormalization())\n",
    "conv_1d_s3_model.add(layers.GlobalMaxPooling1D())\n",
    "# conv_1d_s3_model.add(layers.BatchNormalization())\n",
    "# conv_1d_s3_model.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "# conv_1d_s3_model.layers[0].set_weights([w2d.word_embedding])\n",
    "# conv_1d_s3_model.layers[0].trainable = False\n",
    "conv_output_tensor_0 = conv_1d_s3_model(convnet_input_tensor)\n",
    "\n",
    "\n",
    "conv_1d_s1_model = Sequential()\n",
    "conv_1d_s1_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "conv_1d_s1_model.add(layers.Dropout(0.3))\n",
    "conv_1d_s1_model.add(layers.SeparableConv1D(64, 1, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "conv_1d_s1_model.add(layers.BatchNormalization())\n",
    "# conv_1d_s1_model.add(layers.MaxPooling1D(2))\n",
    "# conv_1d_s1_model.add(layers.SeparableConv1D(32, 3, activation='relu'))\n",
    "conv_1d_s1_model.add(layers.GlobalMaxPooling1D())\n",
    "# conv_1d_s1_model.add(layers.BatchNormalization())\n",
    "# conv_1d_s1_model.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "# conv_1d_s1_model.layers[0].set_weights([w2d.word_embedding])\n",
    "# conv_1d_s1_model.layers[0].trainable = False\n",
    "conv_output_tensor_1 = conv_1d_s1_model(convnet_input_tensor)\n",
    "\n",
    "conv_1d_complex_model = Sequential()\n",
    "conv_1d_complex_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "conv_1d_complex_model.add(layers.Dropout(0.3))\n",
    "conv_1d_complex_model.add(layers.SeparableConv1D(64, 2, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)))\n",
    "conv_1d_complex_model.add(layers.BatchNormalization())\n",
    "# conv_1d_complex_model.add(layers.SeparableConv1D(64, 3, activation='relu'))\n",
    "# conv_1d_complex_model.add(layers.MaxPooling1D(2))\n",
    "# conv_1d_complex_model.add(layers.SeparableConv1D(64, 3, activation='relu'))\n",
    "# conv_1d_complex_model.add(layers.SeparableConv1D(128, 3, activation='relu'))\n",
    "# conv_1d_complex_model.add(layers.MaxPooling1D(2))\n",
    "# conv_1d_complex_model.add(layers.SeparableConv1D(64, 3, activation='relu'))\n",
    "# conv_1d_complex_model.add(layers.SeparableConv1D(128, 3, activation='relu'))\n",
    "conv_1d_complex_model.add(layers.GlobalMaxPooling1D())\n",
    "# conv_1d_complex_model.add(layers.BatchNormalization())\n",
    "# conv_1d_s1_model.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "# conv_1d_complex_model.layers[0].set_weights([w2d.word_embedding])\n",
    "# conv_1d_complex_model.layers[0].trainable = False\n",
    "conv_output_tensor_2 = conv_1d_complex_model(convnet_input_tensor)\n",
    "\n",
    "# x = layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen)(word_input_tensor)\n",
    "# x = layers.Conv1D(128, 5, activation='relu', padding='same', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(x)\n",
    "# x = layers.Dropout(0.2)(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# y = layers.Conv1D(128, 10, activation='relu', padding='same')(x)\n",
    "# added = layers.add([y, x])\n",
    "# added = layers.GlobalMaxPooling1D()(added)\n",
    "\n",
    "concatenated = layers.concatenate([conv_output_tensor_0,\n",
    "                                   conv_output_tensor_1,\n",
    "                                   conv_output_tensor_2,\n",
    "#                                    ,added\n",
    "                                  ], axis=-1)\n",
    "concatenated = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(concatenated)\n",
    "concatenated = layers.Dropout(0.3)(concatenated)\n",
    "concatenated = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(concatenated)\n",
    "concatenated = layers.Dropout(0.3)(concatenated)\n",
    "answer = layers.Dense(len(set(train_labels)), activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(convnet_input_tensor, answer)\n",
    "model.summary()\n",
    "\n",
    "# model.layers[0].set_weights([w2d.word_embedding])\n",
    "# model.layers[0].trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=2000,\n",
    "                    batch_size=class_size,\n",
    "                    callbacks=callbacks_list_convnet,\n",
    "                    verbose= 2\n",
    "                   )\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "l_model = load_model('my_model_convnet.h5')\n",
    "yhat = l_model.predict(X_test)\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print('my_model_convnet Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "print(max(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from numpy import dstack\n",
    "from keras.utils import plot_model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(model_names_list):\n",
    "    all_models = list()\n",
    "    for model_name in model_names_list:\n",
    "        # define filename for this ensemble\n",
    "#         filename = 'models/model_' + str(i + 1) + '.h5'\n",
    "        filename = model_name + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "# define stacked model from multiple member input models\n",
    "def define_stacked_model(members):\n",
    "    # update all layers in all models to not be trainable\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            # make not trainable\n",
    "            layer.trainable = False\n",
    "            # rename to avoid 'unique layer name' issue\n",
    "            layer.name = 'ensemble_' + str(i + 1) + '_' + layer.name\n",
    "    # define multi-headed input\n",
    "    ensemble_visible = [model.input for model in members]\n",
    "#     print(ensemble_visible)\n",
    "#     ensemble_visible = [[ngram_input_tensor, word_input_tensor], convnet_input_tensor]\n",
    "    # concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "#     ensemble_outputs = [concatenated, answer]\n",
    "    merge = concatenate(ensemble_outputs)\n",
    "    hidden = layers.Dense(128, activation='relu')(merge)\n",
    "    hidden = layers.Dropout(0.3)(hidden)\n",
    "    output = layers.Dense(len(set(train_labels)), activation='softmax')(hidden)\n",
    "    model = Model(inputs=ensemble_visible, outputs=output)\n",
    "    # plot graph of ensemble\n",
    "#     plot_model(model, show_shapes=True, to_file='model_graph.png')\n",
    "    # compile\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=3e-4), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fit a stacked model\n",
    "def fit_stacked_model(model, inputX, inputy, valX, valy):\n",
    "    # prepare input data\n",
    "#     X = [inputX for _ in range(len(model.input))]\n",
    "    # encode output data\n",
    "#     inputy_enc = to_categorical(inputy)\n",
    "    # fit model\n",
    "    model.fit(inputX, inputy, validation_data=(valX, valy), batch_size=class_size,\n",
    "              callbacks=callbacks_list_stacked, epochs=500, verbose=1)\n",
    "    \n",
    "# make a prediction with a stacked model\n",
    "def predict_stacked_model(model, inputX):\n",
    "    # prepare input data\n",
    "#     X = [inputX for _ in range(len(model.input))]\n",
    "    # make prediction\n",
    "    return model.predict(inputX, verbose=0)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "members = load_all_models(['my_model_neu_ngrams', 'my_model_neu_words', 'my_model_convnet'])\n",
    "print('Loaded %d models' % len(members))\n",
    "# define ensemble model\n",
    "stacked_model = define_stacked_model(members)\n",
    "# fit stacked model on test dataset\n",
    "fit_stacked_model(stacked_model, [X_scaled_train_data_ngrams, X_scaled_train_data_words, X_train], y_train, [X_scaled_val_data_ngrams, X_scaled_val_data_words, X_val], y_val)\n",
    "final_model = load_model('my_model_neu_stacked.h5')\n",
    "# make predictions and evaluate\n",
    "yhat = predict_stacked_model(stacked_model, [scaled_test_data_ngrams, scaled_test_data_words, test_data])\n",
    "yhat = argmax(yhat, axis=1)\n",
    "acc = accuracy_score(test_labels, yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
