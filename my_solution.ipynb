{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Reading general data of the problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading general data of the problems, done!\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import json\n",
    "import os\n",
    "\n",
    "from MyUtils import clean_folder, read_files\n",
    "from Word2Dim import Word2Dim\n",
    "\n",
    "dataset_path = '.' + os.sep + 'pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23'\n",
    "outpath = '.' + os.sep + 'dev_out'\n",
    "\n",
    "clean_folder(outpath)\n",
    "\n",
    "infocollection = dataset_path + os.sep + 'collection-info.json'\n",
    "problems = []\n",
    "language = []\n",
    "with open(infocollection, 'r') as f:\n",
    "    for attrib in json.load(f):\n",
    "        problems.append(attrib['problem-name'])\n",
    "        language.append(attrib['language'])\n",
    "print('Reading general data of the problems, done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reading problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc count to process:  63\n",
      "Processing doc # 7\n",
      "Processing doc # 1\n",
      "Processing doc # 13\n",
      "Processing doc # 14\n",
      "Processing doc # 8\n",
      "Processing doc # 2\n",
      "Processing doc # 9\n",
      "Processing doc # 15\n",
      "Processing doc # 3\n",
      "Processing doc # 10\n",
      "Processing doc # 11\n",
      "Processing doc # 4\n",
      "Processing doc # 16\n",
      "Processing doc # 12\n",
      "Processing doc # 5\n",
      "Processing doc # 19\n",
      "Processing doc # 6\n",
      "Processing doc # 17\n",
      "Processing doc # 20\n",
      "Processing doc # 18\n",
      "Processing doc # 25\n",
      "Processing doc # 26\n",
      "Processing doc # 31\n",
      "Processing doc # 21\n",
      "Processing doc # 27\n",
      "Processing doc # 32\n",
      "Processing doc # 22\n",
      "Processing doc # 28\n",
      "Processing doc # 33\n",
      "Processing doc # 29\n",
      "Processing doc # 23\n",
      "Processing doc # 24\n",
      "Processing doc # 30\n",
      "Processing doc # 34\n",
      "Processing doc # 37\n",
      "Processing doc # 35\n",
      "Processing doc # 43\n",
      "Processing doc # 38\n",
      "Processing doc # 36\n",
      "Processing doc # 39\n",
      "Processing doc # 44\n",
      "Processing doc # 49\n",
      "Processing doc # 40\n",
      "Processing doc # 45\n",
      "Processing doc # 50\n",
      "Processing doc # 41\n",
      "Processing doc # 46\n",
      "Processing doc # 51\n",
      "Processing doc # 42\n",
      "Processing doc # 47\n",
      "Processing doc # 52\n",
      "Processing doc # 53\n",
      "Processing doc # 55\n",
      "Processing doc # 48\n",
      "Processing doc # 54\n",
      "Processing doc # 56\n",
      "Processing doc # 61\n",
      "Processing doc # 57\n",
      "Processing doc # 58\n",
      "Processing doc # 62\n",
      "Processing doc # 59\n",
      "Processing doc # 63\n",
      "Processing doc # 60\n",
      "process_doc, done!\n",
      "doc count to process:  468\n",
      "Processing doc # 1\n",
      "Processing doc # 40\n",
      "Processing doc # 79\n",
      "Processing doc # 2\n",
      "Processing doc # 80\n",
      "Processing doc # 41\n",
      "Processing doc # 3\n",
      "Processing doc # 81\n",
      "Processing doc # 4\n",
      "Processing doc # 42\n",
      "Processing doc # 82\n",
      "Processing doc # 43\n",
      "Processing doc # 5\n",
      "Processing doc # 83\n",
      "Processing doc # 6\n",
      "Processing doc # 44\n",
      "Processing doc # 84\n",
      "Processing doc # 7\n",
      "Processing doc # 45\n",
      "Processing doc # 85\n",
      "Processing doc # 46\n",
      "Processing doc # 8\n",
      "Processing doc # 86\n",
      "Processing doc # 47\n",
      "Processing doc # 9\n",
      "Processing doc # 48\n",
      "Processing doc # 87\n",
      "Processing doc # 10\n",
      "Processing doc # 11\n",
      "Processing doc # 49\n",
      "Processing doc # 88\n",
      "Processing doc # 12\n",
      "Processing doc # 50\n",
      "Processing doc # 89\n",
      "Processing doc # 13\n",
      "Processing doc # 51\n",
      "Processing doc # 90\n",
      "Processing doc # 52\n",
      "Processing doc # 14\n",
      "Processing doc # 53\n",
      "Processing doc # 91\n",
      "Processing doc # 15\n",
      "Processing doc # 54\n",
      "Processing doc # 16\n",
      "Processing doc # 92\n",
      "Processing doc # 17\n",
      "Processing doc # 55\n",
      "Processing doc # 93\n",
      "Processing doc # 18\n",
      "Processing doc # 19\n",
      "Processing doc # 94\n",
      "Processing doc # 56\n",
      "Processing doc # 57\n",
      "Processing doc # 95\n",
      "Processing doc # 20\n",
      "Processing doc # 58\n",
      "Processing doc # 21\n",
      "Processing doc # 96\n",
      "Processing doc # 59\n",
      "Processing doc # 97\n",
      "Processing doc # 60\n",
      "Processing doc # 22\n",
      "Processing doc # 98\n",
      "Processing doc # 61\n",
      "Processing doc # 99\n",
      "Processing doc # 62\n",
      "Processing doc # 23\n",
      "Processing doc # 100\n",
      "Processing doc # 24\n",
      "Processing doc # 63\n",
      "Processing doc # 25\n",
      "Processing doc # 101\n",
      "Processing doc # 64\n",
      "Processing doc # 65\n",
      "Processing doc # 26\n",
      "Processing doc # 102\n",
      "Processing doc # 66\n",
      "Processing doc # 103\n",
      "Processing doc # 27\n",
      "Processing doc # 67\n",
      "Processing doc # 104\n",
      "Processing doc # 28\n",
      "Processing doc # 105\n",
      "Processing doc # 68\n",
      "Processing doc # 29\n",
      "Processing doc # 69\n",
      "Processing doc # 30\n",
      "Processing doc # 106\n",
      "Processing doc # 70\n",
      "Processing doc # 31\n",
      "Processing doc # 71\n",
      "Processing doc # 32\n",
      "Processing doc # 72\n",
      "Processing doc # 33\n",
      "Processing doc # 107\n",
      "Processing doc # 73\n",
      "Processing doc # 34\n",
      "Processing doc # 108\n",
      "Processing doc # 74\n",
      "Processing doc # 109\n",
      "Processing doc # 35\n",
      "Processing doc # 110\n",
      "Processing doc # 75\n",
      "Processing doc # 111\n",
      "Processing doc # 36\n",
      "Processing doc # 76\n",
      "Processing doc # 112\n",
      "Processing doc # 37\n",
      "Processing doc # 77\n",
      "Processing doc # 38\n",
      "Processing doc # 78\n",
      "Processing doc # 113\n",
      "Processing doc # 39\n",
      "Processing doc # 118\n",
      "Processing doc # 114\n",
      "Processing doc # 157\n",
      "Processing doc # 115\n",
      "Processing doc # 119\n",
      "Processing doc # 158\n",
      "Processing doc # 116\n",
      "Processing doc # 120\n",
      "Processing doc # 159\n",
      "Processing doc # 117\n",
      "Processing doc # 160\n",
      "Processing doc # 196\n",
      "Processing doc # 121\n",
      "Processing doc # 161\n",
      "Processing doc # 122\n",
      "Processing doc # 197\n",
      "Processing doc # 123\n",
      "Processing doc # 198\n",
      "Processing doc # 162\n",
      "Processing doc # 124\n",
      "Processing doc # 125\n",
      "Processing doc # 199\n",
      "Processing doc # 163\n",
      "Processing doc # 164\n",
      "Processing doc # 126\n",
      "Processing doc # 200\n",
      "Processing doc # 165\n",
      "Processing doc # 127\n",
      "Processing doc # 201\n",
      "Processing doc # 128\n",
      "Processing doc # 166\n",
      "Processing doc # 202\n",
      "Processing doc # 203\n",
      "Processing doc # 129\n",
      "Processing doc # 167\n",
      "Processing doc # 204\n",
      "Processing doc # 168\n",
      "Processing doc # 205\n",
      "Processing doc # 130\n",
      "Processing doc # 169\n",
      "Processing doc # 206\n",
      "Processing doc # 170\n",
      "Processing doc # 131\n",
      "Processing doc # 171\n",
      "Processing doc # 207\n",
      "Processing doc # 132\n",
      "Processing doc # 172\n",
      "Processing doc # 208\n",
      "Processing doc # 133\n",
      "Processing doc # 173\n",
      "Processing doc # 209\n",
      "Processing doc # 134\n",
      "Processing doc # 210\n",
      "Processing doc # 174\n",
      "Processing doc # 135\n",
      "Processing doc # 211\n",
      "Processing doc # 175\n",
      "Processing doc # 136\n",
      "Processing doc # 212\n",
      "Processing doc # 176\n",
      "Processing doc # 137\n",
      "Processing doc # 138\n",
      "Processing doc # 177\n",
      "Processing doc # 213\n",
      "Processing doc # 178\n",
      "Processing doc # 179\n",
      "Processing doc # 139\n",
      "Processing doc # 214\n",
      "Processing doc # 180\n",
      "Processing doc # 140\n",
      "Processing doc # 215\n",
      "Processing doc # 181\n",
      "Processing doc # 182\n",
      "Processing doc # 141\n",
      "Processing doc # 216\n",
      "Processing doc # 183\n",
      "Processing doc # 217\n",
      "Processing doc # 184\n",
      "Processing doc # 142\n",
      "Processing doc # 218\n",
      "Processing doc # 185\n",
      "Processing doc # 143\n",
      "Processing doc # 186\n",
      "Processing doc # 219\n",
      "Processing doc # 144\n",
      "Processing doc # 187\n",
      "Processing doc # 220\n",
      "Processing doc # 188\n",
      "Processing doc # 221\n",
      "Processing doc # 145\n",
      "Processing doc # 189\n",
      "Processing doc # 146\n",
      "Processing doc # 222\n",
      "Processing doc # 190\n",
      "Processing doc # 147\n",
      "Processing doc # 191\n",
      "Processing doc # 223\n",
      "Processing doc # 148\n",
      "Processing doc # 192\n",
      "Processing doc # 149\n",
      "Processing doc # 224\n",
      "Processing doc # 150\n",
      "Processing doc # 193\n",
      "Processing doc # 151\n",
      "Processing doc # 194\n",
      "Processing doc # 152\n",
      "Processing doc # 225\n",
      "Processing doc # 226\n",
      "Processing doc # 195\n",
      "Processing doc # 153\n",
      "Processing doc # 227\n",
      "Processing doc # 235\n",
      "Processing doc # 228\n",
      "Processing doc # 154\n",
      "Processing doc # 236\n",
      "Processing doc # 229\n",
      "Processing doc # 155\n",
      "Processing doc # 237\n",
      "Processing doc # 230\n",
      "Processing doc # 238\n",
      "Processing doc # 156\n",
      "Processing doc # 274\n",
      "Processing doc # 239\n",
      "Processing doc # 231\n",
      "Processing doc # 275\n",
      "Processing doc # 240\n",
      "Processing doc # 232\n",
      "Processing doc # 241\n",
      "Processing doc # 276\n",
      "Processing doc # 233\n",
      "Processing doc # 242\n",
      "Processing doc # 234\n",
      "Processing doc # 277\n",
      "Processing doc # 243\n",
      "Processing doc # 313\n",
      "Processing doc # 278\n",
      "Processing doc # 314\n",
      "Processing doc # 244\n",
      "Processing doc # 315\n",
      "Processing doc # 245\n",
      "Processing doc # 279\n",
      "Processing doc # 316\n",
      "Processing doc # 280\n",
      "Processing doc # 246\n",
      "Processing doc # 317\n",
      "Processing doc # 318\n",
      "Processing doc # 247\n",
      "Processing doc # 281\n",
      "Processing doc # 319\n",
      "Processing doc # 248\n",
      "Processing doc # 282\n",
      "Processing doc # 320\n",
      "Processing doc # 249\n",
      "Processing doc # 283\n",
      "Processing doc # 321\n",
      "Processing doc # 284\n",
      "Processing doc # 250\n",
      "Processing doc # 322\n",
      "Processing doc # 285\n",
      "Processing doc # 251\n",
      "Processing doc # 286\n",
      "Processing doc # 323\n",
      "Processing doc # 324\n",
      "Processing doc # 287\n",
      "Processing doc # 252\n",
      "Processing doc # 288\n",
      "Processing doc # 253\n",
      "Processing doc # 289\n",
      "Processing doc # 254\n",
      "Processing doc # 325\n",
      "Processing doc # 290\n",
      "Processing doc # 255\n",
      "Processing doc # 326\n",
      "Processing doc # 291\n",
      "Processing doc # 327\n",
      "Processing doc # 256\n",
      "Processing doc # 292\n",
      "Processing doc # 328\n",
      "Processing doc # 257\n",
      "Processing doc # 293\n",
      "Processing doc # 329\n",
      "Processing doc # 294\n",
      "Processing doc # 258\n",
      "Processing doc # 330\n",
      "Processing doc # 295\n",
      "Processing doc # 331\n",
      "Processing doc # 259\n",
      "Processing doc # 296\n",
      "Processing doc # 332\n",
      "Processing doc # 297\n",
      "Processing doc # 260\n",
      "Processing doc # 298\n",
      "Processing doc # 333\n",
      "Processing doc # 299\n",
      "Processing doc # 261\n",
      "Processing doc # 334\n",
      "Processing doc # 262\n",
      "Processing doc # 335\n",
      "Processing doc # 300\n",
      "Processing doc # 263\n",
      "Processing doc # 336\n",
      "Processing doc # 264\n",
      "Processing doc # 301\n",
      "Processing doc # 265\n",
      "Processing doc # 302\n",
      "Processing doc # 337\n",
      "Processing doc # 266\n",
      "Processing doc # 303\n",
      "Processing doc # 338\n",
      "Processing doc # 267\n",
      "Processing doc # 339\n",
      "Processing doc # 340\n",
      "Processing doc # 268\n",
      "Processing doc # 304\n",
      "Processing doc # 341\n",
      "Processing doc # 305\n",
      "Processing doc # 269\n",
      "Processing doc # 342\n",
      "Processing doc # 306\n",
      "Processing doc # 270\n",
      "Processing doc # 343\n",
      "Processing doc # 307\n",
      "Processing doc # 344\n",
      "Processing doc # 271\n",
      "Processing doc # 345\n",
      "Processing doc # 308\n",
      "Processing doc # 346\n",
      "Processing doc # 272\n",
      "Processing doc # 309\n",
      "Processing doc # 273\n",
      "Processing doc # 347\n",
      "Processing doc # 310\n",
      "Processing doc # 352\n",
      "Processing doc # 311\n",
      "Processing doc # 348\n",
      "Processing doc # 353\n",
      "Processing doc # 349\n",
      "Processing doc # 312\n",
      "Processing doc # 354\n",
      "Processing doc # 391\n",
      "Processing doc # 350\n",
      "Processing doc # 351\n",
      "Processing doc # 392\n",
      "Processing doc # 355\n",
      "Processing doc # 430\n",
      "Processing doc # 356\n",
      "Processing doc # 431\n",
      "Processing doc # 393\n",
      "Processing doc # 357\n",
      "Processing doc # 432\n",
      "Processing doc # 394\n",
      "Processing doc # 358\n",
      "Processing doc # 433\n",
      "Processing doc # 434\n",
      "Processing doc # 395\n",
      "Processing doc # 359\n",
      "Processing doc # 360\n",
      "Processing doc # 435\n",
      "Processing doc # 396\n",
      "Processing doc # 361\n",
      "Processing doc # 397\n",
      "Processing doc # 436\n",
      "Processing doc # 437\n",
      "Processing doc # 398\n",
      "Processing doc # 362\n",
      "Processing doc # 399\n",
      "Processing doc # 363\n",
      "Processing doc # 400\n",
      "Processing doc # 438\n",
      "Processing doc # 364\n",
      "Processing doc # 401\n",
      "Processing doc # 439\n",
      "Processing doc # 365\n",
      "Processing doc # 402\n",
      "Processing doc # 440\n",
      "Processing doc # 403\n",
      "Processing doc # 441\n",
      "Processing doc # 366\n",
      "Processing doc # 442\n",
      "Processing doc # 404\n",
      "Processing doc # 367\n",
      "Processing doc # 405\n",
      "Processing doc # 368\n",
      "Processing doc # 443\n",
      "Processing doc # 369\n",
      "Processing doc # 444\n",
      "Processing doc # 406\n",
      "Processing doc # 407\n",
      "Processing doc # 445\n",
      "Processing doc # 408\n",
      "Processing doc # 370\n",
      "Processing doc # 446\n",
      "Processing doc # 409\n",
      "Processing doc # 371\n",
      "Processing doc # 447\n",
      "Processing doc # 410\n",
      "Processing doc # 448\n",
      "Processing doc # 372\n",
      "Processing doc # 449\n",
      "Processing doc # 373\n",
      "Processing doc # 411\n",
      "Processing doc # 450\n",
      "Processing doc # 374\n",
      "Processing doc # 412\n",
      "Processing doc # 375\n",
      "Processing doc # 451\n",
      "Processing doc # 413\n",
      "Processing doc # 452\n",
      "Processing doc # 376\n",
      "Processing doc # 414\n",
      "Processing doc # 453\n",
      "Processing doc # 377\n",
      "Processing doc # 415\n",
      "Processing doc # 454\n",
      "Processing doc # 378\n",
      "Processing doc # 416\n",
      "Processing doc # 455\n",
      "Processing doc # 456\n",
      "Processing doc # 417\n",
      "Processing doc # 379\n",
      "Processing doc # 457\n",
      "Processing doc # 418\n",
      "Processing doc # 380\n",
      "Processing doc # 381\n",
      "Processing doc # 419\n",
      "Processing doc # 458\n",
      "Processing doc # 382\n",
      "Processing doc # 420\n",
      "Processing doc # 459\n",
      "Processing doc # 383\n",
      "Processing doc # 460\n",
      "Processing doc # 421\n",
      "Processing doc # 461\n",
      "Processing doc # 422\n",
      "Processing doc # 462\n",
      "Processing doc # 384\n",
      "Processing doc # 423\n",
      "Processing doc # 463\n",
      "Processing doc # 385\n",
      "Processing doc # 464\n",
      "Processing doc # 424\n",
      "Processing doc # 386\n",
      "Processing doc # 465\n",
      "Processing doc # 387\n",
      "Processing doc # 425\n",
      "Processing doc # 466\n",
      "Processing doc # 388\n",
      "Processing doc # 426\n",
      "Processing doc # 389\n",
      "Processing doc # 467\n",
      "Processing doc # 390\n",
      "Processing doc # 468\n",
      "Processing doc # 427\n",
      "Processing doc # 428\n",
      "Processing doc # 429\n",
      "Reading problem 1, done!\n"
     ]
    }
   ],
   "source": [
    "problem = problems[0]\n",
    "index = 0\n",
    "infoproblem = dataset_path + os.sep + problem + os.sep + 'problem-info.json'\n",
    "candidates = []\n",
    "with open(infoproblem, 'r') as f:\n",
    "    fj = json.load(f)\n",
    "    unk_folder = fj['unknown-folder']\n",
    "    for attrib in fj['candidate-authors']:\n",
    "        candidates.append(attrib['author-name'])\n",
    "\n",
    "candidates.sort()\n",
    "# Building training set\n",
    "train_docs = []\n",
    "for candidate in candidates:\n",
    "    train_docs.extend(read_files(dataset_path + os.sep + problem, candidate))\n",
    "train_texts = [text for i, (text, label) in enumerate(train_docs)]\n",
    "train_labels = [label for i, (text, label) in enumerate(train_docs)]\n",
    "index_2_label_dict = {i: l for i, l in enumerate(set(train_labels))}\n",
    "label_2_index_dict = {l: i for i, l in enumerate(set(train_labels))}\n",
    "train_labels = [label_2_index_dict[v] for v in train_labels]\n",
    "w2d = Word2Dim()\n",
    "train_tokenized_with_pos, train_tokenized_indexed = w2d.fit_transform_texts(train_texts, train_labels,\n",
    "                                                                            language[index])\n",
    "\n",
    "maxlen = len(max(train_tokenized_indexed, key=len))  # We will cut the texts after # words\n",
    "embedding_dim = w2d.word_embedding.shape[1]\n",
    "\n",
    "# preparing test set\n",
    "ground_truth_file = dataset_path + os.sep + problem + os.sep + 'ground-truth.json'\n",
    "gt = {}\n",
    "with open(ground_truth_file, 'r') as f:\n",
    "    for attrib in json.load(f)['ground_truth']:\n",
    "        gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "test_docs = read_files(dataset_path + os.sep + problem, unk_folder, gt)\n",
    "test_texts = [text for i, (text, label) in enumerate(test_docs)]\n",
    "test_labels = [label for i, (text, label) in enumerate(test_docs)]\n",
    "\n",
    "# Filter validation to known authors\n",
    "test_texts = [text for i, (text, label) in enumerate(test_docs) if label in label_2_index_dict.keys()]\n",
    "test_labels = [label for i, (text, label) in enumerate(test_docs) if label in label_2_index_dict.keys()]\n",
    "\n",
    "test_labels = [label_2_index_dict[v] for v in test_labels]\n",
    "\n",
    "test_tokenized_with_pos, test_tokenized_indexed = w2d.transform(test_texts)\n",
    "print(\"Reading problem 1, done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Keras Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[index_2_label_dict[test_label] for test_label in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 1019, 9)           72225     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 1017, 32)          896       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 203, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 201, 32)           3104      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 9)                 297       \n",
      "=================================================================\n",
      "Total params: 82,762\n",
      "Trainable params: 82,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 63 samples, validate on 468 samples\n",
      "Epoch 1/120\n",
      "63/63 [==============================] - 25s 400ms/step - loss: 2.2165 - acc: 0.0794 - val_loss: 2.2201 - val_acc: 0.0620\n",
      "Epoch 2/120\n",
      "63/63 [==============================] - 24s 384ms/step - loss: 2.2025 - acc: 0.0952 - val_loss: 2.2032 - val_acc: 0.0684\n",
      "Epoch 3/120\n",
      "63/63 [==============================] - 26s 408ms/step - loss: 2.1981 - acc: 0.1111 - val_loss: 2.2009 - val_acc: 0.0556\n",
      "Epoch 4/120\n",
      "63/63 [==============================] - 25s 398ms/step - loss: 2.1912 - acc: 0.1270 - val_loss: 2.2137 - val_acc: 0.0812\n",
      "Epoch 5/120\n",
      "63/63 [==============================] - 24s 388ms/step - loss: 2.1700 - acc: 0.2063 - val_loss: 2.2180 - val_acc: 0.0812\n",
      "Epoch 6/120\n",
      "63/63 [==============================] - 24s 385ms/step - loss: 2.1570 - acc: 0.2698 - val_loss: 2.2413 - val_acc: 0.0556\n",
      "Epoch 7/120\n",
      "63/63 [==============================] - 24s 380ms/step - loss: 2.1352 - acc: 0.1746 - val_loss: 2.2283 - val_acc: 0.0855\n",
      "Epoch 8/120\n",
      "63/63 [==============================] - 23s 373ms/step - loss: 2.0950 - acc: 0.3333 - val_loss: 2.2306 - val_acc: 0.0641\n",
      "Epoch 9/120\n",
      "63/63 [==============================] - 23s 371ms/step - loss: 2.0444 - acc: 0.3968 - val_loss: 2.1563 - val_acc: 0.1517\n",
      "Epoch 10/120\n",
      "63/63 [==============================] - 24s 385ms/step - loss: 2.0077 - acc: 0.3492 - val_loss: 2.1506 - val_acc: 0.1581\n",
      "Epoch 11/120\n",
      "63/63 [==============================] - 24s 388ms/step - loss: 1.8602 - acc: 0.4444 - val_loss: 2.2819 - val_acc: 0.0962\n",
      "Epoch 12/120\n",
      "63/63 [==============================] - 23s 361ms/step - loss: 1.7632 - acc: 0.3810 - val_loss: 2.0832 - val_acc: 0.1645\n",
      "Epoch 13/120\n",
      "63/63 [==============================] - 24s 383ms/step - loss: 1.5607 - acc: 0.5714 - val_loss: 2.1386 - val_acc: 0.1496\n",
      "Epoch 14/120\n",
      "63/63 [==============================] - 24s 381ms/step - loss: 1.3838 - acc: 0.5873 - val_loss: 2.1581 - val_acc: 0.1432\n",
      "Epoch 15/120\n",
      "62/63 [============================>.] - ETA: 0s - loss: 1.2944 - acc: 0.5968"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "train_data = pad_sequences(train_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "test_data = pad_sequences(test_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_data, test_data, to_categorical(train_labels), to_categorical(test_labels)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels,\n",
    "#                                                   test_size=0.28, random_state=2019,\n",
    "#                                                   stratify=train_labels)\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_val = to_categorical(y_val)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "# model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5))\n",
    "# model.add(Dense(embedding_dim, activation='relu'))\n",
    "model.add(Dense(len(set(train_labels)), activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.layers[0].set_weights([w2d.word_embedding])\n",
    "# model.layers[0].trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=5e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=120,\n",
    "                    batch_size=1)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
