{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Reading general data of the problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading general data of the problems, done!\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import division\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from MyUtils import clean_folder, read_files\n",
    "from Word2Dim import Word2Dim\n",
    "\n",
    "dataset_path = '.' + os.sep + 'pan19-cross-domain-authorship-attribution-training-dataset-2019-01-23'\n",
    "outpath = '.' + os.sep + 'dev_out'\n",
    "\n",
    "clean_folder(outpath)\n",
    "\n",
    "infocollection = dataset_path + os.sep + 'collection-info.json'\n",
    "problems = []\n",
    "language = []\n",
    "with open(infocollection, 'r') as f:\n",
    "    for attrib in json.load(f):\n",
    "        problems.append(attrib['problem-name'])\n",
    "        language.append(attrib['language'])\n",
    "print('Reading general data of the problems, done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reading problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc count to process:  63\n",
      "process_doc, done!\n",
      "doc count to process:  468\n",
      "Reading problem 1, done!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"f1d07faf-51fc-42a3-acd1-f8ea0f3373ca\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"f1d07faf-51fc-42a3-acd1-f8ea0f3373ca\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "%%notify\n",
    "problem = problems[0]\n",
    "index = 0\n",
    "infoproblem = dataset_path + os.sep + problem + os.sep + 'problem-info.json'\n",
    "candidates = []\n",
    "with open(infoproblem, 'r') as f:\n",
    "    fj = json.load(f)\n",
    "    unk_folder = fj['unknown-folder']\n",
    "    for attrib in fj['candidate-authors']:\n",
    "        candidates.append(attrib['author-name'])\n",
    "\n",
    "candidates.sort()\n",
    "# Building training set\n",
    "train_docs = []\n",
    "for candidate in candidates:\n",
    "    train_docs.extend(read_files(dataset_path + os.sep + problem, candidate))\n",
    "train_texts = [text for i, (text, label) in enumerate(train_docs)]\n",
    "train_labels = [label for i, (text, label) in enumerate(train_docs)]\n",
    "index_2_label_dict = {i: l for i, l in enumerate(set(train_labels))}\n",
    "label_2_index_dict = {l: i for i, l in enumerate(set(train_labels))}\n",
    "train_labels = [label_2_index_dict[v] for v in train_labels]\n",
    "w2d = Word2Dim()\n",
    "train_tokenized_with_pos, train_tokenized_indexed = w2d.fit_transform_texts(train_texts, train_labels,\n",
    "                                                                            language[index])\n",
    "\n",
    "maxlen = len(max(train_tokenized_indexed, key=len))  # We will cut the texts after # words\n",
    "embedding_dim = w2d.word_embedding.shape[1]\n",
    "\n",
    "# preparing test set\n",
    "ground_truth_file = dataset_path + os.sep + problem + os.sep + 'ground-truth.json'\n",
    "gt = {}\n",
    "with open(ground_truth_file, 'r') as f:\n",
    "    for attrib in json.load(f)['ground_truth']:\n",
    "        gt[attrib['unknown-text']] = attrib['true-author']\n",
    "\n",
    "test_docs = read_files(dataset_path + os.sep + problem, unk_folder, gt)\n",
    "test_texts = [text for i, (text, label) in enumerate(test_docs)]\n",
    "test_labels = [label for i, (text, label) in enumerate(test_docs)]\n",
    "\n",
    "# Filter validation to known authors\n",
    "test_texts = [text for i, (text, label) in enumerate(test_docs) if label in label_2_index_dict.keys()]\n",
    "test_labels = [label for i, (text, label) in enumerate(test_docs) if label in label_2_index_dict.keys()]\n",
    "\n",
    "test_labels = [label_2_index_dict[v] for v in test_labels]\n",
    "\n",
    "test_tokenized_with_pos, test_tokenized_indexed = w2d.transform(test_texts)\n",
    "print(\"Reading problem 1, done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Keras Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "[index_2_label_dict[test_label] for test_label in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: (?, 1020, 32) x: (?, 1020, 32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              (None, 1020)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1020, 9)      68607       words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 1020, 32)     608         embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 1020, 32)     3104        conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 1020, 32)     0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 32)           0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 9)            297         global_max_pooling1d_20[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 72,616\n",
      "Trainable params: 72,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 54 samples, validate on 9 samples\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 2.2022 - acc: 0.0926 - val_loss: 2.2024 - val_acc: 0.1111\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1951 - acc: 0.1111 - val_loss: 2.2021 - val_acc: 0.1111\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1893 - acc: 0.1111 - val_loss: 2.2012 - val_acc: 0.1111\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1836 - acc: 0.1111 - val_loss: 2.2004 - val_acc: 0.1111\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1782 - acc: 0.1667 - val_loss: 2.1998 - val_acc: 0.1111\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1739 - acc: 0.2407 - val_loss: 2.1989 - val_acc: 0.1111\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1693 - acc: 0.2222 - val_loss: 2.1988 - val_acc: 0.1111\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1643 - acc: 0.2593 - val_loss: 2.1975 - val_acc: 0.1111\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1599 - acc: 0.2778 - val_loss: 2.1964 - val_acc: 0.1111\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1550 - acc: 0.3704 - val_loss: 2.1957 - val_acc: 0.1111\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1508 - acc: 0.3704 - val_loss: 2.1945 - val_acc: 0.1111\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1463 - acc: 0.3704 - val_loss: 2.1937 - val_acc: 0.1111\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1421 - acc: 0.4259 - val_loss: 2.1926 - val_acc: 0.1111\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1379 - acc: 0.4259 - val_loss: 2.1912 - val_acc: 0.2222\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1339 - acc: 0.4259 - val_loss: 2.1902 - val_acc: 0.2222\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1293 - acc: 0.4259 - val_loss: 2.1887 - val_acc: 0.2222\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1250 - acc: 0.4259 - val_loss: 2.1878 - val_acc: 0.2222\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1207 - acc: 0.5000 - val_loss: 2.1864 - val_acc: 0.2222\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1164 - acc: 0.4630 - val_loss: 2.1850 - val_acc: 0.2222\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1122 - acc: 0.4815 - val_loss: 2.1836 - val_acc: 0.2222\n",
      "Epoch 21/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1075 - acc: 0.5185 - val_loss: 2.1821 - val_acc: 0.2222\n",
      "Epoch 22/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1026 - acc: 0.5185 - val_loss: 2.1809 - val_acc: 0.2222\n",
      "Epoch 23/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0984 - acc: 0.5370 - val_loss: 2.1797 - val_acc: 0.2222\n",
      "Epoch 24/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0937 - acc: 0.5370 - val_loss: 2.1782 - val_acc: 0.3333\n",
      "Epoch 25/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0887 - acc: 0.5370 - val_loss: 2.1768 - val_acc: 0.3333\n",
      "Epoch 26/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0837 - acc: 0.5370 - val_loss: 2.1749 - val_acc: 0.3333\n",
      "Epoch 27/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.0786 - acc: 0.5556 - val_loss: 2.1735 - val_acc: 0.3333\n",
      "Epoch 28/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0735 - acc: 0.5556 - val_loss: 2.1721 - val_acc: 0.3333\n",
      "Epoch 29/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0676 - acc: 0.5556 - val_loss: 2.1706 - val_acc: 0.3333\n",
      "Epoch 30/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0627 - acc: 0.5741 - val_loss: 2.1691 - val_acc: 0.3333\n",
      "Epoch 31/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0566 - acc: 0.5741 - val_loss: 2.1675 - val_acc: 0.3333\n",
      "Epoch 32/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0506 - acc: 0.5741 - val_loss: 2.1659 - val_acc: 0.3333\n",
      "Epoch 33/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0448 - acc: 0.5741 - val_loss: 2.1638 - val_acc: 0.3333\n",
      "Epoch 34/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.0388 - acc: 0.5741 - val_loss: 2.1619 - val_acc: 0.3333\n",
      "Epoch 35/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.0323 - acc: 0.5926 - val_loss: 2.1595 - val_acc: 0.3333\n",
      "Epoch 36/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0258 - acc: 0.5926 - val_loss: 2.1572 - val_acc: 0.2222\n",
      "Epoch 37/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0191 - acc: 0.5926 - val_loss: 2.1550 - val_acc: 0.2222\n",
      "Epoch 38/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0120 - acc: 0.6111 - val_loss: 2.1529 - val_acc: 0.2222\n",
      "Epoch 39/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0048 - acc: 0.6111 - val_loss: 2.1504 - val_acc: 0.2222\n",
      "Epoch 40/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.9980 - acc: 0.6111 - val_loss: 2.1484 - val_acc: 0.2222\n",
      "Epoch 41/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9904 - acc: 0.6296 - val_loss: 2.1463 - val_acc: 0.2222\n",
      "Epoch 42/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9824 - acc: 0.6296 - val_loss: 2.1437 - val_acc: 0.2222\n",
      "Epoch 43/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9746 - acc: 0.6296 - val_loss: 2.1418 - val_acc: 0.2222\n",
      "Epoch 44/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9658 - acc: 0.6296 - val_loss: 2.1396 - val_acc: 0.2222\n",
      "Epoch 45/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.9575 - acc: 0.6296 - val_loss: 2.1366 - val_acc: 0.2222\n",
      "Epoch 46/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9493 - acc: 0.6296 - val_loss: 2.1337 - val_acc: 0.2222\n",
      "Epoch 47/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9399 - acc: 0.6296 - val_loss: 2.1307 - val_acc: 0.2222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.9306 - acc: 0.6296 - val_loss: 2.1280 - val_acc: 0.2222\n",
      "Epoch 49/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9221 - acc: 0.6296 - val_loss: 2.1254 - val_acc: 0.2222\n",
      "Epoch 50/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9117 - acc: 0.6296 - val_loss: 2.1219 - val_acc: 0.2222\n",
      "Epoch 51/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9025 - acc: 0.6296 - val_loss: 2.1193 - val_acc: 0.2222\n",
      "Epoch 52/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8932 - acc: 0.6296 - val_loss: 2.1158 - val_acc: 0.2222\n",
      "Epoch 53/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8818 - acc: 0.6296 - val_loss: 2.1126 - val_acc: 0.2222\n",
      "Epoch 54/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.8713 - acc: 0.6667 - val_loss: 2.1091 - val_acc: 0.2222\n",
      "Epoch 55/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8592 - acc: 0.6667 - val_loss: 2.1055 - val_acc: 0.2222\n",
      "Epoch 56/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8479 - acc: 0.6481 - val_loss: 2.1022 - val_acc: 0.2222\n",
      "Epoch 57/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8355 - acc: 0.7037 - val_loss: 2.0977 - val_acc: 0.3333\n",
      "Epoch 58/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8241 - acc: 0.6852 - val_loss: 2.0940 - val_acc: 0.2222\n",
      "Epoch 59/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8111 - acc: 0.7222 - val_loss: 2.0899 - val_acc: 0.2222\n",
      "Epoch 60/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7987 - acc: 0.7407 - val_loss: 2.0863 - val_acc: 0.2222\n",
      "Epoch 61/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7877 - acc: 0.7407 - val_loss: 2.0825 - val_acc: 0.2222\n",
      "Epoch 62/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7723 - acc: 0.7778 - val_loss: 2.0777 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.7590 - acc: 0.8333 - val_loss: 2.0731 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.7447 - acc: 0.8519 - val_loss: 2.0679 - val_acc: 0.2222\n",
      "Epoch 65/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7317 - acc: 0.8519 - val_loss: 2.0631 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7163 - acc: 0.8704 - val_loss: 2.0583 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7000 - acc: 0.8889 - val_loss: 2.0535 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6859 - acc: 0.9074 - val_loss: 2.0489 - val_acc: 0.2222\n",
      "Epoch 69/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6701 - acc: 0.9074 - val_loss: 2.0428 - val_acc: 0.3333\n",
      "Epoch 70/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6534 - acc: 0.9259 - val_loss: 2.0384 - val_acc: 0.3333\n",
      "Epoch 71/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6370 - acc: 0.9259 - val_loss: 2.0339 - val_acc: 0.3333\n",
      "Epoch 72/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6206 - acc: 0.9259 - val_loss: 2.0286 - val_acc: 0.3333\n",
      "Epoch 73/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.6040 - acc: 0.9444 - val_loss: 2.0221 - val_acc: 0.3333\n",
      "Epoch 74/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5865 - acc: 0.9444 - val_loss: 2.0167 - val_acc: 0.3333\n",
      "Epoch 75/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5696 - acc: 0.9444 - val_loss: 2.0105 - val_acc: 0.3333\n",
      "Epoch 76/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.5517 - acc: 0.9444 - val_loss: 2.0047 - val_acc: 0.3333\n",
      "Epoch 77/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.5327 - acc: 0.9444 - val_loss: 1.9993 - val_acc: 0.3333\n",
      "Epoch 78/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5148 - acc: 0.9444 - val_loss: 1.9925 - val_acc: 0.3333\n",
      "Epoch 79/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.4948 - acc: 0.9444 - val_loss: 1.9864 - val_acc: 0.3333\n",
      "Epoch 80/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.4763 - acc: 0.9444 - val_loss: 1.9812 - val_acc: 0.3333\n",
      "Epoch 81/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.4567 - acc: 0.9444 - val_loss: 1.9740 - val_acc: 0.4444\n",
      "Epoch 82/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.4377 - acc: 0.9444 - val_loss: 1.9670 - val_acc: 0.4444\n",
      "Epoch 83/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.4172 - acc: 0.9630 - val_loss: 1.9601 - val_acc: 0.4444\n",
      "Epoch 84/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3983 - acc: 0.9630 - val_loss: 1.9540 - val_acc: 0.4444\n",
      "Epoch 85/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3777 - acc: 0.9630 - val_loss: 1.9468 - val_acc: 0.4444\n",
      "Epoch 86/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3575 - acc: 0.9630 - val_loss: 1.9404 - val_acc: 0.4444\n",
      "Epoch 87/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3357 - acc: 0.9815 - val_loss: 1.9336 - val_acc: 0.4444\n",
      "Epoch 88/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3151 - acc: 0.9815 - val_loss: 1.9267 - val_acc: 0.4444\n",
      "Epoch 89/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2941 - acc: 0.9815 - val_loss: 1.9201 - val_acc: 0.4444\n",
      "Epoch 90/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2741 - acc: 1.0000 - val_loss: 1.9121 - val_acc: 0.4444\n",
      "Epoch 91/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2520 - acc: 1.0000 - val_loss: 1.9057 - val_acc: 0.4444\n",
      "Epoch 92/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2297 - acc: 1.0000 - val_loss: 1.8977 - val_acc: 0.4444\n",
      "Epoch 93/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2091 - acc: 1.0000 - val_loss: 1.8908 - val_acc: 0.4444\n",
      "Epoch 94/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1877 - acc: 1.0000 - val_loss: 1.8829 - val_acc: 0.4444\n",
      "Epoch 95/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1652 - acc: 1.0000 - val_loss: 1.8762 - val_acc: 0.4444\n",
      "Epoch 96/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1429 - acc: 1.0000 - val_loss: 1.8689 - val_acc: 0.4444\n",
      "Epoch 97/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1216 - acc: 1.0000 - val_loss: 1.8616 - val_acc: 0.4444\n",
      "Epoch 98/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0992 - acc: 1.0000 - val_loss: 1.8540 - val_acc: 0.4444\n",
      "Epoch 99/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0783 - acc: 1.0000 - val_loss: 1.8455 - val_acc: 0.4444\n",
      "Epoch 100/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0560 - acc: 1.0000 - val_loss: 1.8389 - val_acc: 0.4444\n",
      "Epoch 101/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0342 - acc: 1.0000 - val_loss: 1.8303 - val_acc: 0.4444\n",
      "Epoch 102/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0108 - acc: 1.0000 - val_loss: 1.8236 - val_acc: 0.4444\n",
      "Epoch 103/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9900 - acc: 1.0000 - val_loss: 1.8145 - val_acc: 0.4444\n",
      "Epoch 104/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9675 - acc: 1.0000 - val_loss: 1.8059 - val_acc: 0.5556\n",
      "Epoch 105/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9458 - acc: 1.0000 - val_loss: 1.7994 - val_acc: 0.5556\n",
      "Epoch 106/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9239 - acc: 1.0000 - val_loss: 1.7927 - val_acc: 0.5556\n",
      "Epoch 107/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9029 - acc: 1.0000 - val_loss: 1.7829 - val_acc: 0.5556\n",
      "Epoch 108/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.8815 - acc: 1.0000 - val_loss: 1.7771 - val_acc: 0.5556\n",
      "Epoch 109/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.8591 - acc: 1.0000 - val_loss: 1.7695 - val_acc: 0.5556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.8386 - acc: 1.0000 - val_loss: 1.7598 - val_acc: 0.5556\n",
      "Epoch 111/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.8179 - acc: 1.0000 - val_loss: 1.7552 - val_acc: 0.5556\n",
      "Epoch 112/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7969 - acc: 1.0000 - val_loss: 1.7463 - val_acc: 0.5556\n",
      "Epoch 113/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.7761 - acc: 1.0000 - val_loss: 1.7380 - val_acc: 0.5556\n",
      "Epoch 114/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7559 - acc: 1.0000 - val_loss: 1.7300 - val_acc: 0.5556\n",
      "Epoch 115/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7367 - acc: 1.0000 - val_loss: 1.7225 - val_acc: 0.5556\n",
      "Epoch 116/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.7160 - acc: 1.0000 - val_loss: 1.7162 - val_acc: 0.5556\n",
      "Epoch 117/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6961 - acc: 1.0000 - val_loss: 1.7072 - val_acc: 0.5556\n",
      "Epoch 118/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.6774 - acc: 1.0000 - val_loss: 1.7014 - val_acc: 0.5556\n",
      "Epoch 119/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6574 - acc: 1.0000 - val_loss: 1.6941 - val_acc: 0.5556\n",
      "Epoch 120/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6398 - acc: 1.0000 - val_loss: 1.6859 - val_acc: 0.5556\n",
      "Epoch 121/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6204 - acc: 1.0000 - val_loss: 1.6786 - val_acc: 0.4444\n",
      "Epoch 122/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.6024 - acc: 1.0000 - val_loss: 1.6716 - val_acc: 0.5556\n",
      "Epoch 123/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5848 - acc: 1.0000 - val_loss: 1.6651 - val_acc: 0.4444\n",
      "Epoch 124/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5675 - acc: 1.0000 - val_loss: 1.6587 - val_acc: 0.4444\n",
      "Epoch 125/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5498 - acc: 1.0000 - val_loss: 1.6509 - val_acc: 0.4444\n",
      "Epoch 126/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5329 - acc: 1.0000 - val_loss: 1.6449 - val_acc: 0.4444\n",
      "Epoch 127/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5168 - acc: 1.0000 - val_loss: 1.6396 - val_acc: 0.3333\n",
      "Epoch 128/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.5010 - acc: 1.0000 - val_loss: 1.6330 - val_acc: 0.4444\n",
      "Epoch 129/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4847 - acc: 1.0000 - val_loss: 1.6267 - val_acc: 0.4444\n",
      "Epoch 130/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4693 - acc: 1.0000 - val_loss: 1.6198 - val_acc: 0.4444\n",
      "Epoch 131/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.4542 - acc: 1.0000 - val_loss: 1.6143 - val_acc: 0.3333\n",
      "Epoch 132/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4401 - acc: 1.0000 - val_loss: 1.6088 - val_acc: 0.3333\n",
      "Epoch 133/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4255 - acc: 1.0000 - val_loss: 1.6029 - val_acc: 0.3333\n",
      "Epoch 134/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.4108 - acc: 1.0000 - val_loss: 1.5970 - val_acc: 0.3333\n",
      "Epoch 135/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3982 - acc: 1.0000 - val_loss: 1.5909 - val_acc: 0.3333\n",
      "Epoch 136/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3845 - acc: 1.0000 - val_loss: 1.5844 - val_acc: 0.3333\n",
      "Epoch 137/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3721 - acc: 1.0000 - val_loss: 1.5793 - val_acc: 0.3333\n",
      "Epoch 138/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3598 - acc: 1.0000 - val_loss: 1.5737 - val_acc: 0.3333\n",
      "Epoch 139/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3470 - acc: 1.0000 - val_loss: 1.5677 - val_acc: 0.3333\n",
      "Epoch 140/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.3365 - acc: 1.0000 - val_loss: 1.5630 - val_acc: 0.3333\n",
      "Epoch 141/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3241 - acc: 1.0000 - val_loss: 1.5585 - val_acc: 0.3333\n",
      "Epoch 142/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3135 - acc: 1.0000 - val_loss: 1.5529 - val_acc: 0.3333\n",
      "Epoch 143/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.3030 - acc: 1.0000 - val_loss: 1.5467 - val_acc: 0.3333\n",
      "Epoch 144/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2924 - acc: 1.0000 - val_loss: 1.5409 - val_acc: 0.3333\n",
      "Epoch 145/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2819 - acc: 1.0000 - val_loss: 1.5359 - val_acc: 0.3333\n",
      "Epoch 146/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2723 - acc: 1.0000 - val_loss: 1.5314 - val_acc: 0.3333\n",
      "Epoch 147/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2632 - acc: 1.0000 - val_loss: 1.5271 - val_acc: 0.4444\n",
      "Epoch 148/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2539 - acc: 1.0000 - val_loss: 1.5216 - val_acc: 0.4444\n",
      "Epoch 149/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2450 - acc: 1.0000 - val_loss: 1.5169 - val_acc: 0.4444\n",
      "Epoch 150/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2366 - acc: 1.0000 - val_loss: 1.5115 - val_acc: 0.4444\n",
      "Epoch 151/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.2278 - acc: 1.0000 - val_loss: 1.5082 - val_acc: 0.4444\n",
      "Epoch 152/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2198 - acc: 1.0000 - val_loss: 1.5036 - val_acc: 0.4444\n",
      "Epoch 153/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2125 - acc: 1.0000 - val_loss: 1.4988 - val_acc: 0.4444\n",
      "Epoch 154/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.2049 - acc: 1.0000 - val_loss: 1.4952 - val_acc: 0.4444\n",
      "Epoch 155/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1972 - acc: 1.0000 - val_loss: 1.4887 - val_acc: 0.4444\n",
      "Epoch 156/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1903 - acc: 1.0000 - val_loss: 1.4842 - val_acc: 0.4444\n",
      "Epoch 157/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1838 - acc: 1.0000 - val_loss: 1.4796 - val_acc: 0.4444\n",
      "Epoch 158/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1773 - acc: 1.0000 - val_loss: 1.4751 - val_acc: 0.4444\n",
      "Epoch 159/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1709 - acc: 1.0000 - val_loss: 1.4702 - val_acc: 0.4444\n",
      "Epoch 160/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1653 - acc: 1.0000 - val_loss: 1.4664 - val_acc: 0.4444\n",
      "Epoch 161/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1592 - acc: 1.0000 - val_loss: 1.4624 - val_acc: 0.4444\n",
      "Epoch 162/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1535 - acc: 1.0000 - val_loss: 1.4591 - val_acc: 0.4444\n",
      "Epoch 163/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1484 - acc: 1.0000 - val_loss: 1.4553 - val_acc: 0.4444\n",
      "Epoch 164/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1432 - acc: 1.0000 - val_loss: 1.4509 - val_acc: 0.4444\n",
      "Epoch 165/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1379 - acc: 1.0000 - val_loss: 1.4486 - val_acc: 0.4444\n",
      "Epoch 166/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1331 - acc: 1.0000 - val_loss: 1.4446 - val_acc: 0.4444\n",
      "Epoch 167/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1285 - acc: 1.0000 - val_loss: 1.4399 - val_acc: 0.4444\n",
      "Epoch 168/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1243 - acc: 1.0000 - val_loss: 1.4379 - val_acc: 0.4444\n",
      "Epoch 169/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1195 - acc: 1.0000 - val_loss: 1.4342 - val_acc: 0.4444\n",
      "Epoch 170/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1155 - acc: 1.0000 - val_loss: 1.4313 - val_acc: 0.4444\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1115 - acc: 1.0000 - val_loss: 1.4274 - val_acc: 0.4444\n",
      "Epoch 172/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.1075 - acc: 1.0000 - val_loss: 1.4253 - val_acc: 0.4444\n",
      "Epoch 173/500\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1026 - acc: 1.000 - 0s 5ms/step - loss: 0.1036 - acc: 1.0000 - val_loss: 1.4207 - val_acc: 0.4444\n",
      "Epoch 174/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1000 - acc: 1.0000 - val_loss: 1.4184 - val_acc: 0.4444\n",
      "Epoch 175/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0964 - acc: 1.0000 - val_loss: 1.4145 - val_acc: 0.4444\n",
      "Epoch 176/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0932 - acc: 1.0000 - val_loss: 1.4123 - val_acc: 0.4444\n",
      "Epoch 177/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0902 - acc: 1.0000 - val_loss: 1.4101 - val_acc: 0.4444\n",
      "Epoch 178/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0870 - acc: 1.0000 - val_loss: 1.4063 - val_acc: 0.4444\n",
      "Epoch 179/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0839 - acc: 1.0000 - val_loss: 1.4033 - val_acc: 0.4444\n",
      "Epoch 180/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0809 - acc: 1.0000 - val_loss: 1.4024 - val_acc: 0.4444\n",
      "Epoch 181/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0783 - acc: 1.0000 - val_loss: 1.3987 - val_acc: 0.4444\n",
      "Epoch 182/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0755 - acc: 1.0000 - val_loss: 1.3965 - val_acc: 0.4444\n",
      "Epoch 183/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0729 - acc: 1.0000 - val_loss: 1.3936 - val_acc: 0.4444\n",
      "Epoch 184/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0704 - acc: 1.0000 - val_loss: 1.3913 - val_acc: 0.4444\n",
      "Epoch 185/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0680 - acc: 1.0000 - val_loss: 1.3891 - val_acc: 0.4444\n",
      "Epoch 186/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0657 - acc: 1.0000 - val_loss: 1.3853 - val_acc: 0.4444\n",
      "Epoch 187/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0635 - acc: 1.0000 - val_loss: 1.3855 - val_acc: 0.4444\n",
      "Epoch 188/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0613 - acc: 1.0000 - val_loss: 1.3826 - val_acc: 0.4444\n",
      "Epoch 189/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0592 - acc: 1.0000 - val_loss: 1.3781 - val_acc: 0.4444\n",
      "Epoch 190/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 1.3766 - val_acc: 0.4444\n",
      "Epoch 191/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0553 - acc: 1.0000 - val_loss: 1.3749 - val_acc: 0.4444\n",
      "Epoch 192/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0535 - acc: 1.0000 - val_loss: 1.3721 - val_acc: 0.4444\n",
      "Epoch 193/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0516 - acc: 1.0000 - val_loss: 1.3712 - val_acc: 0.4444\n",
      "Epoch 194/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0499 - acc: 1.0000 - val_loss: 1.3680 - val_acc: 0.4444\n",
      "Epoch 195/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0481 - acc: 1.0000 - val_loss: 1.3662 - val_acc: 0.4444\n",
      "Epoch 196/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0466 - acc: 1.0000 - val_loss: 1.3659 - val_acc: 0.4444\n",
      "Epoch 197/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0450 - acc: 1.0000 - val_loss: 1.3637 - val_acc: 0.4444\n",
      "Epoch 198/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 1.3611 - val_acc: 0.4444\n",
      "Epoch 199/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0420 - acc: 1.0000 - val_loss: 1.3608 - val_acc: 0.4444\n",
      "Epoch 200/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0406 - acc: 1.0000 - val_loss: 1.3574 - val_acc: 0.4444\n",
      "Epoch 201/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0392 - acc: 1.0000 - val_loss: 1.3561 - val_acc: 0.4444\n",
      "Epoch 202/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0379 - acc: 1.0000 - val_loss: 1.3527 - val_acc: 0.4444\n",
      "Epoch 203/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 1.3531 - val_acc: 0.4444\n",
      "Epoch 204/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0355 - acc: 1.0000 - val_loss: 1.3519 - val_acc: 0.4444\n",
      "Epoch 205/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0343 - acc: 1.0000 - val_loss: 1.3496 - val_acc: 0.4444\n",
      "Epoch 206/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0331 - acc: 1.0000 - val_loss: 1.3464 - val_acc: 0.4444\n",
      "Epoch 207/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0321 - acc: 1.0000 - val_loss: 1.3461 - val_acc: 0.4444\n",
      "Epoch 208/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0310 - acc: 1.0000 - val_loss: 1.3459 - val_acc: 0.4444\n",
      "Epoch 209/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0301 - acc: 1.0000 - val_loss: 1.3435 - val_acc: 0.4444\n",
      "Epoch 210/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 1.0000 - val_loss: 1.3444 - val_acc: 0.4444\n",
      "Epoch 211/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.3414 - val_acc: 0.4444\n",
      "Epoch 212/500\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.0274 - acc: 1.000 - 0s 5ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 1.3406 - val_acc: 0.4444\n",
      "Epoch 213/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0263 - acc: 1.0000 - val_loss: 1.3388 - val_acc: 0.4444\n",
      "Epoch 214/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 1.3371 - val_acc: 0.4444\n",
      "Epoch 215/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0246 - acc: 1.0000 - val_loss: 1.3360 - val_acc: 0.4444\n",
      "Epoch 216/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 1.3364 - val_acc: 0.4444\n",
      "Epoch 217/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 1.3333 - val_acc: 0.4444\n",
      "Epoch 218/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 1.3316 - val_acc: 0.4444\n",
      "Epoch 219/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 1.3318 - val_acc: 0.4444\n",
      "Epoch 220/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 1.3315 - val_acc: 0.4444\n",
      "Epoch 221/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.3307 - val_acc: 0.4444\n",
      "Epoch 222/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0195 - acc: 1.0000 - val_loss: 1.3294 - val_acc: 0.4444\n",
      "Epoch 223/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 1.3272 - val_acc: 0.4444\n",
      "Epoch 224/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 1.3273 - val_acc: 0.4444\n",
      "Epoch 225/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0177 - acc: 1.0000 - val_loss: 1.3271 - val_acc: 0.4444\n",
      "Epoch 226/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 1.3263 - val_acc: 0.4444\n",
      "Epoch 227/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 1.3245 - val_acc: 0.4444\n",
      "Epoch 228/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 1.3242 - val_acc: 0.4444\n",
      "Epoch 229/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 1.3217 - val_acc: 0.4444\n",
      "Epoch 230/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 1.3205 - val_acc: 0.4444\n",
      "Epoch 231/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 1.3193 - val_acc: 0.4444\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.3208 - val_acc: 0.4444\n",
      "Epoch 233/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.4444\n",
      "Epoch 234/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 1.3184 - val_acc: 0.4444\n",
      "Epoch 235/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 1.3187 - val_acc: 0.4444\n",
      "Epoch 236/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.4444\n",
      "Epoch 237/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.3179 - val_acc: 0.4444\n",
      "Epoch 238/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.3175 - val_acc: 0.4444\n",
      "Epoch 239/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 1.3141 - val_acc: 0.4444\n",
      "Epoch 240/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0109 - acc: 1.0000 - val_loss: 1.3167 - val_acc: 0.4444\n",
      "Epoch 241/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.3146 - val_acc: 0.4444\n",
      "Epoch 242/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.3145 - val_acc: 0.4444\n",
      "Epoch 243/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 1.3141 - val_acc: 0.4444\n",
      "Epoch 244/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 1.3134 - val_acc: 0.4444\n",
      "Epoch 245/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.3120 - val_acc: 0.4444\n",
      "Epoch 246/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 1.3117 - val_acc: 0.4444\n",
      "Epoch 247/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 1.3119 - val_acc: 0.4444\n",
      "Epoch 248/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.4444\n",
      "Epoch 249/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 1.3095 - val_acc: 0.4444\n",
      "Epoch 250/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 1.3098 - val_acc: 0.4444\n",
      "Epoch 251/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.3107 - val_acc: 0.4444\n",
      "Epoch 252/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.4444\n",
      "Epoch 253/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.3094 - val_acc: 0.4444\n",
      "Epoch 254/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 1.3096 - val_acc: 0.4444\n",
      "Epoch 255/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.3094 - val_acc: 0.4444\n",
      "Epoch 256/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.3102 - val_acc: 0.4444\n",
      "Epoch 257/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.3074 - val_acc: 0.4444\n",
      "Epoch 258/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 1.3077 - val_acc: 0.4444\n",
      "Epoch 259/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 1.3083 - val_acc: 0.4444\n",
      "Epoch 260/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.3088 - val_acc: 0.4444\n",
      "Epoch 261/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.3072 - val_acc: 0.4444\n",
      "Epoch 262/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.4444\n",
      "Epoch 263/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.3074 - val_acc: 0.4444\n",
      "Epoch 264/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.3072 - val_acc: 0.4444\n",
      "Epoch 265/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.3075 - val_acc: 0.4444\n",
      "Epoch 266/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 1.3084 - val_acc: 0.4444\n",
      "Epoch 267/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.3092 - val_acc: 0.4444\n",
      "Epoch 268/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.3073 - val_acc: 0.4444\n",
      "Epoch 269/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.3070 - val_acc: 0.4444\n",
      "Epoch 270/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.3086 - val_acc: 0.4444\n",
      "Epoch 271/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.3082 - val_acc: 0.4444\n",
      "Epoch 272/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.3072 - val_acc: 0.4444\n",
      "Epoch 273/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.3080 - val_acc: 0.4444\n",
      "Epoch 274/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.3077 - val_acc: 0.4444\n",
      "Epoch 275/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.3077 - val_acc: 0.4444\n",
      "Epoch 276/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.3069 - val_acc: 0.4444\n",
      "Epoch 277/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.3065 - val_acc: 0.4444\n",
      "Epoch 278/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 1.3076 - val_acc: 0.4444\n",
      "Epoch 279/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.3084 - val_acc: 0.4444\n",
      "Epoch 280/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.3066 - val_acc: 0.4444\n",
      "Epoch 281/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.3068 - val_acc: 0.4444\n",
      "Epoch 282/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.3072 - val_acc: 0.4444\n",
      "Epoch 283/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.3076 - val_acc: 0.4444\n",
      "Epoch 284/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 1.3075 - val_acc: 0.4444\n",
      "Epoch 285/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.3066 - val_acc: 0.4444\n",
      "Epoch 286/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.3056 - val_acc: 0.4444\n",
      "Epoch 287/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 1.3082 - val_acc: 0.4444\n",
      "Epoch 288/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.4444\n",
      "Epoch 289/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.3091 - val_acc: 0.4444\n",
      "Epoch 290/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.3081 - val_acc: 0.4444\n",
      "Epoch 291/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.3105 - val_acc: 0.4444\n",
      "Epoch 292/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.3081 - val_acc: 0.4444\n",
      "Epoch 293/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.3096 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.3109 - val_acc: 0.4444\n",
      "Epoch 295/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.3110 - val_acc: 0.4444\n",
      "Epoch 296/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.4444\n",
      "Epoch 297/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.3094 - val_acc: 0.4444\n",
      "Epoch 298/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.3119 - val_acc: 0.4444\n",
      "Epoch 299/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.3107 - val_acc: 0.4444\n",
      "Epoch 300/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.3132 - val_acc: 0.4444\n",
      "Epoch 301/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3128 - val_acc: 0.4444\n",
      "Epoch 302/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.3135 - val_acc: 0.4444\n",
      "Epoch 303/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3134 - val_acc: 0.4444\n",
      "Epoch 304/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.3141 - val_acc: 0.4444\n",
      "Epoch 305/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.3147 - val_acc: 0.4444\n",
      "Epoch 306/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.4444\n",
      "Epoch 307/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.3168 - val_acc: 0.4444\n",
      "Epoch 308/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.3156 - val_acc: 0.4444\n",
      "Epoch 309/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3167 - val_acc: 0.4444\n",
      "Epoch 310/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3172 - val_acc: 0.4444\n",
      "Epoch 311/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.3176 - val_acc: 0.4444\n",
      "Epoch 312/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3173 - val_acc: 0.4444\n",
      "Epoch 313/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3194 - val_acc: 0.4444\n",
      "Epoch 314/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.3191 - val_acc: 0.4444\n",
      "Epoch 315/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.3195 - val_acc: 0.4444\n",
      "Epoch 316/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.3196 - val_acc: 0.4444\n",
      "Epoch 317/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.7829e-04 - acc: 1.0000 - val_loss: 1.3202 - val_acc: 0.4444\n",
      "Epoch 318/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 9.4715e-04 - acc: 1.0000 - val_loss: 1.3238 - val_acc: 0.4444\n",
      "Epoch 319/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.1989e-04 - acc: 1.0000 - val_loss: 1.3219 - val_acc: 0.4444\n",
      "Epoch 320/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.9170e-04 - acc: 1.0000 - val_loss: 1.3250 - val_acc: 0.4444\n",
      "Epoch 321/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.6404e-04 - acc: 1.0000 - val_loss: 1.3245 - val_acc: 0.4444\n",
      "Epoch 322/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.3829e-04 - acc: 1.0000 - val_loss: 1.3252 - val_acc: 0.4444\n",
      "Epoch 323/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.1388e-04 - acc: 1.0000 - val_loss: 1.3264 - val_acc: 0.4444\n",
      "Epoch 324/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.8946e-04 - acc: 1.0000 - val_loss: 1.3273 - val_acc: 0.4444\n",
      "Epoch 325/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.6541e-04 - acc: 1.0000 - val_loss: 1.3264 - val_acc: 0.4444\n",
      "Epoch 326/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.4342e-04 - acc: 1.0000 - val_loss: 1.3286 - val_acc: 0.4444\n",
      "Epoch 327/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 7.2138e-04 - acc: 1.0000 - val_loss: 1.3289 - val_acc: 0.4444\n",
      "Epoch 328/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.9944e-04 - acc: 1.0000 - val_loss: 1.3279 - val_acc: 0.4444\n",
      "Epoch 329/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.7695e-04 - acc: 1.0000 - val_loss: 1.3293 - val_acc: 0.4444\n",
      "Epoch 330/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.5637e-04 - acc: 1.0000 - val_loss: 1.3317 - val_acc: 0.4444\n",
      "Epoch 331/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.3782e-04 - acc: 1.0000 - val_loss: 1.3302 - val_acc: 0.4444\n",
      "Epoch 332/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.1841e-04 - acc: 1.0000 - val_loss: 1.3323 - val_acc: 0.4444\n",
      "Epoch 333/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.9912e-04 - acc: 1.0000 - val_loss: 1.3331 - val_acc: 0.4444\n",
      "Epoch 334/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.8249e-04 - acc: 1.0000 - val_loss: 1.3344 - val_acc: 0.4444\n",
      "Epoch 335/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.6562e-04 - acc: 1.0000 - val_loss: 1.3369 - val_acc: 0.4444\n",
      "Epoch 336/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.4835e-04 - acc: 1.0000 - val_loss: 1.3346 - val_acc: 0.4444\n",
      "Epoch 337/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.3157e-04 - acc: 1.0000 - val_loss: 1.3367 - val_acc: 0.4444\n",
      "Epoch 338/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.1499e-04 - acc: 1.0000 - val_loss: 1.3342 - val_acc: 0.4444\n",
      "Epoch 339/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.0032e-04 - acc: 1.0000 - val_loss: 1.3369 - val_acc: 0.4444\n",
      "Epoch 340/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.8512e-04 - acc: 1.0000 - val_loss: 1.3370 - val_acc: 0.4444\n",
      "Epoch 341/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 4.7093e-04 - acc: 1.0000 - val_loss: 1.3389 - val_acc: 0.4444\n",
      "Epoch 342/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.5687e-04 - acc: 1.0000 - val_loss: 1.3399 - val_acc: 0.4444\n",
      "Epoch 343/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.4313e-04 - acc: 1.0000 - val_loss: 1.3395 - val_acc: 0.4444\n",
      "Epoch 344/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.3016e-04 - acc: 1.0000 - val_loss: 1.3411 - val_acc: 0.4444\n",
      "Epoch 345/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 4.1635e-04 - acc: 1.0000 - val_loss: 1.3420 - val_acc: 0.4444\n",
      "Epoch 346/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.0535e-04 - acc: 1.0000 - val_loss: 1.3430 - val_acc: 0.4444\n",
      "Epoch 347/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.9206e-04 - acc: 1.0000 - val_loss: 1.3448 - val_acc: 0.4444\n",
      "Epoch 348/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.8085e-04 - acc: 1.0000 - val_loss: 1.3447 - val_acc: 0.4444\n",
      "Epoch 349/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.6937e-04 - acc: 1.0000 - val_loss: 1.3458 - val_acc: 0.4444\n",
      "Epoch 350/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.5862e-04 - acc: 1.0000 - val_loss: 1.3445 - val_acc: 0.4444\n",
      "Epoch 351/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.4795e-04 - acc: 1.0000 - val_loss: 1.3461 - val_acc: 0.4444\n",
      "Epoch 352/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.3732e-04 - acc: 1.0000 - val_loss: 1.3467 - val_acc: 0.4444\n",
      "Epoch 353/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.2732e-04 - acc: 1.0000 - val_loss: 1.3479 - val_acc: 0.4444\n",
      "Epoch 354/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 6ms/step - loss: 3.1735e-04 - acc: 1.0000 - val_loss: 1.3493 - val_acc: 0.4444\n",
      "Epoch 355/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.0826e-04 - acc: 1.0000 - val_loss: 1.3511 - val_acc: 0.4444\n",
      "Epoch 356/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.9876e-04 - acc: 1.0000 - val_loss: 1.3520 - val_acc: 0.4444\n",
      "Epoch 357/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.9016e-04 - acc: 1.0000 - val_loss: 1.3537 - val_acc: 0.4444\n",
      "Epoch 358/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.8186e-04 - acc: 1.0000 - val_loss: 1.3528 - val_acc: 0.4444\n",
      "Epoch 359/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.7323e-04 - acc: 1.0000 - val_loss: 1.3546 - val_acc: 0.4444\n",
      "Epoch 360/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.6499e-04 - acc: 1.0000 - val_loss: 1.3565 - val_acc: 0.4444\n",
      "Epoch 361/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.5727e-04 - acc: 1.0000 - val_loss: 1.3552 - val_acc: 0.4444\n",
      "Epoch 362/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.4981e-04 - acc: 1.0000 - val_loss: 1.3601 - val_acc: 0.4444\n",
      "Epoch 363/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.4213e-04 - acc: 1.0000 - val_loss: 1.3599 - val_acc: 0.4444\n",
      "Epoch 364/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.3500e-04 - acc: 1.0000 - val_loss: 1.3613 - val_acc: 0.4444\n",
      "Epoch 365/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.2847e-04 - acc: 1.0000 - val_loss: 1.3597 - val_acc: 0.4444\n",
      "Epoch 366/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.2161e-04 - acc: 1.0000 - val_loss: 1.3625 - val_acc: 0.4444\n",
      "Epoch 367/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.1476e-04 - acc: 1.0000 - val_loss: 1.3638 - val_acc: 0.4444\n",
      "Epoch 368/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0851e-04 - acc: 1.0000 - val_loss: 1.3622 - val_acc: 0.4444\n",
      "Epoch 369/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0248e-04 - acc: 1.0000 - val_loss: 1.3648 - val_acc: 0.4444\n",
      "Epoch 370/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9650e-04 - acc: 1.0000 - val_loss: 1.3667 - val_acc: 0.4444\n",
      "Epoch 371/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9029e-04 - acc: 1.0000 - val_loss: 1.3667 - val_acc: 0.4444\n",
      "Epoch 372/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8514e-04 - acc: 1.0000 - val_loss: 1.3685 - val_acc: 0.4444\n",
      "Epoch 373/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7932e-04 - acc: 1.0000 - val_loss: 1.3683 - val_acc: 0.4444\n",
      "Epoch 374/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7398e-04 - acc: 1.0000 - val_loss: 1.3704 - val_acc: 0.4444\n",
      "Epoch 375/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6904e-04 - acc: 1.0000 - val_loss: 1.3733 - val_acc: 0.4444\n",
      "Epoch 376/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6398e-04 - acc: 1.0000 - val_loss: 1.3714 - val_acc: 0.4444\n",
      "Epoch 377/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5923e-04 - acc: 1.0000 - val_loss: 1.3750 - val_acc: 0.4444\n",
      "Epoch 378/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5438e-04 - acc: 1.0000 - val_loss: 1.3759 - val_acc: 0.4444\n",
      "Epoch 379/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5015e-04 - acc: 1.0000 - val_loss: 1.3782 - val_acc: 0.4444\n",
      "Epoch 380/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.4538e-04 - acc: 1.0000 - val_loss: 1.3766 - val_acc: 0.4444\n",
      "Epoch 381/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.4126e-04 - acc: 1.0000 - val_loss: 1.3763 - val_acc: 0.4444\n",
      "Epoch 382/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3711e-04 - acc: 1.0000 - val_loss: 1.3798 - val_acc: 0.4444\n",
      "Epoch 383/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3320e-04 - acc: 1.0000 - val_loss: 1.3804 - val_acc: 0.4444\n",
      "Epoch 384/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2901e-04 - acc: 1.0000 - val_loss: 1.3805 - val_acc: 0.4444\n",
      "Epoch 385/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2531e-04 - acc: 1.0000 - val_loss: 1.3801 - val_acc: 0.4444\n",
      "Epoch 386/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2150e-04 - acc: 1.0000 - val_loss: 1.3845 - val_acc: 0.4444\n",
      "Epoch 387/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1789e-04 - acc: 1.0000 - val_loss: 1.3864 - val_acc: 0.4444\n",
      "Epoch 388/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1486e-04 - acc: 1.0000 - val_loss: 1.3862 - val_acc: 0.4444\n",
      "Epoch 389/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1097e-04 - acc: 1.0000 - val_loss: 1.3883 - val_acc: 0.4444\n",
      "Epoch 390/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0785e-04 - acc: 1.0000 - val_loss: 1.3912 - val_acc: 0.4444\n",
      "Epoch 391/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0479e-04 - acc: 1.0000 - val_loss: 1.3891 - val_acc: 0.4444\n",
      "Epoch 392/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0176e-04 - acc: 1.0000 - val_loss: 1.3915 - val_acc: 0.4444\n",
      "Epoch 393/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.8697e-05 - acc: 1.0000 - val_loss: 1.3923 - val_acc: 0.4444\n",
      "Epoch 394/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.5876e-05 - acc: 1.0000 - val_loss: 1.3919 - val_acc: 0.4444\n",
      "Epoch 395/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.2977e-05 - acc: 1.0000 - val_loss: 1.3950 - val_acc: 0.4444\n",
      "Epoch 396/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 9.0167e-05 - acc: 1.0000 - val_loss: 1.3939 - val_acc: 0.4444\n",
      "Epoch 397/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.7530e-05 - acc: 1.0000 - val_loss: 1.3982 - val_acc: 0.4444\n",
      "Epoch 398/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.4872e-05 - acc: 1.0000 - val_loss: 1.3987 - val_acc: 0.4444\n",
      "Epoch 399/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.2457e-05 - acc: 1.0000 - val_loss: 1.3984 - val_acc: 0.4444\n",
      "Epoch 400/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.0043e-05 - acc: 1.0000 - val_loss: 1.4015 - val_acc: 0.4444\n",
      "Epoch 401/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 7.7639e-05 - acc: 1.0000 - val_loss: 1.4038 - val_acc: 0.4444\n",
      "Epoch 402/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 7.5473e-05 - acc: 1.0000 - val_loss: 1.4047 - val_acc: 0.4444\n",
      "Epoch 403/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.3330e-05 - acc: 1.0000 - val_loss: 1.4048 - val_acc: 0.4444\n",
      "Epoch 404/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.1002e-05 - acc: 1.0000 - val_loss: 1.4050 - val_acc: 0.4444\n",
      "Epoch 405/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.8931e-05 - acc: 1.0000 - val_loss: 1.4078 - val_acc: 0.4444\n",
      "Epoch 406/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.7006e-05 - acc: 1.0000 - val_loss: 1.4079 - val_acc: 0.4444\n",
      "Epoch 407/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.5039e-05 - acc: 1.0000 - val_loss: 1.4106 - val_acc: 0.4444\n",
      "Epoch 408/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.3098e-05 - acc: 1.0000 - val_loss: 1.4125 - val_acc: 0.4444\n",
      "Epoch 409/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.1255e-05 - acc: 1.0000 - val_loss: 1.4096 - val_acc: 0.4444\n",
      "Epoch 410/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.9488e-05 - acc: 1.0000 - val_loss: 1.4136 - val_acc: 0.4444\n",
      "Epoch 411/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.7770e-05 - acc: 1.0000 - val_loss: 1.4146 - val_acc: 0.4444\n",
      "Epoch 412/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.6103e-05 - acc: 1.0000 - val_loss: 1.4143 - val_acc: 0.4444\n",
      "Epoch 413/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.4326e-05 - acc: 1.0000 - val_loss: 1.4173 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.2804e-05 - acc: 1.0000 - val_loss: 1.4180 - val_acc: 0.4444\n",
      "Epoch 415/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.1306e-05 - acc: 1.0000 - val_loss: 1.4197 - val_acc: 0.4444\n",
      "Epoch 416/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 4.9745e-05 - acc: 1.0000 - val_loss: 1.4216 - val_acc: 0.4444\n",
      "Epoch 417/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.8222e-05 - acc: 1.0000 - val_loss: 1.4247 - val_acc: 0.4444\n",
      "Epoch 418/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.6926e-05 - acc: 1.0000 - val_loss: 1.4219 - val_acc: 0.4444\n",
      "Epoch 419/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.5566e-05 - acc: 1.0000 - val_loss: 1.4278 - val_acc: 0.4444\n",
      "Epoch 420/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 4.4210e-05 - acc: 1.0000 - val_loss: 1.4274 - val_acc: 0.4444\n",
      "Epoch 421/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.2767e-05 - acc: 1.0000 - val_loss: 1.4308 - val_acc: 0.4444\n",
      "Epoch 422/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.1590e-05 - acc: 1.0000 - val_loss: 1.4295 - val_acc: 0.4444\n",
      "Epoch 423/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 4.0301e-05 - acc: 1.0000 - val_loss: 1.4312 - val_acc: 0.4444\n",
      "Epoch 424/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.9179e-05 - acc: 1.0000 - val_loss: 1.4337 - val_acc: 0.4444\n",
      "Epoch 425/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.8054e-05 - acc: 1.0000 - val_loss: 1.4373 - val_acc: 0.4444\n",
      "Epoch 426/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.6886e-05 - acc: 1.0000 - val_loss: 1.4354 - val_acc: 0.4444\n",
      "Epoch 427/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.5800e-05 - acc: 1.0000 - val_loss: 1.4365 - val_acc: 0.4444\n",
      "Epoch 428/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.4811e-05 - acc: 1.0000 - val_loss: 1.4392 - val_acc: 0.4444\n",
      "Epoch 429/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.3716e-05 - acc: 1.0000 - val_loss: 1.4404 - val_acc: 0.4444\n",
      "Epoch 430/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.2749e-05 - acc: 1.0000 - val_loss: 1.4424 - val_acc: 0.4444\n",
      "Epoch 431/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 3.1776e-05 - acc: 1.0000 - val_loss: 1.4448 - val_acc: 0.4444\n",
      "Epoch 432/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 3.0856e-05 - acc: 1.0000 - val_loss: 1.4463 - val_acc: 0.4444\n",
      "Epoch 433/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.9951e-05 - acc: 1.0000 - val_loss: 1.4448 - val_acc: 0.4444\n",
      "Epoch 434/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.9047e-05 - acc: 1.0000 - val_loss: 1.4490 - val_acc: 0.4444\n",
      "Epoch 435/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.8270e-05 - acc: 1.0000 - val_loss: 1.4497 - val_acc: 0.4444\n",
      "Epoch 436/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.7423e-05 - acc: 1.0000 - val_loss: 1.4523 - val_acc: 0.4444\n",
      "Epoch 437/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.6643e-05 - acc: 1.0000 - val_loss: 1.4552 - val_acc: 0.4444\n",
      "Epoch 438/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.5787e-05 - acc: 1.0000 - val_loss: 1.4544 - val_acc: 0.4444\n",
      "Epoch 439/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.5107e-05 - acc: 1.0000 - val_loss: 1.4546 - val_acc: 0.4444\n",
      "Epoch 440/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.4380e-05 - acc: 1.0000 - val_loss: 1.4607 - val_acc: 0.4444\n",
      "Epoch 441/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.3661e-05 - acc: 1.0000 - val_loss: 1.4602 - val_acc: 0.4444\n",
      "Epoch 442/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.2939e-05 - acc: 1.0000 - val_loss: 1.4591 - val_acc: 0.4444\n",
      "Epoch 443/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.2290e-05 - acc: 1.0000 - val_loss: 1.4630 - val_acc: 0.4444\n",
      "Epoch 444/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1622e-05 - acc: 1.0000 - val_loss: 1.4651 - val_acc: 0.4444\n",
      "Epoch 445/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 2.1036e-05 - acc: 1.0000 - val_loss: 1.4672 - val_acc: 0.4444\n",
      "Epoch 446/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.0371e-05 - acc: 1.0000 - val_loss: 1.4686 - val_acc: 0.4444\n",
      "Epoch 447/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9804e-05 - acc: 1.0000 - val_loss: 1.4706 - val_acc: 0.4444\n",
      "Epoch 448/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.9198e-05 - acc: 1.0000 - val_loss: 1.4715 - val_acc: 0.4444\n",
      "Epoch 449/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8670e-05 - acc: 1.0000 - val_loss: 1.4747 - val_acc: 0.4444\n",
      "Epoch 450/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.8139e-05 - acc: 1.0000 - val_loss: 1.4749 - val_acc: 0.4444\n",
      "Epoch 451/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.7607e-05 - acc: 1.0000 - val_loss: 1.4790 - val_acc: 0.4444\n",
      "Epoch 452/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.7088e-05 - acc: 1.0000 - val_loss: 1.4822 - val_acc: 0.4444\n",
      "Epoch 453/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6576e-05 - acc: 1.0000 - val_loss: 1.4826 - val_acc: 0.4444\n",
      "Epoch 454/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.6100e-05 - acc: 1.0000 - val_loss: 1.4814 - val_acc: 0.4444\n",
      "Epoch 455/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5625e-05 - acc: 1.0000 - val_loss: 1.4844 - val_acc: 0.4444\n",
      "Epoch 456/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.5195e-05 - acc: 1.0000 - val_loss: 1.4868 - val_acc: 0.4444\n",
      "Epoch 457/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.4738e-05 - acc: 1.0000 - val_loss: 1.4880 - val_acc: 0.4444\n",
      "Epoch 458/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.4318e-05 - acc: 1.0000 - val_loss: 1.4872 - val_acc: 0.4444\n",
      "Epoch 459/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3905e-05 - acc: 1.0000 - val_loss: 1.4908 - val_acc: 0.4444\n",
      "Epoch 460/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.3492e-05 - acc: 1.0000 - val_loss: 1.4927 - val_acc: 0.4444\n",
      "Epoch 461/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.3101e-05 - acc: 1.0000 - val_loss: 1.4967 - val_acc: 0.4444\n",
      "Epoch 462/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2741e-05 - acc: 1.0000 - val_loss: 1.4965 - val_acc: 0.4444\n",
      "Epoch 463/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2364e-05 - acc: 1.0000 - val_loss: 1.4978 - val_acc: 0.4444\n",
      "Epoch 464/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2012e-05 - acc: 1.0000 - val_loss: 1.4992 - val_acc: 0.4444\n",
      "Epoch 465/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1655e-05 - acc: 1.0000 - val_loss: 1.5002 - val_acc: 0.4444\n",
      "Epoch 466/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1308e-05 - acc: 1.0000 - val_loss: 1.5013 - val_acc: 0.4444\n",
      "Epoch 467/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1004e-05 - acc: 1.0000 - val_loss: 1.5057 - val_acc: 0.4444\n",
      "Epoch 468/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0667e-05 - acc: 1.0000 - val_loss: 1.5044 - val_acc: 0.4444\n",
      "Epoch 469/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0364e-05 - acc: 1.0000 - val_loss: 1.5064 - val_acc: 0.4444\n",
      "Epoch 470/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0058e-05 - acc: 1.0000 - val_loss: 1.5078 - val_acc: 0.4444\n",
      "Epoch 471/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 9.7885e-06 - acc: 1.0000 - val_loss: 1.5109 - val_acc: 0.4444\n",
      "Epoch 472/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.4871e-06 - acc: 1.0000 - val_loss: 1.5142 - val_acc: 0.4444\n",
      "Epoch 473/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 9.2222e-06 - acc: 1.0000 - val_loss: 1.5155 - val_acc: 0.4444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 8.9562e-06 - acc: 1.0000 - val_loss: 1.5156 - val_acc: 0.4444\n",
      "Epoch 475/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.6990e-06 - acc: 1.0000 - val_loss: 1.5205 - val_acc: 0.4444\n",
      "Epoch 476/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.4518e-06 - acc: 1.0000 - val_loss: 1.5193 - val_acc: 0.4444\n",
      "Epoch 477/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 8.1957e-06 - acc: 1.0000 - val_loss: 1.5227 - val_acc: 0.4444\n",
      "Epoch 478/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.9882e-06 - acc: 1.0000 - val_loss: 1.5264 - val_acc: 0.4444\n",
      "Epoch 479/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.7221e-06 - acc: 1.0000 - val_loss: 1.5263 - val_acc: 0.4444\n",
      "Epoch 480/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.5102e-06 - acc: 1.0000 - val_loss: 1.5267 - val_acc: 0.4444\n",
      "Epoch 481/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.2950e-06 - acc: 1.0000 - val_loss: 1.5267 - val_acc: 0.4444\n",
      "Epoch 482/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 7.0897e-06 - acc: 1.0000 - val_loss: 1.5303 - val_acc: 0.4444\n",
      "Epoch 483/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.8811e-06 - acc: 1.0000 - val_loss: 1.5331 - val_acc: 0.4444\n",
      "Epoch 484/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.7000e-06 - acc: 1.0000 - val_loss: 1.5370 - val_acc: 0.4444\n",
      "Epoch 485/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.4771e-06 - acc: 1.0000 - val_loss: 1.5371 - val_acc: 0.4444\n",
      "Epoch 486/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.2872e-06 - acc: 1.0000 - val_loss: 1.5395 - val_acc: 0.4444\n",
      "Epoch 487/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 6.1051e-06 - acc: 1.0000 - val_loss: 1.5398 - val_acc: 0.4444\n",
      "Epoch 488/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.9373e-06 - acc: 1.0000 - val_loss: 1.5430 - val_acc: 0.4444\n",
      "Epoch 489/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.7894e-06 - acc: 1.0000 - val_loss: 1.5429 - val_acc: 0.4444\n",
      "Epoch 490/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 5.6106e-06 - acc: 1.0000 - val_loss: 1.5471 - val_acc: 0.4444\n",
      "Epoch 491/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.4483e-06 - acc: 1.0000 - val_loss: 1.5494 - val_acc: 0.4444\n",
      "Epoch 492/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.2971e-06 - acc: 1.0000 - val_loss: 1.5522 - val_acc: 0.4444\n",
      "Epoch 493/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 5.1393e-06 - acc: 1.0000 - val_loss: 1.5526 - val_acc: 0.4444\n",
      "Epoch 494/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.9936e-06 - acc: 1.0000 - val_loss: 1.5554 - val_acc: 0.4444\n",
      "Epoch 495/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.8523e-06 - acc: 1.0000 - val_loss: 1.5591 - val_acc: 0.4444\n",
      "Epoch 496/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.7055e-06 - acc: 1.0000 - val_loss: 1.5591 - val_acc: 0.4444\n",
      "Epoch 497/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.5863e-06 - acc: 1.0000 - val_loss: 1.5608 - val_acc: 0.4444\n",
      "Epoch 498/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.4505e-06 - acc: 1.0000 - val_loss: 1.5622 - val_acc: 0.4444\n",
      "Epoch 499/500\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 4.3280e-06 - acc: 1.0000 - val_loss: 1.5663 - val_acc: 0.4444\n",
      "Epoch 500/500\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 4.1823e-06 - acc: 1.0000 - val_loss: 1.5648 - val_acc: 0.4444\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "train_data = pad_sequences(train_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "test_data = pad_sequences(test_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_data, test_data, to_categorical(train_labels), to_categorical(test_labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels,\n",
    "                                                  test_size=len(set(train_labels)), random_state=2019,\n",
    "                                                  stratify=train_labels)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "\n",
    "word_input_tensor = Input(shape=(maxlen,) , name='words')\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "# model.add(layers.Conv1D(32, 1, activation='relu'))\n",
    "# model.add(layers.MaxPooling1D(2))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "# model.add(layers.GlobalMaxPooling1D())\n",
    "# model.add(layers.SimpleRNN(embedding_dim, dropout=0.1, recurrent_dropout=0.5, return_sequences= True))\n",
    "# model.add(layers.SimpleRNN(embedding_dim))\n",
    "# model.add(Dense(embedding_dim, activation='relu'))\n",
    "# model.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "x = layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen)(word_input_tensor)\n",
    "x = layers.Conv1D(32, 2, activation='relu', padding='same')(x)\n",
    "# x = layers.MaxPooling1D(2)(x)\n",
    "y = layers.Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "# y = layers.MaxPooling1D(2)(y)\n",
    "# y = layers.Conv1D(32, 3, activation='relu')(y)\n",
    "# y = layers.MaxPooling1D(2)(y)\n",
    "# y = layers.Conv1D(32, 5, activation='relu')(y)\n",
    "# y = layers.MaxPooling1D(2)(y)\n",
    "# y = layers.Conv1D(32, 5, activation='relu')(y)\n",
    "# y = layers.GlobalMaxPooling1D()(y)\n",
    "\n",
    "print('y:', y.shape, 'x:', x.shape)\n",
    "added = layers.add([y, x])\n",
    "answer = layers.GlobalMaxPooling1D()(added)\n",
    "answer = layers.Dense(len(set(train_labels)), activation='softmax')(answer)\n",
    "\n",
    "model = Model(word_input_tensor, answer)\n",
    "model.summary()\n",
    "\n",
    "# model.layers[0].set_weights([w2d.word_embedding])\n",
    "# model.layers[0].trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=500,\n",
    "                    batch_size=1)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              (None, 1020)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 32)           69503       words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 32)           72031       words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64)           0           sequential_3[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 9)            585         concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 142,119\n",
      "Trainable params: 142,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 63 samples, validate on 468 samples\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1976 - acc: 0.1111 - val_loss: 0.1970 - val_acc: 0.1111\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1973 - acc: 0.1111 - val_loss: 0.1970 - val_acc: 0.1111\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1970 - acc: 0.1111 - val_loss: 0.1970 - val_acc: 0.1111\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.1967 - acc: 0.1746 - val_loss: 0.1969 - val_acc: 0.1111\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.1964 - acc: 0.1905 - val_loss: 0.1970 - val_acc: 0.1111\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.1962 - acc: 0.2540 - val_loss: 0.1969 - val_acc: 0.1111\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.1960 - acc: 0.2698 - val_loss: 0.1968 - val_acc: 0.1111\n",
      "Epoch 8/100\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.1958 - acc: 0.2679"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e6aeefbca5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     batch_size=1)\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32mc:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\designer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "\n",
    "\n",
    "from keras import layers, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "train_data = pad_sequences(train_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "test_data = pad_sequences(test_tokenized_indexed, maxlen=maxlen)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_data, test_data, to_categorical(train_labels), to_categorical(test_labels)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels,\n",
    "#                                                   test_size=0.28, random_state=2019,\n",
    "#                                                   stratify=train_labels)\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_val = to_categorical(y_val)\n",
    "word_input_tensor = Input(shape=(maxlen,) , name='words')\n",
    "\n",
    "conv_1d_s3_model = Sequential()\n",
    "conv_1d_s3_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "# conv_1d_s3_model.add(layers.Dropout(0.1))\n",
    "conv_1d_s3_model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "conv_1d_s3_model.add(layers.GlobalMaxPooling1D())\n",
    "# conv_1d_s3_model.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "word_output_tensor_0 = conv_1d_s3_model(word_input_tensor)\n",
    "\n",
    "conv_1d_s1_model = Sequential()\n",
    "conv_1d_s1_model.add(layers.Embedding(w2d.word_embedding.shape[0], embedding_dim, input_length=maxlen))\n",
    "conv_1d_s1_model.add(layers.Conv1D(32, 1, activation='relu'))\n",
    "conv_1d_s1_model.add(layers.MaxPooling1D(1))\n",
    "conv_1d_s1_model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "conv_1d_s1_model.add(layers.GlobalMaxPooling1D())\n",
    "# conv_1d_s1_model.add(layers.Dense(len(set(train_labels)), activation='softmax'))\n",
    "\n",
    "word_output_tensor_1 = conv_1d_s1_model(word_input_tensor)\n",
    "\n",
    "concatenated = layers.concatenate([word_output_tensor_0, word_output_tensor_1], axis=-1)\n",
    "\n",
    "answer = layers.Dense(len(set(train_labels)), activation='softmax')(concatenated)\n",
    "\n",
    "model = Model(word_input_tensor, answer)\n",
    "model.summary()\n",
    "\n",
    "# model.layers[0].set_weights([w2d.word_embedding])\n",
    "# model.layers[0].trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=2e-4),\n",
    "              loss='mae',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=100,\n",
    "                    batch_size=1)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
